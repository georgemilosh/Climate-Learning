{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-05 16:49:44.890100: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "In this environment you cannot import Basemap\n",
      "Could not load field_infos: using the hardcoded version\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.insert(0,'../PLASIM/')\n",
    "import Learn2_new as ln\n",
    "ut = ln.ut # utilities\n",
    "ef = ln.ef # ERA_Fields_New\n",
    "\n",
    "# log to stdout\n",
    "import logging\n",
    "import os\n",
    "logging.getLogger().level = logging.INFO\n",
    "logging.getLogger().handlers = [logging.StreamHandler(sys.stdout)]\n",
    "\n",
    "# set spacing of the indentation\n",
    "ut.indentation_sep = '  '"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading config file from folder ./models/tests/test9\n",
      "tf.__version__ = '2.4.1'\n",
      "tf.config.list_physical_devices('GPU') = []\n",
      "\n",
      "This machine does not have a GPU: training may be very slow\n",
      "\n",
      "{\n",
      "    \"run_kwargs\": {\n",
      "        \"log_level\": 20,\n",
      "        \"load_data_kwargs\": {\n",
      "            \"dataset_years\": 1000,\n",
      "            \"year_list\": \"range(5)\",\n",
      "            \"sampling\": \"\",\n",
      "            \"Model\": \"CESM\",\n",
      "            \"area\": \"France\",\n",
      "            \"filter_area\": \"France\",\n",
      "            \"lon_start\": -72,\n",
      "            \"lon_end\": 56,\n",
      "            \"lat_start\": 128,\n",
      "            \"lat_end\": 192,\n",
      "            \"mylocal\": \"/local/gmiloshe/CESM/\",\n",
      "            \"fields\": [\n",
      "                \"t2m\"\n",
      "            ],\n",
      "            \"preprefix\": \"North_Anomalies_\",\n",
      "            \"datafolder\": \"Data_CESM\"\n",
      "        },\n",
      "        \"prepare_XY_kwargs\": {\n",
      "            \"do_premix\": false,\n",
      "            \"premix_seed\": 0,\n",
      "            \"do_balance_folds\": true,\n",
      "            \"nfolds\": 5,\n",
      "            \"year_permutation\": null,\n",
      "            \"flatten_time_axis\": true,\n",
      "            \"return_time_series\": false,\n",
      "            \"make_XY_kwargs\": {\n",
      "                \"label_field\": \"t2m\",\n",
      "                \"time_start\": 31,\n",
      "                \"time_end\": 123,\n",
      "                \"T\": 14,\n",
      "                \"tau\": 0,\n",
      "                \"percent\": 5,\n",
      "                \"threshold\": null,\n",
      "                \"label_period_start\": null,\n",
      "                \"label_period_end\": null,\n",
      "                \"A_weights\": null,\n",
      "                \"return_threshold\": false\n",
      "            },\n",
      "            \"roll_X_kwargs\": {\n",
      "                \"roll_axis\": \"lon\",\n",
      "                \"roll_steps\": 0\n",
      "            }\n",
      "        },\n",
      "        \"k_fold_cross_val_kwargs\": {\n",
      "            \"load_from\": \"last\",\n",
      "            \"nfolds\": 5,\n",
      "            \"val_folds\": 1,\n",
      "            \"u\": 1,\n",
      "            \"normalization_mode\": \"pointwise\",\n",
      "            \"fullmetrics\": true,\n",
      "            \"training_epochs\": 40,\n",
      "            \"training_epochs_tl\": 10,\n",
      "            \"loss\": \"sparse_categorical_crossentropy\",\n",
      "            \"lr\": 0.0001,\n",
      "            \"prune_threshold\": null,\n",
      "            \"min_folds_before_pruning\": null,\n",
      "            \"create_model_kwargs\": {\n",
      "                \"conv_channels\": null,\n",
      "                \"kernel_sizes\": null,\n",
      "                \"strides\": null,\n",
      "                \"padding\": \"valid\",\n",
      "                \"batch_normalizations\": true,\n",
      "                \"conv_activations\": \"relu\",\n",
      "                \"conv_dropouts\": 0.2,\n",
      "                \"max_pool_sizes\": false,\n",
      "                \"conv_l2coef\": null,\n",
      "                \"dense_units\": [\n",
      "                    2\n",
      "                ],\n",
      "                \"dense_activations\": [\n",
      "                    null\n",
      "                ],\n",
      "                \"dense_dropouts\": [\n",
      "                    false\n",
      "                ],\n",
      "                \"dense_l2coef\": null\n",
      "            },\n",
      "            \"train_model_kwargs\": {\n",
      "                \"enable_early_stopping\": false,\n",
      "                \"u\": 1,\n",
      "                \"batch_size\": 1024,\n",
      "                \"checkpoint_every\": 1,\n",
      "                \"additional_callbacks\": [\n",
      "                    \"csv_logger\"\n",
      "                ],\n",
      "                \"return_metric\": \"val_CustomLoss\",\n",
      "                \"early_stopping_kwargs\": {\n",
      "                    \"monitor\": \"val_CustomLoss\",\n",
      "                    \"min_delta\": 0,\n",
      "                    \"patience\": 0,\n",
      "                    \"mode\": \"auto\"\n",
      "                }\n",
      "            },\n",
      "            \"optimal_checkpoint_kwargs\": {\n",
      "                \"metric\": \"val_CustomLoss\",\n",
      "                \"direction\": \"minimize\",\n",
      "                \"first_epoch\": 1,\n",
      "                \"collective\": true,\n",
      "                \"fold_subfolder\": null\n",
      "            }\n",
      "        }\n",
      "    },\n",
      "    \"telegram_kwargs\": {\n",
      "        \"telegram_bot_token\": \"~/ENSMLbot.txt\",\n",
      "        \"chat_ID\": null,\n",
      "        \"telegram_logging_level\": 31,\n",
      "        \"telegram_logging_format\": null\n",
      "    }\n",
      "}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-05 16:49:52.190398: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2023-02-05 16:49:52.192937: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\n",
      "2023-02-05 16:49:52.414074: E tensorflow/stream_executor/cuda/cuda_driver.cc:328] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2023-02-05 16:49:52.414120: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (apollo2048g): /proc/driver/nvidia/version does not exist\n"
     ]
    }
   ],
   "source": [
    "import itertools as its\n",
    "# create a work directory\n",
    "work_dir = './models/tests/test9'\n",
    "\n",
    "t = ln.Trainer(work_dir)\n",
    "Months1 = [0, 0, 0, 0, 0, 0, 31, 30, 31, 31, 30, 0, 0, 0] # Because of 3 day running mean we lose 2 days\n",
    "Tot_Mon1 = list(its.accumulate(Months1))\n",
    "ln.fields_infos['t2m'] = { # how we label the field\n",
    "        'name': 'TSA', # how the variable is called in the *.nc files\n",
    "        'filename_suffix': 'TSA', # the ending of the filename\n",
    "        'label': 'Temperature',\n",
    "    }\n",
    "ln.fields_infos['mrso'] = { # how we label the field\n",
    "        'name': 'H2OSOI', # how the variable is called in the *.nc files\n",
    "        'filename_suffix': 'H2OSOI', # the ending of the filename\n",
    "        'label': 'soil moisture',\n",
    "    }\n",
    "ln.fields_infos['zg500'] = { # howimport itertools as its we label the field\n",
    "        'name': 'Z3', # how the variable is called in the *.nc files\n",
    "        'filename_suffix': 'Z3.500hPa', # the ending of the filename\n",
    "        'label': '500 mbar Geopotential',\n",
    "    }\n",
    "\n",
    "d = {\n",
    "    'conv_channels': None, \n",
    "    'kernel_sizes': None,\n",
    "    'strides': None,\n",
    "    'batch_normalization': False, # disable batch normalization\n",
    "    'max_pool_sizes': False, # disable max pool\n",
    "    'conv_dropout': False, # disable dropout in the convolutional layer\n",
    "    'max_pool_sizes': False,\n",
    "    'conv_l2coef': None,\n",
    "    'dense_units': [2], # number of neurons per fully connected layer\n",
    "    'dense_dropouts': [False],\n",
    "    'dense_activations': [None],\n",
    "    'dense_l2coef' : None,\n",
    "    'nfolds' : 5,\n",
    "    'fields': ['t2m'], \n",
    "    'year_list' : 'range(5)', \n",
    "    'mylocal' : '/local/gmiloshe/CESM/', \n",
    "    'time_start' : Tot_Mon1[6], \n",
    "    'time_end' : Tot_Mon1[9], # Take into account number of days per month in CESM\n",
    "    'lon_start' : -72, \n",
    "    'lon_end' : 56,\n",
    "    'lat_end' : 192, \n",
    "    'lat_start' : 128, # latitudes start from 90 degrees North Pole\n",
    "    'Model' : 'CESM', \n",
    "    'datafolder' : 'Data_CESM', \n",
    "    'dataset_years' : 1000, \n",
    "    'preprefix' : 'North_Anomalies_'\n",
    "}\n",
    "\n",
    "ut.set_values_recursive(t.config_dict, d, inplace=True)\n",
    "print(ut.dict2str(t.config_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scheduling 1 run at default values\n"
     ]
    }
   ],
   "source": [
    "t.schedule()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting 1 run\n",
      "apollo2048g: Run 1/1\n",
      "Skipping already performed run 0\n",
      "apollo2048g: \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ALL RUNS COMPLETED\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "t.run_multiple()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scheduling 1 run at values {'training_epochs': 2, 'u': 10}\n"
     ]
    }
   ],
   "source": [
    "t.schedule(training_epochs=2,u=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting 1 run\n",
      "apollo2048g: Run 1/1\n",
      "Models will be loaded from 0\n",
      "folder = '1--training_epochs__2--u__10'\n",
      "\n",
      "{\n",
      "    \"training_epochs\": 2,\n",
      "    \"u\": 10\n",
      "}\n",
      "prepare_XY:\n",
      "  return_threshold = False  \n",
      "  make_XY:\n",
      "    make_X:\n",
      "    make_X: completed in 0.0 s\n",
      "    assign_labels:\n",
      "      A_weights = None\n",
      "      compute_time_average:\n",
      "      compute_time_average: completed in 0.0 s\n",
      "      threshold = 3.1026405938310333\n",
      "    assign_labels: completed in 0.0 s\n",
      "  make_XY: completed in 0.0 s\n",
      "  roll_X:\n",
      "  roll_X: completed in 0.0 s\n",
      "  Mixing\n",
      "  Mixing overriden by provided permutation\n",
      "  Mixing completed in 0.0 s\n",
      "  \n",
      "  X.shape = (5, 79, 64, 128, 1), Y.shape = (5, 79)\n",
      "  Flattened time: X.shape = (395, 64, 128, 1), Y.shape = (395,)\n",
      "prepare_XY: completed in 0.1 s\n",
      "k_fold_cross_val:\n",
      "  =============\n",
      "  fold 0 (1/5)\n",
      "  =============\n",
      "  k_fold_cross_val_split:\n",
      "  k_fold_cross_val_split: completed in 0.0 s\n",
      "  number of training data before undersampling: 316 of which 310 negative and 6 positive\n",
      "  number of training data: 37 of which 31 negative and 6 positive\n",
      "  0.0000\\% of the data have non zero std below 1e-4\n",
      "  X_tr.shape = (37, 64, 128, 1), X_va.shape = (79, 64, 128, 1)\n",
      "  WARNING:tensorflow:Unable to restore custom metric. Please ensure that the layer implements `get_config` and `from_config` when saving. In addition, please use the `custom_objects` arg when calling `load_model()`.\n",
      "  Unable to restore custom metric. Please ensure that the layer implements `get_config` and `from_config` when saving. In addition, please use the `custom_objects` arg when calling `load_model()`.\n",
      "  WARNING:tensorflow:Unable to restore custom metric. Please ensure that the layer implements `get_config` and `from_config` when saving. In addition, please use the `custom_objects` arg when calling `load_model()`.\n",
      "  Unable to restore custom metric. Please ensure that the layer implements `get_config` and `from_config` when saving. In addition, please use the `custom_objects` arg when calling `load_model()`.\n",
      "  WARNING:tensorflow:Unable to restore custom metric. Please ensure that the layer implements `get_config` and `from_config` when saving. In addition, please use the `custom_objects` arg when calling `load_model()`.\n",
      "  Unable to restore custom metric. Please ensure that the layer implements `get_config` and `from_config` when saving. In addition, please use the `custom_objects` arg when calling `load_model()`.\n",
      "  WARNING:tensorflow:Unable to restore custom metric. Please ensure that the layer implements `get_config` and `from_config` when saving. In addition, please use the `custom_objects` arg when calling `load_model()`.\n",
      "  Unable to restore custom metric. Please ensure that the layer implements `get_config` and `from_config` when saving. In addition, please use the `custom_objects` arg when calling `load_model()`.\n",
      "  WARNING:tensorflow:Unable to restore custom metric. Please ensure that the layer implements `get_config` and `from_config` when saving. In addition, please use the `custom_objects` arg when calling `load_model()`.\n",
      "  Unable to restore custom metric. Please ensure that the layer implements `get_config` and `from_config` when saving. In addition, please use the `custom_objects` arg when calling `load_model()`.\n",
      "  \n",
      "  Model: \"sequential\"\n",
      "  _________________________________________________________________\n",
      "  Layer (type)                 Output Shape              Param #   \n",
      "  =================================================================\n",
      "  flatten (Flatten)            (None, 8192)              0         \n",
      "  _________________________________________________________________\n",
      "  dense (Dense)                (None, 2)                 16386     \n",
      "  =================================================================\n",
      "  Total params: 16,386\n",
      "  Trainable params: 16,386\n",
      "  Non-trainable params: 0\n",
      "  _________________________________________________________________\n",
      "  \n",
      "  Using sparse_categorical_crossentropy loss\n",
      "  train_model:\n",
      "    Converting training data to tensors\n",
      "    Converting validation data to tensors\n",
      "    Training the network on 37 datapoint and validating on 79\n",
      "    Epoch 1/10    \n",
      "    1/1 - 1s - loss: 0.6589 - accuracy: 0.5946 - MCC: 0.2815 - UnbiasedMCC: 0.0000e+00 - confusion_matrix: 9.2500 - BrierScore: 0.4049 - CustomLoss: 0.3797 - val_loss: 0.8786 - val_accuracy: 0.4304 - val_MCC: -3.9431e-02 - val_UnbiasedMCC: -7.1527e-02 - val_confusion_matrix: 19.7500 - val_BrierScore: 0.3967 - val_CustomLoss: 0.5461\n",
      "    \n",
      "    Epoch 00001: saving model to ./models/tests/test9/1--training_epochs__2--u__10/fold_0/cp-0001.ckpt    \n",
      "    Epoch 2/10    \n",
      "    1/1 - 0s - loss: 0.6095 - accuracy: 0.6757 - MCC: 0.4520 - UnbiasedMCC: 0.0000e+00 - confusion_matrix: 9.2500 - BrierScore: 0.4036 - CustomLoss: 0.3228 - val_loss: 0.8706 - val_accuracy: 0.4304 - val_MCC: 0.0071 - val_UnbiasedMCC: -5.0252e-02 - val_confusion_matrix: 19.7500 - val_BrierScore: 0.3935 - val_CustomLoss: 0.5215\n",
      "    \n",
      "    Epoch 00002: saving model to ./models/tests/test9/1--training_epochs__2--u__10/fold_0/cp-0002.ckpt    \n",
      "    Epoch 3/10    \n",
      "    1/1 - 0s - loss: 0.5705 - accuracy: 0.7297 - MCC: 0.5040 - UnbiasedMCC: 0.3788 - confusion_matrix: 9.2500 - BrierScore: 0.4026 - CustomLoss: 0.2740 - val_loss: 0.8635 - val_accuracy: 0.4177 - val_MCC: -4.4521e-03 - val_UnbiasedMCC: 0.0000e+00 - val_confusion_matrix: 19.7500 - val_BrierScore: 0.3911 - val_CustomLoss: 0.5027\n",
      "    \n",
      "    Epoch 00003: saving model to ./models/tests/test9/1--training_epochs__2--u__10/fold_0/cp-0003.ckpt    \n",
      "    Epoch 4/10    \n",
      "    1/1 - 0s - loss: 0.5397 - accuracy: 0.7838 - MCC: 0.5639 - UnbiasedMCC: 0.3788 - confusion_matrix: 9.2500 - BrierScore: 0.4029 - CustomLoss: 0.2337 - val_loss: 0.8564 - val_accuracy: 0.4430 - val_MCC: 0.1147 - val_UnbiasedMCC: 0.0000e+00 - val_confusion_matrix: 19.7500 - val_BrierScore: 0.3898 - val_CustomLoss: 0.4896\n",
      "    \n",
      "    Epoch 00004: saving model to ./models/tests/test9/1--training_epochs__2--u__10/fold_0/cp-0004.ckpt    \n",
      "    Epoch 5/10    \n",
      "    1/1 - 0s - loss: 0.5148 - accuracy: 0.7838 - MCC: 0.5639 - UnbiasedMCC: 0.6752 - confusion_matrix: 9.2500 - BrierScore: 0.4052 - CustomLoss: 0.2014 - val_loss: 0.8488 - val_accuracy: 0.4430 - val_MCC: 0.1147 - val_UnbiasedMCC: 0.0000e+00 - val_confusion_matrix: 19.7500 - val_BrierScore: 0.3895 - val_CustomLoss: 0.4815\n",
      "    \n",
      "    Epoch 00005: saving model to ./models/tests/test9/1--training_epochs__2--u__10/fold_0/cp-0005.ckpt    \n",
      "    Epoch 6/10    \n",
      "    1/1 - 0s - loss: 0.4939 - accuracy: 0.7838 - MCC: 0.5639 - UnbiasedMCC: 0.8985 - confusion_matrix: 9.2500 - BrierScore: 0.4090 - CustomLoss: 0.1760 - val_loss: 0.8407 - val_accuracy: 0.4177 - val_MCC: 0.0434 - val_UnbiasedMCC: 0.0000e+00 - val_confusion_matrix: 19.7500 - val_BrierScore: 0.3901 - val_CustomLoss: 0.4776\n",
      "    \n",
      "    Epoch 00006: saving model to ./models/tests/test9/1--training_epochs__2--u__10/fold_0/cp-0006.ckpt    \n",
      "    Epoch 7/10    \n",
      "    1/1 - 0s - loss: 0.4755 - accuracy: 0.7838 - MCC: 0.5639 - UnbiasedMCC: 0.8985 - confusion_matrix: 9.2500 - BrierScore: 0.4137 - CustomLoss: 0.1560 - val_loss: 0.8324 - val_accuracy: 0.4557 - val_MCC: 0.0770 - val_UnbiasedMCC: 0.0000e+00 - val_confusion_matrix: 19.7500 - val_BrierScore: 0.3915 - val_CustomLoss: 0.4773\n",
      "    \n",
      "    Epoch 00007: saving model to ./models/tests/test9/1--training_epochs__2--u__10/fold_0/cp-0007.ckpt    \n",
      "    Epoch 8/10    \n",
      "    1/1 - 0s - loss: 0.4588 - accuracy: 0.7838 - MCC: 0.5639 - UnbiasedMCC: 0.8985 - confusion_matrix: 9.2500 - BrierScore: 0.4187 - CustomLoss: 0.1403 - val_loss: 0.8243 - val_accuracy: 0.4810 - val_MCC: 0.0990 - val_UnbiasedMCC: 0.0000e+00 - val_confusion_matrix: 19.7500 - val_BrierScore: 0.3933 - val_CustomLoss: 0.4797\n",
      "    \n",
      "    Epoch 00008: saving model to ./models/tests/test9/1--training_epochs__2--u__10/fold_0/cp-0008.ckpt    \n",
      "    Epoch 9/10    \n",
      "    1/1 - 0s - loss: 0.4431 - accuracy: 0.7568 - MCC: 0.5328 - UnbiasedMCC: 0.8985 - confusion_matrix: 9.2500 - BrierScore: 0.4235 - CustomLoss: 0.1277 - val_loss: 0.8166 - val_accuracy: 0.4810 - val_MCC: 0.0522 - val_UnbiasedMCC: 0.0000e+00 - val_confusion_matrix: 19.7500 - val_BrierScore: 0.3953 - val_CustomLoss: 0.4842\n",
      "    \n",
      "    Epoch 00009: saving model to ./models/tests/test9/1--training_epochs__2--u__10/fold_0/cp-0009.ckpt    \n",
      "    Epoch 10/10    \n",
      "    1/1 - 0s - loss: 0.4283 - accuracy: 0.7838 - MCC: 0.5639 - UnbiasedMCC: 0.8985 - confusion_matrix: 9.2500 - BrierScore: 0.4280 - CustomLoss: 0.1175 - val_loss: 0.8097 - val_accuracy: 0.4304 - val_MCC: -1.3077e-01 - val_UnbiasedMCC: 0.0000e+00 - val_confusion_matrix: 19.7500 - val_BrierScore: 0.3975 - val_CustomLoss: 0.4901\n",
      "    \n",
      "    Epoch 00010: saving model to ./models/tests/test9/1--training_epochs__2--u__10/fold_0/cp-0010.ckpt    \n",
      "    INFO:tensorflow:Assets written to: ./models/tests/test9/1--training_epochs__2--u__10/fold_0/assets\n",
      "    Assets written to: ./models/tests/test9/1--training_epochs__2--u__10/fold_0/assets\n",
      "                 loss  accuracy       MCC  UnbiasedMCC           confusion_matrix  \\\n",
      "    epoch-1                                                                         \n",
      "    0        0.658907  0.594595  0.281507     0.000000  [[31.0, 0.0], [6.0, 0.0]]   \n",
      "    1        0.609520  0.675676  0.451997     0.000000  [[31.0, 0.0], [6.0, 0.0]]   \n",
      "    2        0.570509  0.729730  0.504016     0.378838  [[31.0, 0.0], [5.0, 1.0]]   \n",
      "    3        0.539703  0.783784  0.563890     0.378838  [[31.0, 0.0], [5.0, 1.0]]   \n",
      "    4        0.514814  0.783784  0.563890     0.675191  [[31.0, 0.0], [3.0, 3.0]]   \n",
      "    5        0.493894  0.783784  0.563890     0.898494  [[31.0, 0.0], [1.0, 5.0]]   \n",
      "    6        0.475520  0.783784  0.563890     0.898494  [[31.0, 0.0], [1.0, 5.0]]   \n",
      "    7        0.458775  0.783784  0.563890     0.898494  [[31.0, 0.0], [1.0, 5.0]]   \n",
      "    8        0.443124  0.756757  0.532795     0.898494  [[31.0, 0.0], [1.0, 5.0]]   \n",
      "    9        0.428291  0.783784  0.563890     0.898494  [[31.0, 0.0], [1.0, 5.0]]   \n",
      "    \n",
      "             BrierScore  CustomLoss  val_loss  val_accuracy   val_MCC  \\\n",
      "    epoch-1                                                             \n",
      "    0          0.404904    0.379708  0.878598      0.430380 -0.039431   \n",
      "    1          0.403562    0.322783  0.870609      0.430380  0.007080   \n",
      "    2          0.402562    0.274029  0.863519      0.417722 -0.004452   \n",
      "    3          0.402947    0.233734  0.856395      0.443038  0.114735   \n",
      "    4          0.405182    0.201414  0.848801      0.443038  0.114735   \n",
      "    5          0.408984    0.175964  0.840733      0.417722  0.043364   \n",
      "    6          0.413684    0.156020  0.832449      0.455696  0.076997   \n",
      "    7          0.418657    0.140285  0.824287      0.481013  0.099015   \n",
      "    8          0.423496    0.127700  0.816598      0.481013  0.052197   \n",
      "    9          0.427994    0.117461  0.809681      0.430380 -0.130770   \n",
      "    \n",
      "             val_UnbiasedMCC        val_confusion_matrix  val_BrierScore  \\\n",
      "    epoch-1                                                                \n",
      "    0              -0.071527  [[64.0, 2.0], [13.0, 0.0]]        0.396686   \n",
      "    1              -0.050252  [[65.0, 1.0], [13.0, 0.0]]        0.393471   \n",
      "    2               0.000000  [[66.0, 0.0], [13.0, 0.0]]        0.391110   \n",
      "    3               0.000000  [[66.0, 0.0], [13.0, 0.0]]        0.389792   \n",
      "    4               0.000000  [[66.0, 0.0], [13.0, 0.0]]        0.389512   \n",
      "    5               0.000000  [[66.0, 0.0], [13.0, 0.0]]        0.390135   \n",
      "    6               0.000000  [[66.0, 0.0], [13.0, 0.0]]        0.391456   \n",
      "    7               0.000000  [[66.0, 0.0], [13.0, 0.0]]        0.393260   \n",
      "    8               0.000000  [[66.0, 0.0], [13.0, 0.0]]        0.395346   \n",
      "    9               0.000000  [[66.0, 0.0], [13.0, 0.0]]        0.397539   \n",
      "    \n",
      "             val_CustomLoss  \n",
      "    epoch-1                  \n",
      "    0              0.546115  \n",
      "    1              0.521520  \n",
      "    2              0.502720  \n",
      "    3              0.489570  \n",
      "    4              0.481470  \n",
      "    5              0.477643  \n",
      "    6              0.477301  \n",
      "    7              0.479707  \n",
      "    8              0.484177  \n",
      "    9              0.490080  \n",
      "    score = 0.47730082273483276\n",
      "  train_model: completed in 4.1 s\n",
      "  RAM memory: 3.979e+11\n",
      "  =============\n",
      "  fold 1 (2/5)\n",
      "  =============\n",
      "  k_fold_cross_val_split:\n",
      "  k_fold_cross_val_split: completed in 0.0 s\n",
      "  number of training data before undersampling: 316 of which 303 negative and 13 positive\n",
      "  number of training data: 43 of which 30 negative and 13 positive\n",
      "  0.0000\\% of the data have non zero std below 1e-4\n",
      "  X_tr.shape = (43, 64, 128, 1), X_va.shape = (79, 64, 128, 1)\n",
      "  WARNING:tensorflow:Unable to restore custom metric. Please ensure that the layer implements `get_config` and `from_config` when saving. In addition, please use the `custom_objects` arg when calling `load_model()`.\n",
      "  Unable to restore custom metric. Please ensure that the layer implements `get_config` and `from_config` when saving. In addition, please use the `custom_objects` arg when calling `load_model()`.\n",
      "  WARNING:tensorflow:Unable to restore custom metric. Please ensure that the layer implements `get_config` and `from_config` when saving. In addition, please use the `custom_objects` arg when calling `load_model()`.\n",
      "  Unable to restore custom metric. Please ensure that the layer implements `get_config` and `from_config` when saving. In addition, please use the `custom_objects` arg when calling `load_model()`.\n",
      "  WARNING:tensorflow:Unable to restore custom metric. Please ensure that the layer implements `get_config` and `from_config` when saving. In addition, please use the `custom_objects` arg when calling `load_model()`.\n",
      "  Unable to restore custom metric. Please ensure that the layer implements `get_config` and `from_config` when saving. In addition, please use the `custom_objects` arg when calling `load_model()`.\n",
      "  WARNING:tensorflow:Unable to restore custom metric. Please ensure that the layer implements `get_config` and `from_config` when saving. In addition, please use the `custom_objects` arg when calling `load_model()`.\n",
      "  Unable to restore custom metric. Please ensure that the layer implements `get_config` and `from_config` when saving. In addition, please use the `custom_objects` arg when calling `load_model()`.\n",
      "  WARNING:tensorflow:Unable to restore custom metric. Please ensure that the layer implements `get_config` and `from_config` when saving. In addition, please use the `custom_objects` arg when calling `load_model()`.\n",
      "  Unable to restore custom metric. Please ensure that the layer implements `get_config` and `from_config` when saving. In addition, please use the `custom_objects` arg when calling `load_model()`.\n",
      "  \n",
      "  Model: \"sequential\"\n",
      "  _________________________________________________________________\n",
      "  Layer (type)                 Output Shape              Param #   \n",
      "  =================================================================\n",
      "  flatten (Flatten)            (None, 8192)              0         \n",
      "  _________________________________________________________________\n",
      "  dense (Dense)                (None, 2)                 16386     \n",
      "  =================================================================\n",
      "  Total params: 16,386\n",
      "  Trainable params: 16,386\n",
      "  Non-trainable params: 0\n",
      "  _________________________________________________________________\n",
      "  \n",
      "  Using sparse_categorical_crossentropy loss\n",
      "  train_model:\n",
      "    Converting training data to tensors\n",
      "    Converting validation data to tensors\n",
      "    Training the network on 43 datapoint and validating on 79\n",
      "    Epoch 1/10    \n",
      "    1/1 - 1s - loss: 0.4940 - accuracy: 0.8140 - MCC: 0.6738 - UnbiasedMCC: 0.0000e+00 - confusion_matrix: 10.7500 - BrierScore: 0.4051 - CustomLoss: 0.5390 - val_loss: 0.5500 - val_accuracy: 0.7342 - val_MCC: -3.3851e-02 - val_UnbiasedMCC: 0.0000e+00 - val_confusion_matrix: 19.7500 - val_BrierScore: 0.4422 - val_CustomLoss: 0.3062\n",
      "    \n",
      "    Epoch 00001: saving model to ./models/tests/test9/1--training_epochs__2--u__10/fold_1/cp-0001.ckpt    \n",
      "    Epoch 2/10    \n",
      "    1/1 - 0s - loss: 0.4294 - accuracy: 0.8837 - MCC: 0.7758 - UnbiasedMCC: 0.0000e+00 - confusion_matrix: 10.7500 - BrierScore: 0.4015 - CustomLoss: 0.4528 - val_loss: 0.5643 - val_accuracy: 0.7215 - val_MCC: -4.1818e-02 - val_UnbiasedMCC: 0.0000e+00 - val_confusion_matrix: 19.7500 - val_BrierScore: 0.4407 - val_CustomLoss: 0.3146\n",
      "    \n",
      "    Epoch 00002: saving model to ./models/tests/test9/1--training_epochs__2--u__10/fold_1/cp-0002.ckpt    \n",
      "    Epoch 3/10    \n",
      "    1/1 - 0s - loss: 0.3790 - accuracy: 0.9070 - MCC: 0.8141 - UnbiasedMCC: 0.3355 - confusion_matrix: 10.7500 - BrierScore: 0.3997 - CustomLoss: 0.3793 - val_loss: 0.5833 - val_accuracy: 0.7089 - val_MCC: -4.9531e-02 - val_UnbiasedMCC: 0.0000e+00 - val_confusion_matrix: 19.7500 - val_BrierScore: 0.4389 - val_CustomLoss: 0.3246\n",
      "    \n",
      "    Epoch 00003: saving model to ./models/tests/test9/1--training_epochs__2--u__10/fold_1/cp-0003.ckpt    \n",
      "    Epoch 4/10    \n",
      "    1/1 - 0s - loss: 0.3398 - accuracy: 0.9070 - MCC: 0.8141 - UnbiasedMCC: 0.6117 - confusion_matrix: 10.7500 - BrierScore: 0.4012 - CustomLoss: 0.3188 - val_loss: 0.6054 - val_accuracy: 0.7089 - val_MCC: -4.9531e-02 - val_UnbiasedMCC: 0.0000e+00 - val_confusion_matrix: 19.7500 - val_BrierScore: 0.4369 - val_CustomLoss: 0.3361\n",
      "    \n",
      "    Epoch 00004: saving model to ./models/tests/test9/1--training_epochs__2--u__10/fold_1/cp-0004.ckpt    \n",
      "    Epoch 5/10    \n",
      "    1/1 - 0s - loss: 0.3087 - accuracy: 0.9070 - MCC: 0.8141 - UnbiasedMCC: 0.6699 - confusion_matrix: 10.7500 - BrierScore: 0.4058 - CustomLoss: 0.2703 - val_loss: 0.6293 - val_accuracy: 0.6962 - val_MCC: -5.7030e-02 - val_UnbiasedMCC: -3.2461e-02 - val_confusion_matrix: 19.7500 - val_BrierScore: 0.4351 - val_CustomLoss: 0.3488\n",
      "    \n",
      "    Epoch 00005: saving model to ./models/tests/test9/1--training_epochs__2--u__10/fold_1/cp-0005.ckpt    \n",
      "    Epoch 6/10    \n",
      "    1/1 - 0s - loss: 0.2837 - accuracy: 0.9070 - MCC: 0.8141 - UnbiasedMCC: 0.7263 - confusion_matrix: 10.7500 - BrierScore: 0.4119 - CustomLoss: 0.2319 - val_loss: 0.6541 - val_accuracy: 0.6709 - val_MCC: -7.1514e-02 - val_UnbiasedMCC: -4.6204e-02 - val_confusion_matrix: 19.7500 - val_BrierScore: 0.4336 - val_CustomLoss: 0.3622\n",
      "    \n",
      "    Epoch 00006: saving model to ./models/tests/test9/1--training_epochs__2--u__10/fold_1/cp-0006.ckpt    \n",
      "    Epoch 7/10    \n",
      "    1/1 - 0s - loss: 0.2631 - accuracy: 0.9070 - MCC: 0.8141 - UnbiasedMCC: 0.7816 - confusion_matrix: 10.7500 - BrierScore: 0.4184 - CustomLoss: 0.2014 - val_loss: 0.6788 - val_accuracy: 0.6582 - val_MCC: -7.8552e-02 - val_UnbiasedMCC: -4.6204e-02 - val_confusion_matrix: 19.7500 - val_BrierScore: 0.4324 - val_CustomLoss: 0.3761\n",
      "    \n",
      "    Epoch 00007: saving model to ./models/tests/test9/1--training_epochs__2--u__10/fold_1/cp-0007.ckpt    \n",
      "    Epoch 8/10    \n",
      "    1/1 - 0s - loss: 0.2458 - accuracy: 0.9070 - MCC: 0.8141 - UnbiasedMCC: 0.8362 - confusion_matrix: 10.7500 - BrierScore: 0.4246 - CustomLoss: 0.1770 - val_loss: 0.7027 - val_accuracy: 0.6582 - val_MCC: -7.8552e-02 - val_UnbiasedMCC: -4.6204e-02 - val_confusion_matrix: 19.7500 - val_BrierScore: 0.4316 - val_CustomLoss: 0.3902\n",
      "    \n",
      "    Epoch 00008: saving model to ./models/tests/test9/1--training_epochs__2--u__10/fold_1/cp-0008.ckpt    \n",
      "    Epoch 9/10    \n",
      "    1/1 - 0s - loss: 0.2309 - accuracy: 0.9070 - MCC: 0.8141 - UnbiasedMCC: 0.8362 - confusion_matrix: 10.7500 - BrierScore: 0.4301 - CustomLoss: 0.1572 - val_loss: 0.7254 - val_accuracy: 0.6456 - val_MCC: -8.5485e-02 - val_UnbiasedMCC: -6.6208e-02 - val_confusion_matrix: 19.7500 - val_BrierScore: 0.4310 - val_CustomLoss: 0.4042\n",
      "    \n",
      "    Epoch 00009: saving model to ./models/tests/test9/1--training_epochs__2--u__10/fold_1/cp-0009.ckpt    \n",
      "    Epoch 10/10    \n",
      "    1/1 - 0s - loss: 0.2178 - accuracy: 0.9070 - MCC: 0.8141 - UnbiasedMCC: 0.8362 - confusion_matrix: 10.7500 - BrierScore: 0.4351 - CustomLoss: 0.1410 - val_loss: 0.7466 - val_accuracy: 0.6329 - val_MCC: -9.2332e-02 - val_UnbiasedMCC: -7.4522e-02 - val_confusion_matrix: 19.7500 - val_BrierScore: 0.4307 - val_CustomLoss: 0.4177\n",
      "    \n",
      "    Epoch 00010: saving model to ./models/tests/test9/1--training_epochs__2--u__10/fold_1/cp-0010.ckpt    \n",
      "    INFO:tensorflow:Assets written to: ./models/tests/test9/1--training_epochs__2--u__10/fold_1/assets\n",
      "    Assets written to: ./models/tests/test9/1--training_epochs__2--u__10/fold_1/assets\n",
      "                 loss  accuracy       MCC  UnbiasedMCC  \\\n",
      "    epoch-1                                              \n",
      "    0        0.493989  0.813953  0.673772     0.000000   \n",
      "    1        0.429379  0.883721  0.775791     0.000000   \n",
      "    2        0.379045  0.906977  0.814092     0.335515   \n",
      "    3        0.339757  0.906977  0.814092     0.611736   \n",
      "    4        0.308693  0.906977  0.814092     0.669864   \n",
      "    5        0.283671  0.906977  0.814092     0.726273   \n",
      "    6        0.263086  0.906977  0.814092     0.781575   \n",
      "    7        0.245771  0.906977  0.814092     0.836242   \n",
      "    8        0.230881  0.906977  0.814092     0.836242   \n",
      "    9        0.217803  0.906977  0.814092     0.836242   \n",
      "    \n",
      "                       confusion_matrix  BrierScore  CustomLoss  val_loss  \\\n",
      "    epoch-1                                                                 \n",
      "    0        [[30.0, 0.0], [13.0, 0.0]]    0.405126    0.539022  0.550029   \n",
      "    1        [[30.0, 0.0], [13.0, 0.0]]    0.401454    0.452825  0.564342   \n",
      "    2        [[30.0, 0.0], [11.0, 2.0]]    0.399667    0.379257  0.583261   \n",
      "    3         [[30.0, 0.0], [7.0, 6.0]]    0.401219    0.318784  0.605364   \n",
      "    4         [[30.0, 0.0], [6.0, 7.0]]    0.405775    0.270337  0.629348   \n",
      "    5         [[30.0, 0.0], [5.0, 8.0]]    0.411929    0.231932  0.654107   \n",
      "    6         [[30.0, 0.0], [4.0, 9.0]]    0.418430    0.201440  0.678767   \n",
      "    7        [[30.0, 0.0], [3.0, 10.0]]    0.424589    0.177026  0.702687   \n",
      "    8        [[30.0, 0.0], [3.0, 10.0]]    0.430146    0.157248  0.725405   \n",
      "    9        [[30.0, 0.0], [3.0, 10.0]]    0.435061    0.141022  0.746607   \n",
      "    \n",
      "             val_accuracy   val_MCC  val_UnbiasedMCC       val_confusion_matrix  \\\n",
      "    epoch-1                                                                       \n",
      "    0            0.734177 -0.033851         0.000000  [[73.0, 0.0], [6.0, 0.0]]   \n",
      "    1            0.721519 -0.041818         0.000000  [[73.0, 0.0], [6.0, 0.0]]   \n",
      "    2            0.708861 -0.049531         0.000000  [[73.0, 0.0], [6.0, 0.0]]   \n",
      "    3            0.708861 -0.049531         0.000000  [[73.0, 0.0], [6.0, 0.0]]   \n",
      "    4            0.696203 -0.057030        -0.032461  [[72.0, 1.0], [6.0, 0.0]]   \n",
      "    5            0.670886 -0.071514        -0.046204  [[71.0, 2.0], [6.0, 0.0]]   \n",
      "    6            0.658228 -0.078552        -0.046204  [[71.0, 2.0], [6.0, 0.0]]   \n",
      "    7            0.658228 -0.078552        -0.046204  [[71.0, 2.0], [6.0, 0.0]]   \n",
      "    8            0.645570 -0.085485        -0.066208  [[69.0, 4.0], [6.0, 0.0]]   \n",
      "    9            0.632911 -0.092332        -0.074522  [[68.0, 5.0], [6.0, 0.0]]   \n",
      "    \n",
      "             val_BrierScore  val_CustomLoss  \n",
      "    epoch-1                                  \n",
      "    0              0.442231        0.306191  \n",
      "    1              0.440749        0.314584  \n",
      "    2              0.438861        0.324642  \n",
      "    3              0.436888        0.336138  \n",
      "    4              0.435074        0.348774  \n",
      "    5              0.433562        0.362220  \n",
      "    6              0.432401        0.376140  \n",
      "    7              0.431573        0.390215  \n",
      "    8              0.431027        0.404162  \n",
      "    9              0.430705        0.417748  \n",
      "    score = 0.3061913251876831\n",
      "  train_model: completed in 3.9 s\n",
      "  RAM memory: 3.979e+11\n",
      "  =============\n",
      "  fold 2 (3/5)\n",
      "  =============\n",
      "  k_fold_cross_val_split:\n",
      "  k_fold_cross_val_split: completed in 0.0 s\n",
      "  number of training data before undersampling: 316 of which 297 negative and 19 positive\n",
      "  number of training data: 48 of which 29 negative and 19 positive\n",
      "  0.0000\\% of the data have non zero std below 1e-4\n",
      "  X_tr.shape = (48, 64, 128, 1), X_va.shape = (79, 64, 128, 1)\n",
      "  WARNING:tensorflow:Unable to restore custom metric. Please ensure that the layer implements `get_config` and `from_config` when saving. In addition, please use the `custom_objects` arg when calling `load_model()`.\n",
      "  Unable to restore custom metric. Please ensure that the layer implements `get_config` and `from_config` when saving. In addition, please use the `custom_objects` arg when calling `load_model()`.\n",
      "  WARNING:tensorflow:Unable to restore custom metric. Please ensure that the layer implements `get_config` and `from_config` when saving. In addition, please use the `custom_objects` arg when calling `load_model()`.\n",
      "  Unable to restore custom metric. Please ensure that the layer implements `get_config` and `from_config` when saving. In addition, please use the `custom_objects` arg when calling `load_model()`.\n",
      "  WARNING:tensorflow:Unable to restore custom metric. Please ensure that the layer implements `get_config` and `from_config` when saving. In addition, please use the `custom_objects` arg when calling `load_model()`.\n",
      "  Unable to restore custom metric. Please ensure that the layer implements `get_config` and `from_config` when saving. In addition, please use the `custom_objects` arg when calling `load_model()`.\n",
      "  WARNING:tensorflow:Unable to restore custom metric. Please ensure that the layer implements `get_config` and `from_config` when saving. In addition, please use the `custom_objects` arg when calling `load_model()`.\n",
      "  Unable to restore custom metric. Please ensure that the layer implements `get_config` and `from_config` when saving. In addition, please use the `custom_objects` arg when calling `load_model()`.\n",
      "  WARNING:tensorflow:Unable to restore custom metric. Please ensure that the layer implements `get_config` and `from_config` when saving. In addition, please use the `custom_objects` arg when calling `load_model()`.\n",
      "  Unable to restore custom metric. Please ensure that the layer implements `get_config` and `from_config` when saving. In addition, please use the `custom_objects` arg when calling `load_model()`.\n",
      "  \n",
      "  Model: \"sequential\"\n",
      "  _________________________________________________________________\n",
      "  Layer (type)                 Output Shape              Param #   \n",
      "  =================================================================\n",
      "  flatten (Flatten)            (None, 8192)              0         \n",
      "  _________________________________________________________________\n",
      "  dense (Dense)                (None, 2)                 16386     \n",
      "  =================================================================\n",
      "  Total params: 16,386\n",
      "  Trainable params: 16,386\n",
      "  Non-trainable params: 0\n",
      "  _________________________________________________________________\n",
      "  \n",
      "  Using sparse_categorical_crossentropy loss\n",
      "  train_model:\n",
      "    Converting training data to tensors\n",
      "    Converting validation data to tensors\n",
      "    Training the network on 48 datapoint and validating on 79\n",
      "    Epoch 1/10    \n",
      "    1/1 - 1s - loss: 0.6533 - accuracy: 0.5833 - MCC: 0.1986 - UnbiasedMCC: 0.0000e+00 - confusion_matrix: 12.0000 - BrierScore: 0.4054 - CustomLoss: 0.9150 - val_loss: 0.5731 - val_accuracy: 0.7215 - val_MCC: 0.0000e+00 - val_UnbiasedMCC: 0.0000e+00 - val_confusion_matrix: 19.7500 - val_BrierScore: 0.4349 - val_CustomLoss: 0.1051\n",
      "    \n",
      "    Epoch 00001: saving model to ./models/tests/test9/1--training_epochs__2--u__10/fold_2/cp-0001.ckpt    \n",
      "    Epoch 2/10    \n",
      "    1/1 - 0s - loss: 0.5939 - accuracy: 0.6042 - MCC: 0.2520 - UnbiasedMCC: 0.0000e+00 - confusion_matrix: 12.0000 - BrierScore: 0.4028 - CustomLoss: 0.8420 - val_loss: 0.5260 - val_accuracy: 0.7215 - val_MCC: 0.0000e+00 - val_UnbiasedMCC: 0.0000e+00 - val_confusion_matrix: 19.7500 - val_BrierScore: 0.4403 - val_CustomLoss: 0.0954\n",
      "    \n",
      "    Epoch 00002: saving model to ./models/tests/test9/1--training_epochs__2--u__10/fold_2/cp-0002.ckpt    \n",
      "    Epoch 3/10    \n",
      "    1/1 - 0s - loss: 0.5424 - accuracy: 0.6667 - MCC: 0.3703 - UnbiasedMCC: 0.0000e+00 - confusion_matrix: 12.0000 - BrierScore: 0.3997 - CustomLoss: 0.7738 - val_loss: 0.4862 - val_accuracy: 0.7595 - val_MCC: 0.0000e+00 - val_UnbiasedMCC: 0.0000e+00 - val_confusion_matrix: 19.7500 - val_BrierScore: 0.4449 - val_CustomLoss: 0.0876\n",
      "    \n",
      "    Epoch 00003: saving model to ./models/tests/test9/1--training_epochs__2--u__10/fold_2/cp-0003.ckpt    \n",
      "    Epoch 4/10    \n",
      "    1/1 - 0s - loss: 0.4977 - accuracy: 0.7500 - MCC: 0.5205 - UnbiasedMCC: 0.0000e+00 - confusion_matrix: 12.0000 - BrierScore: 0.3963 - CustomLoss: 0.7105 - val_loss: 0.4526 - val_accuracy: 0.7595 - val_MCC: 0.0000e+00 - val_UnbiasedMCC: 0.0000e+00 - val_confusion_matrix: 19.7500 - val_BrierScore: 0.4488 - val_CustomLoss: 0.0812\n",
      "    \n",
      "    Epoch 00004: saving model to ./models/tests/test9/1--training_epochs__2--u__10/fold_2/cp-0004.ckpt    \n",
      "    Epoch 5/10    \n",
      "    1/1 - 0s - loss: 0.4588 - accuracy: 0.7917 - MCC: 0.6058 - UnbiasedMCC: 0.1802 - confusion_matrix: 12.0000 - BrierScore: 0.3932 - CustomLoss: 0.6521 - val_loss: 0.4242 - val_accuracy: 0.7848 - val_MCC: 0.0000e+00 - val_UnbiasedMCC: 0.0000e+00 - val_confusion_matrix: 19.7500 - val_BrierScore: 0.4521 - val_CustomLoss: 0.0759\n",
      "    \n",
      "    Epoch 00005: saving model to ./models/tests/test9/1--training_epochs__2--u__10/fold_2/cp-0005.ckpt    \n",
      "    Epoch 6/10    \n",
      "    1/1 - 0s - loss: 0.4248 - accuracy: 0.8333 - MCC: 0.7138 - UnbiasedMCC: 0.1802 - confusion_matrix: 12.0000 - BrierScore: 0.3905 - CustomLoss: 0.5987 - val_loss: 0.4000 - val_accuracy: 0.8101 - val_MCC: 0.0000e+00 - val_UnbiasedMCC: 0.0000e+00 - val_confusion_matrix: 19.7500 - val_BrierScore: 0.4549 - val_CustomLoss: 0.0715\n",
      "    \n",
      "    Epoch 00006: saving model to ./models/tests/test9/1--training_epochs__2--u__10/fold_2/cp-0006.ckpt    \n",
      "    Epoch 7/10    \n",
      "    1/1 - 0s - loss: 0.3949 - accuracy: 0.8542 - MCC: 0.7446 - UnbiasedMCC: 0.2576 - confusion_matrix: 12.0000 - BrierScore: 0.3884 - CustomLoss: 0.5500 - val_loss: 0.3791 - val_accuracy: 0.8101 - val_MCC: 0.0000e+00 - val_UnbiasedMCC: 0.0000e+00 - val_confusion_matrix: 19.7500 - val_BrierScore: 0.4573 - val_CustomLoss: 0.0678\n",
      "    \n",
      "    Epoch 00007: saving model to ./models/tests/test9/1--training_epochs__2--u__10/fold_2/cp-0007.ckpt    \n",
      "    Epoch 8/10    \n",
      "    1/1 - 0s - loss: 0.3682 - accuracy: 0.8750 - MCC: 0.7764 - UnbiasedMCC: 0.4670 - confusion_matrix: 12.0000 - BrierScore: 0.3870 - CustomLoss: 0.5060 - val_loss: 0.3609 - val_accuracy: 0.7975 - val_MCC: 0.0000e+00 - val_UnbiasedMCC: 0.0000e+00 - val_confusion_matrix: 19.7500 - val_BrierScore: 0.4594 - val_CustomLoss: 0.0645\n",
      "    \n",
      "    Epoch 00008: saving model to ./models/tests/test9/1--training_epochs__2--u__10/fold_2/cp-0008.ckpt    \n",
      "    Epoch 9/10    \n",
      "    1/1 - 0s - loss: 0.3444 - accuracy: 0.8750 - MCC: 0.7764 - UnbiasedMCC: 0.4670 - confusion_matrix: 12.0000 - BrierScore: 0.3864 - CustomLoss: 0.4663 - val_loss: 0.3448 - val_accuracy: 0.7975 - val_MCC: 0.0000e+00 - val_UnbiasedMCC: 0.0000e+00 - val_confusion_matrix: 19.7500 - val_BrierScore: 0.4612 - val_CustomLoss: 0.0615\n",
      "    \n",
      "    Epoch 00009: saving model to ./models/tests/test9/1--training_epochs__2--u__10/fold_2/cp-0009.ckpt    \n",
      "    Epoch 10/10    \n",
      "    1/1 - 0s - loss: 0.3228 - accuracy: 0.8750 - MCC: 0.7764 - UnbiasedMCC: 0.5105 - confusion_matrix: 12.0000 - BrierScore: 0.3864 - CustomLoss: 0.4306 - val_loss: 0.3303 - val_accuracy: 0.8101 - val_MCC: 0.0000e+00 - val_UnbiasedMCC: 0.0000e+00 - val_confusion_matrix: 19.7500 - val_BrierScore: 0.4628 - val_CustomLoss: 0.0589\n",
      "    \n",
      "    Epoch 00010: saving model to ./models/tests/test9/1--training_epochs__2--u__10/fold_2/cp-0010.ckpt    \n",
      "    INFO:tensorflow:Assets written to: ./models/tests/test9/1--training_epochs__2--u__10/fold_2/assets\n",
      "    Assets written to: ./models/tests/test9/1--training_epochs__2--u__10/fold_2/assets\n",
      "                 loss  accuracy       MCC  UnbiasedMCC  \\\n",
      "    epoch-1                                              \n",
      "    0        0.653340  0.583333  0.198589     0.000000   \n",
      "    1        0.593901  0.604167  0.252034     0.000000   \n",
      "    2        0.542388  0.666667  0.370342     0.000000   \n",
      "    3        0.497716  0.750000  0.520545     0.000000   \n",
      "    4        0.458845  0.791667  0.605821     0.180208   \n",
      "    5        0.424836  0.833333  0.713848     0.180208   \n",
      "    6        0.394869  0.854167  0.744565     0.257607   \n",
      "    7        0.368248  0.875000  0.776375     0.466953   \n",
      "    8        0.344391  0.875000  0.776375     0.466953   \n",
      "    9        0.322829  0.875000  0.776375     0.510481   \n",
      "    \n",
      "                       confusion_matrix  BrierScore  CustomLoss  val_loss  \\\n",
      "    epoch-1                                                                 \n",
      "    0        [[29.0, 0.0], [19.0, 0.0]]    0.405439    0.915009  0.573099   \n",
      "    1        [[29.0, 0.0], [19.0, 0.0]]    0.402799    0.842008  0.525973   \n",
      "    2        [[29.0, 0.0], [19.0, 0.0]]    0.399655    0.773776  0.486188   \n",
      "    3        [[29.0, 0.0], [19.0, 0.0]]    0.396349    0.710455  0.452626   \n",
      "    4        [[29.0, 0.0], [18.0, 1.0]]    0.393208    0.652103  0.424216   \n",
      "    5        [[29.0, 0.0], [18.0, 1.0]]    0.390499    0.598674  0.399983   \n",
      "    6        [[29.0, 0.0], [17.0, 2.0]]    0.388411    0.550041  0.379095   \n",
      "    7        [[29.0, 0.0], [13.0, 6.0]]    0.387039    0.505995  0.360870   \n",
      "    8        [[29.0, 0.0], [13.0, 6.0]]    0.386398    0.466272  0.344762   \n",
      "    9        [[29.0, 0.0], [12.0, 7.0]]    0.386445    0.430560  0.330337   \n",
      "    \n",
      "             val_accuracy  val_MCC  val_UnbiasedMCC       val_confusion_matrix  \\\n",
      "    epoch-1                                                                      \n",
      "    0            0.721519      0.0              0.0  [[77.0, 2.0], [0.0, 0.0]]   \n",
      "    1            0.721519      0.0              0.0  [[77.0, 2.0], [0.0, 0.0]]   \n",
      "    2            0.759494      0.0              0.0  [[78.0, 1.0], [0.0, 0.0]]   \n",
      "    3            0.759494      0.0              0.0  [[78.0, 1.0], [0.0, 0.0]]   \n",
      "    4            0.784810      0.0              0.0  [[78.0, 1.0], [0.0, 0.0]]   \n",
      "    5            0.810127      0.0              0.0  [[78.0, 1.0], [0.0, 0.0]]   \n",
      "    6            0.810127      0.0              0.0  [[78.0, 1.0], [0.0, 0.0]]   \n",
      "    7            0.797468      0.0              0.0  [[78.0, 1.0], [0.0, 0.0]]   \n",
      "    8            0.797468      0.0              0.0  [[78.0, 1.0], [0.0, 0.0]]   \n",
      "    9            0.810127      0.0              0.0  [[78.0, 1.0], [0.0, 0.0]]   \n",
      "    \n",
      "             val_BrierScore  val_CustomLoss  \n",
      "    epoch-1                                  \n",
      "    0              0.434863        0.105097  \n",
      "    1              0.440261        0.095400  \n",
      "    2              0.444865        0.087570  \n",
      "    3              0.448768        0.081197  \n",
      "    4              0.452073        0.075944  \n",
      "    5              0.454882        0.071539  \n",
      "    6              0.457287        0.067770  \n",
      "    7              0.459367        0.064476  \n",
      "    8              0.461185        0.061539  \n",
      "    9              0.462795        0.058873  \n",
      "    score = 0.05887266993522644\n",
      "  train_model: completed in 4.0 s\n",
      "  RAM memory: 3.979e+11\n",
      "  =============\n",
      "  fold 3 (4/5)\n",
      "  =============\n",
      "  k_fold_cross_val_split:\n",
      "  k_fold_cross_val_split: completed in 0.0 s\n",
      "  number of training data before undersampling: 316 of which 297 negative and 19 positive\n",
      "  number of training data: 48 of which 29 negative and 19 positive\n",
      "  0.0000\\% of the data have non zero std below 1e-4\n",
      "  X_tr.shape = (48, 64, 128, 1), X_va.shape = (79, 64, 128, 1)\n",
      "  WARNING:tensorflow:Unable to restore custom metric. Please ensure that the layer implements `get_config` and `from_config` when saving. In addition, please use the `custom_objects` arg when calling `load_model()`.\n",
      "  Unable to restore custom metric. Please ensure that the layer implements `get_config` and `from_config` when saving. In addition, please use the `custom_objects` arg when calling `load_model()`.\n",
      "  WARNING:tensorflow:Unable to restore custom metric. Please ensure that the layer implements `get_config` and `from_config` when saving. In addition, please use the `custom_objects` arg when calling `load_model()`.\n",
      "  Unable to restore custom metric. Please ensure that the layer implements `get_config` and `from_config` when saving. In addition, please use the `custom_objects` arg when calling `load_model()`.\n",
      "  WARNING:tensorflow:Unable to restore custom metric. Please ensure that the layer implements `get_config` and `from_config` when saving. In addition, please use the `custom_objects` arg when calling `load_model()`.\n",
      "  Unable to restore custom metric. Please ensure that the layer implements `get_config` and `from_config` when saving. In addition, please use the `custom_objects` arg when calling `load_model()`.\n",
      "  WARNING:tensorflow:Unable to restore custom metric. Please ensure that the layer implements `get_config` and `from_config` when saving. In addition, please use the `custom_objects` arg when calling `load_model()`.\n",
      "  Unable to restore custom metric. Please ensure that the layer implements `get_config` and `from_config` when saving. In addition, please use the `custom_objects` arg when calling `load_model()`.\n",
      "  WARNING:tensorflow:Unable to restore custom metric. Please ensure that the layer implements `get_config` and `from_config` when saving. In addition, please use the `custom_objects` arg when calling `load_model()`.\n",
      "  Unable to restore custom metric. Please ensure that the layer implements `get_config` and `from_config` when saving. In addition, please use the `custom_objects` arg when calling `load_model()`.\n",
      "  \n",
      "  Model: \"sequential\"\n",
      "  _________________________________________________________________\n",
      "  Layer (type)                 Output Shape              Param #   \n",
      "  =================================================================\n",
      "  flatten (Flatten)            (None, 8192)              0         \n",
      "  _________________________________________________________________\n",
      "  dense (Dense)                (None, 2)                 16386     \n",
      "  =================================================================\n",
      "  Total params: 16,386\n",
      "  Trainable params: 16,386\n",
      "  Non-trainable params: 0\n",
      "  _________________________________________________________________\n",
      "  \n",
      "  Using sparse_categorical_crossentropy loss\n",
      "  train_model:\n",
      "    Converting training data to tensors\n",
      "    Converting validation data to tensors\n",
      "    Training the network on 48 datapoint and validating on 79\n",
      "    Epoch 1/10    \n",
      "    1/1 - 1s - loss: 0.4426 - accuracy: 0.8542 - MCC: 0.7089 - UnbiasedMCC: 0.1802 - confusion_matrix: 12.0000 - BrierScore: 0.4041 - CustomLoss: 0.6863 - val_loss: 0.5280 - val_accuracy: 0.7342 - val_MCC: 0.0000e+00 - val_UnbiasedMCC: 0.0000e+00 - val_confusion_matrix: 19.7500 - val_BrierScore: 0.4375 - val_CustomLoss: 0.0798\n",
      "    \n",
      "    Epoch 00001: saving model to ./models/tests/test9/1--training_epochs__2--u__10/fold_3/cp-0001.ckpt    \n",
      "    Epoch 2/10    \n",
      "    1/1 - 0s - loss: 0.3925 - accuracy: 0.8750 - MCC: 0.7586 - UnbiasedMCC: 0.3190 - confusion_matrix: 12.0000 - BrierScore: 0.4015 - CustomLoss: 0.6164 - val_loss: 0.4925 - val_accuracy: 0.7595 - val_MCC: 0.0000e+00 - val_UnbiasedMCC: 0.0000e+00 - val_confusion_matrix: 19.7500 - val_BrierScore: 0.4417 - val_CustomLoss: 0.0731\n",
      "    \n",
      "    Epoch 00002: saving model to ./models/tests/test9/1--training_epochs__2--u__10/fold_3/cp-0002.ckpt    \n",
      "    Epoch 3/10    \n",
      "    1/1 - 0s - loss: 0.3506 - accuracy: 0.8958 - MCC: 0.7944 - UnbiasedMCC: 0.3725 - confusion_matrix: 12.0000 - BrierScore: 0.3992 - CustomLoss: 0.5528 - val_loss: 0.4637 - val_accuracy: 0.7595 - val_MCC: 0.0000e+00 - val_UnbiasedMCC: 0.0000e+00 - val_confusion_matrix: 19.7500 - val_BrierScore: 0.4452 - val_CustomLoss: 0.0680\n",
      "    \n",
      "    Epoch 00003: saving model to ./models/tests/test9/1--training_epochs__2--u__10/fold_3/cp-0003.ckpt    \n",
      "    Epoch 4/10    \n",
      "    1/1 - 0s - loss: 0.3155 - accuracy: 0.9375 - MCC: 0.8799 - UnbiasedMCC: 0.3725 - confusion_matrix: 12.0000 - BrierScore: 0.3975 - CustomLoss: 0.4955 - val_loss: 0.4403 - val_accuracy: 0.7595 - val_MCC: 0.0000e+00 - val_UnbiasedMCC: 0.0000e+00 - val_confusion_matrix: 19.7500 - val_BrierScore: 0.4480 - val_CustomLoss: 0.0641\n",
      "    \n",
      "    Epoch 00004: saving model to ./models/tests/test9/1--training_epochs__2--u__10/fold_3/cp-0004.ckpt    \n",
      "    Epoch 5/10    \n",
      "    1/1 - 0s - loss: 0.2857 - accuracy: 0.9375 - MCC: 0.8799 - UnbiasedMCC: 0.4213 - confusion_matrix: 12.0000 - BrierScore: 0.3965 - CustomLoss: 0.4445 - val_loss: 0.4212 - val_accuracy: 0.7848 - val_MCC: 0.0000e+00 - val_UnbiasedMCC: 0.0000e+00 - val_confusion_matrix: 19.7500 - val_BrierScore: 0.4503 - val_CustomLoss: 0.0610\n",
      "    \n",
      "    Epoch 00005: saving model to ./models/tests/test9/1--training_epochs__2--u__10/fold_3/cp-0005.ckpt    \n",
      "    Epoch 6/10    \n",
      "    1/1 - 0s - loss: 0.2601 - accuracy: 0.9583 - MCC: 0.9178 - UnbiasedMCC: 0.4213 - confusion_matrix: 12.0000 - BrierScore: 0.3962 - CustomLoss: 0.3991 - val_loss: 0.4050 - val_accuracy: 0.8101 - val_MCC: 0.0000e+00 - val_UnbiasedMCC: 0.0000e+00 - val_confusion_matrix: 19.7500 - val_BrierScore: 0.4523 - val_CustomLoss: 0.0585\n",
      "    \n",
      "    Epoch 00006: saving model to ./models/tests/test9/1--training_epochs__2--u__10/fold_3/cp-0006.ckpt    \n",
      "    Epoch 7/10    \n",
      "    1/1 - 0s - loss: 0.2379 - accuracy: 0.9583 - MCC: 0.9178 - UnbiasedMCC: 0.4670 - confusion_matrix: 12.0000 - BrierScore: 0.3967 - CustomLoss: 0.3589 - val_loss: 0.3911 - val_accuracy: 0.8228 - val_MCC: 0.0000e+00 - val_UnbiasedMCC: 0.0000e+00 - val_confusion_matrix: 19.7500 - val_BrierScore: 0.4540 - val_CustomLoss: 0.0564\n",
      "    \n",
      "    Epoch 00007: saving model to ./models/tests/test9/1--training_epochs__2--u__10/fold_3/cp-0007.ckpt    \n",
      "    Epoch 8/10    \n",
      "    1/1 - 0s - loss: 0.2183 - accuracy: 0.9792 - MCC: 0.9577 - UnbiasedMCC: 0.5525 - confusion_matrix: 12.0000 - BrierScore: 0.3979 - CustomLoss: 0.3235 - val_loss: 0.3787 - val_accuracy: 0.8228 - val_MCC: 0.0000e+00 - val_UnbiasedMCC: 0.0000e+00 - val_confusion_matrix: 19.7500 - val_BrierScore: 0.4555 - val_CustomLoss: 0.0546\n",
      "    \n",
      "    Epoch 00008: saving model to ./models/tests/test9/1--training_epochs__2--u__10/fold_3/cp-0008.ckpt    \n",
      "    Epoch 9/10    \n",
      "    1/1 - 0s - loss: 0.2011 - accuracy: 0.9792 - MCC: 0.9577 - UnbiasedMCC: 0.6736 - confusion_matrix: 12.0000 - BrierScore: 0.3996 - CustomLoss: 0.2922 - val_loss: 0.3676 - val_accuracy: 0.8228 - val_MCC: 0.0000e+00 - val_UnbiasedMCC: 0.0000e+00 - val_confusion_matrix: 19.7500 - val_BrierScore: 0.4568 - val_CustomLoss: 0.0530\n",
      "    \n",
      "    Epoch 00009: saving model to ./models/tests/test9/1--training_epochs__2--u__10/fold_3/cp-0009.ckpt    \n",
      "    Epoch 10/10    \n",
      "    1/1 - 0s - loss: 0.1857 - accuracy: 0.9792 - MCC: 0.9577 - UnbiasedMCC: 0.6736 - confusion_matrix: 12.0000 - BrierScore: 0.4019 - CustomLoss: 0.2646 - val_loss: 0.3574 - val_accuracy: 0.8354 - val_MCC: 0.0000e+00 - val_UnbiasedMCC: 0.0000e+00 - val_confusion_matrix: 19.7500 - val_BrierScore: 0.4580 - val_CustomLoss: 0.0516\n",
      "    \n",
      "    Epoch 00010: saving model to ./models/tests/test9/1--training_epochs__2--u__10/fold_3/cp-0010.ckpt    \n",
      "    INFO:tensorflow:Assets written to: ./models/tests/test9/1--training_epochs__2--u__10/fold_3/assets\n",
      "    Assets written to: ./models/tests/test9/1--training_epochs__2--u__10/fold_3/assets\n",
      "                 loss  accuracy       MCC  UnbiasedMCC  \\\n",
      "    epoch-1                                              \n",
      "    0        0.442582  0.854167  0.708940     0.180208   \n",
      "    1        0.392519  0.875000  0.758609     0.318990   \n",
      "    2        0.350640  0.895833  0.794440     0.372500   \n",
      "    3        0.315514  0.937500  0.879940     0.372500   \n",
      "    4        0.285733  0.937500  0.879940     0.421282   \n",
      "    5        0.260144  0.958333  0.917804     0.421282   \n",
      "    6        0.237888  0.958333  0.917804     0.466953   \n",
      "    7        0.218349  0.979167  0.957727     0.552506   \n",
      "    8        0.201079  0.979167  0.957727     0.673624   \n",
      "    9        0.185741  0.979167  0.957727     0.673624   \n",
      "    \n",
      "                       confusion_matrix  BrierScore  CustomLoss  val_loss  \\\n",
      "    epoch-1                                                                 \n",
      "    0        [[29.0, 0.0], [18.0, 1.0]]    0.404082    0.686279  0.528012   \n",
      "    1        [[29.0, 0.0], [16.0, 3.0]]    0.401502    0.616405  0.492462   \n",
      "    2        [[29.0, 0.0], [15.0, 4.0]]    0.399214    0.552795  0.463685   \n",
      "    3        [[29.0, 0.0], [15.0, 4.0]]    0.397502    0.495549  0.440346   \n",
      "    4        [[29.0, 0.0], [14.0, 5.0]]    0.396499    0.444462  0.421156   \n",
      "    5        [[29.0, 0.0], [14.0, 5.0]]    0.396244    0.399099  0.405009   \n",
      "    6        [[29.0, 0.0], [13.0, 6.0]]    0.396719    0.358940  0.391062   \n",
      "    7        [[29.0, 0.0], [11.0, 8.0]]    0.397871    0.323463  0.378723   \n",
      "    8        [[29.0, 0.0], [8.0, 11.0]]    0.399619    0.292174  0.367587   \n",
      "    9        [[29.0, 0.0], [8.0, 11.0]]    0.401873    0.264612  0.357370   \n",
      "    \n",
      "             val_accuracy  val_MCC  val_UnbiasedMCC       val_confusion_matrix  \\\n",
      "    epoch-1                                                                      \n",
      "    0            0.734177      0.0              0.0  [[79.0, 0.0], [0.0, 0.0]]   \n",
      "    1            0.759494      0.0              0.0  [[79.0, 0.0], [0.0, 0.0]]   \n",
      "    2            0.759494      0.0              0.0  [[79.0, 0.0], [0.0, 0.0]]   \n",
      "    3            0.759494      0.0              0.0  [[79.0, 0.0], [0.0, 0.0]]   \n",
      "    4            0.784810      0.0              0.0  [[79.0, 0.0], [0.0, 0.0]]   \n",
      "    5            0.810127      0.0              0.0  [[79.0, 0.0], [0.0, 0.0]]   \n",
      "    6            0.822785      0.0              0.0  [[79.0, 0.0], [0.0, 0.0]]   \n",
      "    7            0.822785      0.0              0.0  [[79.0, 0.0], [0.0, 0.0]]   \n",
      "    8            0.822785      0.0              0.0  [[79.0, 0.0], [0.0, 0.0]]   \n",
      "    9            0.835443      0.0              0.0  [[79.0, 0.0], [0.0, 0.0]]   \n",
      "    \n",
      "             val_BrierScore  val_CustomLoss  \n",
      "    epoch-1                                  \n",
      "    0              0.437457        0.079824  \n",
      "    1              0.441701        0.073122  \n",
      "    2              0.445165        0.068000  \n",
      "    3              0.447992        0.064070  \n",
      "    4              0.450322        0.060992  \n",
      "    5              0.452284        0.058504  \n",
      "    6              0.453976        0.056420  \n",
      "    7              0.455469        0.054620  \n",
      "    8              0.456812        0.053025  \n",
      "    9              0.458039        0.051581  \n",
      "    score = 0.05158127471804619\n",
      "  train_model: completed in 4.6 s\n",
      "  RAM memory: 3.979e+11\n",
      "  =============\n",
      "  fold 4 (5/5)\n",
      "  =============\n",
      "  k_fold_cross_val_split:\n",
      "  k_fold_cross_val_split: completed in 0.0 s\n",
      "  number of training data before undersampling: 316 of which 297 negative and 19 positive\n",
      "  number of training data: 48 of which 29 negative and 19 positive\n",
      "  0.0000\\% of the data have non zero std below 1e-4\n",
      "  X_tr.shape = (48, 64, 128, 1), X_va.shape = (79, 64, 128, 1)\n",
      "  WARNING:tensorflow:Unable to restore custom metric. Please ensure that the layer implements `get_config` and `from_config` when saving. In addition, please use the `custom_objects` arg when calling `load_model()`.\n",
      "  Unable to restore custom metric. Please ensure that the layer implements `get_config` and `from_config` when saving. In addition, please use the `custom_objects` arg when calling `load_model()`.\n",
      "  WARNING:tensorflow:Unable to restore custom metric. Please ensure that the layer implements `get_config` and `from_config` when saving. In addition, please use the `custom_objects` arg when calling `load_model()`.\n",
      "  Unable to restore custom metric. Please ensure that the layer implements `get_config` and `from_config` when saving. In addition, please use the `custom_objects` arg when calling `load_model()`.\n",
      "  WARNING:tensorflow:Unable to restore custom metric. Please ensure that the layer implements `get_config` and `from_config` when saving. In addition, please use the `custom_objects` arg when calling `load_model()`.\n",
      "  Unable to restore custom metric. Please ensure that the layer implements `get_config` and `from_config` when saving. In addition, please use the `custom_objects` arg when calling `load_model()`.\n",
      "  WARNING:tensorflow:Unable to restore custom metric. Please ensure that the layer implements `get_config` and `from_config` when saving. In addition, please use the `custom_objects` arg when calling `load_model()`.\n",
      "  Unable to restore custom metric. Please ensure that the layer implements `get_config` and `from_config` when saving. In addition, please use the `custom_objects` arg when calling `load_model()`.\n",
      "  WARNING:tensorflow:Unable to restore custom metric. Please ensure that the layer implements `get_config` and `from_config` when saving. In addition, please use the `custom_objects` arg when calling `load_model()`.\n",
      "  Unable to restore custom metric. Please ensure that the layer implements `get_config` and `from_config` when saving. In addition, please use the `custom_objects` arg when calling `load_model()`.\n",
      "  \n",
      "  Model: \"sequential\"\n",
      "  _________________________________________________________________\n",
      "  Layer (type)                 Output Shape              Param #   \n",
      "  =================================================================\n",
      "  flatten (Flatten)            (None, 8192)              0         \n",
      "  _________________________________________________________________\n",
      "  dense (Dense)                (None, 2)                 16386     \n",
      "  =================================================================\n",
      "  Total params: 16,386\n",
      "  Trainable params: 16,386\n",
      "  Non-trainable params: 0\n",
      "  _________________________________________________________________\n",
      "  \n",
      "  Using sparse_categorical_crossentropy loss\n",
      "  train_model:\n",
      "    Converting training data to tensors\n",
      "    Converting validation data to tensors\n",
      "    Training the network on 48 datapoint and validating on 79\n",
      "    Epoch 1/10    \n",
      "    1/1 - 1s - loss: 0.4196 - accuracy: 0.9167 - MCC: 0.8439 - UnbiasedMCC: 0.0000e+00 - confusion_matrix: 12.0000 - BrierScore: 0.4014 - CustomLoss: 0.6604 - val_loss: 0.3916 - val_accuracy: 0.8608 - val_MCC: 0.0000e+00 - val_UnbiasedMCC: 0.0000e+00 - val_confusion_matrix: 19.7500 - val_BrierScore: 0.4544 - val_CustomLoss: 0.0543\n",
      "    \n",
      "    Epoch 00001: saving model to ./models/tests/test9/1--training_epochs__2--u__10/fold_4/cp-0001.ckpt    \n",
      "    Epoch 2/10    \n",
      "    1/1 - 0s - loss: 0.3814 - accuracy: 0.9375 - MCC: 0.8799 - UnbiasedMCC: 0.0000e+00 - confusion_matrix: 12.0000 - BrierScore: 0.3986 - CustomLoss: 0.6048 - val_loss: 0.3525 - val_accuracy: 0.8608 - val_MCC: 0.0000e+00 - val_UnbiasedMCC: 0.0000e+00 - val_confusion_matrix: 19.7500 - val_BrierScore: 0.4592 - val_CustomLoss: 0.0477\n",
      "    \n",
      "    Epoch 00002: saving model to ./models/tests/test9/1--training_epochs__2--u__10/fold_4/cp-0002.ckpt    \n",
      "    Epoch 3/10    \n",
      "    1/1 - 0s - loss: 0.3498 - accuracy: 0.9375 - MCC: 0.8799 - UnbiasedMCC: 0.1802 - confusion_matrix: 12.0000 - BrierScore: 0.3961 - CustomLoss: 0.5545 - val_loss: 0.3209 - val_accuracy: 0.8608 - val_MCC: 0.0000e+00 - val_UnbiasedMCC: 0.0000e+00 - val_confusion_matrix: 19.7500 - val_BrierScore: 0.4631 - val_CustomLoss: 0.0426\n",
      "    \n",
      "    Epoch 00003: saving model to ./models/tests/test9/1--training_epochs__2--u__10/fold_4/cp-0003.ckpt    \n",
      "    Epoch 4/10    \n",
      "    1/1 - 0s - loss: 0.3234 - accuracy: 0.9375 - MCC: 0.8799 - UnbiasedMCC: 0.1802 - confusion_matrix: 12.0000 - BrierScore: 0.3940 - CustomLoss: 0.5092 - val_loss: 0.2956 - val_accuracy: 0.8734 - val_MCC: 0.0000e+00 - val_UnbiasedMCC: 0.0000e+00 - val_confusion_matrix: 19.7500 - val_BrierScore: 0.4662 - val_CustomLoss: 0.0387\n",
      "    \n",
      "    Epoch 00004: saving model to ./models/tests/test9/1--training_epochs__2--u__10/fold_4/cp-0004.ckpt    \n",
      "    Epoch 5/10    \n",
      "    1/1 - 0s - loss: 0.3011 - accuracy: 0.9375 - MCC: 0.8799 - UnbiasedMCC: 0.4670 - confusion_matrix: 12.0000 - BrierScore: 0.3925 - CustomLoss: 0.4688 - val_loss: 0.2754 - val_accuracy: 0.8861 - val_MCC: 0.0000e+00 - val_UnbiasedMCC: 0.0000e+00 - val_confusion_matrix: 19.7500 - val_BrierScore: 0.4686 - val_CustomLoss: 0.0356\n",
      "    \n",
      "    Epoch 00005: saving model to ./models/tests/test9/1--training_epochs__2--u__10/fold_4/cp-0005.ckpt    \n",
      "    Epoch 6/10    \n",
      "    1/1 - 0s - loss: 0.2819 - accuracy: 0.9375 - MCC: 0.8799 - UnbiasedMCC: 0.4670 - confusion_matrix: 12.0000 - BrierScore: 0.3916 - CustomLoss: 0.4328 - val_loss: 0.2593 - val_accuracy: 0.8861 - val_MCC: 0.0000e+00 - val_UnbiasedMCC: 0.0000e+00 - val_confusion_matrix: 19.7500 - val_BrierScore: 0.4706 - val_CustomLoss: 0.0332\n",
      "    \n",
      "    Epoch 00006: saving model to ./models/tests/test9/1--training_epochs__2--u__10/fold_4/cp-0006.ckpt    \n",
      "    Epoch 7/10    \n",
      "    1/1 - 0s - loss: 0.2648 - accuracy: 0.9375 - MCC: 0.8799 - UnbiasedMCC: 0.5105 - confusion_matrix: 12.0000 - BrierScore: 0.3913 - CustomLoss: 0.4007 - val_loss: 0.2465 - val_accuracy: 0.9114 - val_MCC: 0.0000e+00 - val_UnbiasedMCC: 0.0000e+00 - val_confusion_matrix: 19.7500 - val_BrierScore: 0.4721 - val_CustomLoss: 0.0314\n",
      "    \n",
      "    Epoch 00007: saving model to ./models/tests/test9/1--training_epochs__2--u__10/fold_4/cp-0007.ckpt    \n",
      "    Epoch 8/10    \n",
      "    1/1 - 0s - loss: 0.2494 - accuracy: 0.9375 - MCC: 0.8799 - UnbiasedMCC: 0.5935 - confusion_matrix: 12.0000 - BrierScore: 0.3916 - CustomLoss: 0.3723 - val_loss: 0.2363 - val_accuracy: 0.9367 - val_MCC: 0.0000e+00 - val_UnbiasedMCC: 0.0000e+00 - val_confusion_matrix: 19.7500 - val_BrierScore: 0.4733 - val_CustomLoss: 0.0299\n",
      "    \n",
      "    Epoch 00008: saving model to ./models/tests/test9/1--training_epochs__2--u__10/fold_4/cp-0008.ckpt    \n",
      "    Epoch 9/10    \n",
      "    1/1 - 0s - loss: 0.2352 - accuracy: 0.9375 - MCC: 0.8799 - UnbiasedMCC: 0.5935 - confusion_matrix: 12.0000 - BrierScore: 0.3924 - CustomLoss: 0.3470 - val_loss: 0.2281 - val_accuracy: 0.9367 - val_MCC: 0.0000e+00 - val_UnbiasedMCC: 0.0000e+00 - val_confusion_matrix: 19.7500 - val_BrierScore: 0.4743 - val_CustomLoss: 0.0288\n",
      "    \n",
      "    Epoch 00009: saving model to ./models/tests/test9/1--training_epochs__2--u__10/fold_4/cp-0009.ckpt    \n",
      "    Epoch 10/10    \n",
      "    1/1 - 0s - loss: 0.2220 - accuracy: 0.9375 - MCC: 0.8799 - UnbiasedMCC: 0.5935 - confusion_matrix: 12.0000 - BrierScore: 0.3935 - CustomLoss: 0.3244 - val_loss: 0.2216 - val_accuracy: 0.9367 - val_MCC: 0.0000e+00 - val_UnbiasedMCC: 0.0000e+00 - val_confusion_matrix: 19.7500 - val_BrierScore: 0.4750 - val_CustomLoss: 0.0279\n",
      "    \n",
      "    Epoch 00010: saving model to ./models/tests/test9/1--training_epochs__2--u__10/fold_4/cp-0010.ckpt    \n",
      "    INFO:tensorflow:Assets written to: ./models/tests/test9/1--training_epochs__2--u__10/fold_4/assets\n",
      "    Assets written to: ./models/tests/test9/1--training_epochs__2--u__10/fold_4/assets\n",
      "                 loss  accuracy       MCC  UnbiasedMCC  \\\n",
      "    epoch-1                                              \n",
      "    0        0.419580  0.916667  0.843886     0.000000   \n",
      "    1        0.381372  0.937500  0.879940     0.000000   \n",
      "    2        0.349760  0.937500  0.879940     0.180208   \n",
      "    3        0.323421  0.937500  0.879940     0.180208   \n",
      "    4        0.301134  0.937500  0.879940     0.466953   \n",
      "    5        0.281863  0.937500  0.879940     0.466953   \n",
      "    6        0.264798  0.937500  0.879940     0.510481   \n",
      "    7        0.249357  0.937500  0.879940     0.593487   \n",
      "    8        0.235160  0.937500  0.879940     0.593487   \n",
      "    9        0.221984  0.937500  0.879940     0.593487   \n",
      "    \n",
      "                       confusion_matrix  BrierScore  CustomLoss  val_loss  \\\n",
      "    epoch-1                                                                 \n",
      "    0        [[29.0, 0.0], [19.0, 0.0]]    0.401413    0.660413  0.391617   \n",
      "    1        [[29.0, 0.0], [19.0, 0.0]]    0.398621    0.604829  0.352491   \n",
      "    2        [[29.0, 0.0], [18.0, 1.0]]    0.396068    0.554471  0.320902   \n",
      "    3        [[29.0, 0.0], [18.0, 1.0]]    0.393973    0.509222  0.295587   \n",
      "    4        [[29.0, 0.0], [13.0, 6.0]]    0.392457    0.468782  0.275371   \n",
      "    5        [[29.0, 0.0], [13.0, 6.0]]    0.391572    0.432756  0.259270   \n",
      "    6        [[29.0, 0.0], [12.0, 7.0]]    0.391307    0.400725  0.246460   \n",
      "    7        [[29.0, 0.0], [10.0, 9.0]]    0.391602    0.372265  0.236269   \n",
      "    8        [[29.0, 0.0], [10.0, 9.0]]    0.392364    0.346962  0.228146   \n",
      "    9        [[29.0, 0.0], [10.0, 9.0]]    0.393496    0.324423  0.221640   \n",
      "    \n",
      "             val_accuracy  val_MCC  val_UnbiasedMCC       val_confusion_matrix  \\\n",
      "    epoch-1                                                                      \n",
      "    0            0.860759      0.0              0.0  [[79.0, 0.0], [0.0, 0.0]]   \n",
      "    1            0.860759      0.0              0.0  [[79.0, 0.0], [0.0, 0.0]]   \n",
      "    2            0.860759      0.0              0.0  [[79.0, 0.0], [0.0, 0.0]]   \n",
      "    3            0.873418      0.0              0.0  [[79.0, 0.0], [0.0, 0.0]]   \n",
      "    4            0.886076      0.0              0.0  [[79.0, 0.0], [0.0, 0.0]]   \n",
      "    5            0.886076      0.0              0.0  [[79.0, 0.0], [0.0, 0.0]]   \n",
      "    6            0.911392      0.0              0.0  [[79.0, 0.0], [0.0, 0.0]]   \n",
      "    7            0.936709      0.0              0.0  [[79.0, 0.0], [0.0, 0.0]]   \n",
      "    8            0.936709      0.0              0.0  [[79.0, 0.0], [0.0, 0.0]]   \n",
      "    9            0.936709      0.0              0.0  [[79.0, 0.0], [0.0, 0.0]]   \n",
      "    \n",
      "             val_BrierScore  val_CustomLoss  \n",
      "    epoch-1                                  \n",
      "    0              0.454409        0.054306  \n",
      "    1              0.459247        0.047726  \n",
      "    2              0.463114        0.042635  \n",
      "    3              0.466189        0.038690  \n",
      "    4              0.468628        0.035623  \n",
      "    5              0.470561        0.033234  \n",
      "    6              0.472091        0.031369  \n",
      "    7              0.473304        0.029910  \n",
      "    8              0.474267        0.028768  \n",
      "    9              0.475034        0.027871  \n",
      "    score = 0.02787134237587452\n",
      "  train_model: completed in 4.7 s\n",
      "  RAM memory: 3.979e+11\n",
      "  recomputing scores and network predictions with the collective optimal checkpoint\n",
      "  k_fold_cross_val_split:\n",
      "  k_fold_cross_val_split: completed in 0.0 s\n",
      "  WARNING:tensorflow:Unable to restore custom metric. Please ensure that the layer implements `get_config` and `from_config` when saving. In addition, please use the `custom_objects` arg when calling `load_model()`.\n",
      "  Unable to restore custom metric. Please ensure that the layer implements `get_config` and `from_config` when saving. In addition, please use the `custom_objects` arg when calling `load_model()`.\n",
      "  WARNING:tensorflow:Unable to restore custom metric. Please ensure that the layer implements `get_config` and `from_config` when saving. In addition, please use the `custom_objects` arg when calling `load_model()`.\n",
      "  Unable to restore custom metric. Please ensure that the layer implements `get_config` and `from_config` when saving. In addition, please use the `custom_objects` arg when calling `load_model()`.\n",
      "  WARNING:tensorflow:Unable to restore custom metric. Please ensure that the layer implements `get_config` and `from_config` when saving. In addition, please use the `custom_objects` arg when calling `load_model()`.\n",
      "  Unable to restore custom metric. Please ensure that the layer implements `get_config` and `from_config` when saving. In addition, please use the `custom_objects` arg when calling `load_model()`.\n",
      "  WARNING:tensorflow:Unable to restore custom metric. Please ensure that the layer implements `get_config` and `from_config` when saving. In addition, please use the `custom_objects` arg when calling `load_model()`.\n",
      "  Unable to restore custom metric. Please ensure that the layer implements `get_config` and `from_config` when saving. In addition, please use the `custom_objects` arg when calling `load_model()`.\n",
      "  WARNING:tensorflow:Unable to restore custom metric. Please ensure that the layer implements `get_config` and `from_config` when saving. In addition, please use the `custom_objects` arg when calling `load_model()`.\n",
      "  Unable to restore custom metric. Please ensure that the layer implements `get_config` and `from_config` when saving. In addition, please use the `custom_objects` arg when calling `load_model()`.\n",
      "  k_fold_cross_val_split:\n",
      "  k_fold_cross_val_split: completed in 0.0 s\n",
      "  WARNING:tensorflow:Unable to restore custom metric. Please ensure that the layer implements `get_config` and `from_config` when saving. In addition, please use the `custom_objects` arg when calling `load_model()`.\n",
      "  Unable to restore custom metric. Please ensure that the layer implements `get_config` and `from_config` when saving. In addition, please use the `custom_objects` arg when calling `load_model()`.\n",
      "  WARNING:tensorflow:Unable to restore custom metric. Please ensure that the layer implements `get_config` and `from_config` when saving. In addition, please use the `custom_objects` arg when calling `load_model()`.\n",
      "  Unable to restore custom metric. Please ensure that the layer implements `get_config` and `from_config` when saving. In addition, please use the `custom_objects` arg when calling `load_model()`.\n",
      "  WARNING:tensorflow:Unable to restore custom metric. Please ensure that the layer implements `get_config` and `from_config` when saving. In addition, please use the `custom_objects` arg when calling `load_model()`.\n",
      "  Unable to restore custom metric. Please ensure that the layer implements `get_config` and `from_config` when saving. In addition, please use the `custom_objects` arg when calling `load_model()`.\n",
      "  WARNING:tensorflow:Unable to restore custom metric. Please ensure that the layer implements `get_config` and `from_config` when saving. In addition, please use the `custom_objects` arg when calling `load_model()`.\n",
      "  Unable to restore custom metric. Please ensure that the layer implements `get_config` and `from_config` when saving. In addition, please use the `custom_objects` arg when calling `load_model()`.\n",
      "  WARNING:tensorflow:Unable to restore custom metric. Please ensure that the layer implements `get_config` and `from_config` when saving. In addition, please use the `custom_objects` arg when calling `load_model()`.\n",
      "  Unable to restore custom metric. Please ensure that the layer implements `get_config` and `from_config` when saving. In addition, please use the `custom_objects` arg when calling `load_model()`.\n",
      "  k_fold_cross_val_split:\n",
      "  k_fold_cross_val_split: completed in 0.0 s\n",
      "  WARNING:tensorflow:Unable to restore custom metric. Please ensure that the layer implements `get_config` and `from_config` when saving. In addition, please use the `custom_objects` arg when calling `load_model()`.\n",
      "  Unable to restore custom metric. Please ensure that the layer implements `get_config` and `from_config` when saving. In addition, please use the `custom_objects` arg when calling `load_model()`.\n",
      "  WARNING:tensorflow:Unable to restore custom metric. Please ensure that the layer implements `get_config` and `from_config` when saving. In addition, please use the `custom_objects` arg when calling `load_model()`.\n",
      "  Unable to restore custom metric. Please ensure that the layer implements `get_config` and `from_config` when saving. In addition, please use the `custom_objects` arg when calling `load_model()`.\n",
      "  WARNING:tensorflow:Unable to restore custom metric. Please ensure that the layer implements `get_config` and `from_config` when saving. In addition, please use the `custom_objects` arg when calling `load_model()`.\n",
      "  Unable to restore custom metric. Please ensure that the layer implements `get_config` and `from_config` when saving. In addition, please use the `custom_objects` arg when calling `load_model()`.\n",
      "  WARNING:tensorflow:Unable to restore custom metric. Please ensure that the layer implements `get_config` and `from_config` when saving. In addition, please use the `custom_objects` arg when calling `load_model()`.\n",
      "  Unable to restore custom metric. Please ensure that the layer implements `get_config` and `from_config` when saving. In addition, please use the `custom_objects` arg when calling `load_model()`.\n",
      "  WARNING:tensorflow:Unable to restore custom metric. Please ensure that the layer implements `get_config` and `from_config` when saving. In addition, please use the `custom_objects` arg when calling `load_model()`.\n",
      "  Unable to restore custom metric. Please ensure that the layer implements `get_config` and `from_config` when saving. In addition, please use the `custom_objects` arg when calling `load_model()`.\n",
      "  k_fold_cross_val_split:\n",
      "  k_fold_cross_val_split: completed in 0.0 s\n",
      "  WARNING:tensorflow:Unable to restore custom metric. Please ensure that the layer implements `get_config` and `from_config` when saving. In addition, please use the `custom_objects` arg when calling `load_model()`.\n",
      "  Unable to restore custom metric. Please ensure that the layer implements `get_config` and `from_config` when saving. In addition, please use the `custom_objects` arg when calling `load_model()`.\n",
      "  WARNING:tensorflow:Unable to restore custom metric. Please ensure that the layer implements `get_config` and `from_config` when saving. In addition, please use the `custom_objects` arg when calling `load_model()`.\n",
      "  Unable to restore custom metric. Please ensure that the layer implements `get_config` and `from_config` when saving. In addition, please use the `custom_objects` arg when calling `load_model()`.\n",
      "  WARNING:tensorflow:Unable to restore custom metric. Please ensure that the layer implements `get_config` and `from_config` when saving. In addition, please use the `custom_objects` arg when calling `load_model()`.\n",
      "  Unable to restore custom metric. Please ensure that the layer implements `get_config` and `from_config` when saving. In addition, please use the `custom_objects` arg when calling `load_model()`.\n",
      "  WARNING:tensorflow:Unable to restore custom metric. Please ensure that the layer implements `get_config` and `from_config` when saving. In addition, please use the `custom_objects` arg when calling `load_model()`.\n",
      "  Unable to restore custom metric. Please ensure that the layer implements `get_config` and `from_config` when saving. In addition, please use the `custom_objects` arg when calling `load_model()`.\n",
      "  WARNING:tensorflow:Unable to restore custom metric. Please ensure that the layer implements `get_config` and `from_config` when saving. In addition, please use the `custom_objects` arg when calling `load_model()`.\n",
      "  Unable to restore custom metric. Please ensure that the layer implements `get_config` and `from_config` when saving. In addition, please use the `custom_objects` arg when calling `load_model()`.\n",
      "  k_fold_cross_val_split:\n",
      "  k_fold_cross_val_split: completed in 0.0 s\n",
      "  WARNING:tensorflow:Unable to restore custom metric. Please ensure that the layer implements `get_config` and `from_config` when saving. In addition, please use the `custom_objects` arg when calling `load_model()`.\n",
      "  Unable to restore custom metric. Please ensure that the layer implements `get_config` and `from_config` when saving. In addition, please use the `custom_objects` arg when calling `load_model()`.\n",
      "  WARNING:tensorflow:Unable to restore custom metric. Please ensure that the layer implements `get_config` and `from_config` when saving. In addition, please use the `custom_objects` arg when calling `load_model()`.\n",
      "  Unable to restore custom metric. Please ensure that the layer implements `get_config` and `from_config` when saving. In addition, please use the `custom_objects` arg when calling `load_model()`.\n",
      "  WARNING:tensorflow:Unable to restore custom metric. Please ensure that the layer implements `get_config` and `from_config` when saving. In addition, please use the `custom_objects` arg when calling `load_model()`.\n",
      "  Unable to restore custom metric. Please ensure that the layer implements `get_config` and `from_config` when saving. In addition, please use the `custom_objects` arg when calling `load_model()`.\n",
      "  WARNING:tensorflow:Unable to restore custom metric. Please ensure that the layer implements `get_config` and `from_config` when saving. In addition, please use the `custom_objects` arg when calling `load_model()`.\n",
      "  Unable to restore custom metric. Please ensure that the layer implements `get_config` and `from_config` when saving. In addition, please use the `custom_objects` arg when calling `load_model()`.\n",
      "  WARNING:tensorflow:Unable to restore custom metric. Please ensure that the layer implements `get_config` and `from_config` when saving. In addition, please use the `custom_objects` arg when calling `load_model()`.\n",
      "  Unable to restore custom metric. Please ensure that the layer implements `get_config` and `from_config` when saving. In addition, please use the `custom_objects` arg when calling `load_model()`.\n",
      "  \n",
      "  Final scores:\n",
      "  \tfold 0: 0.4814697802066803\n",
      "  \tfold 1: 0.3487742245197296\n",
      "  \tfold 2: 0.0759437158703804\n",
      "  \tfold 3: 0.060992125421762466\n",
      "  \tfold 4: 0.03562306612730026\n",
      "  Average score: 0.20+/-0.18\n",
      "k_fold_cross_val: completed in 25.3 s\n",
      "run completed!!!\n",
      "\n",
      "\n",
      "apollo2048g: \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ALL RUNS COMPLETED\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "t.run_multiple()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading config file from folder ./models/hypop/t7-layers\n",
      "tf.__version__ = '2.4.1'\n",
      "tf.config.list_physical_devices('GPU') = []\n",
      "\n",
      "This machine does not have a GPU: training may be very slow\n",
      "\n",
      "{\n",
      "    \"run_kwargs\": {\n",
      "        \"log_level\": 20,\n",
      "        \"load_data_kwargs\": {\n",
      "            \"dataset_years\": 1000,\n",
      "            \"year_list\": \"range(800)\",\n",
      "            \"sampling\": \"\",\n",
      "            \"Model\": \"CESM\",\n",
      "            \"area\": \"Scandinavia\",\n",
      "            \"filter_area\": \"Scandinavia\",\n",
      "            \"lon_start\": -72,\n",
      "            \"lon_end\": 56,\n",
      "            \"lat_start\": 128,\n",
      "            \"lat_end\": 192,\n",
      "            \"mylocal\": \"/local/gmiloshe/CESM/\",\n",
      "            \"fields\": [\n",
      "                \"t2m\",\n",
      "                \"zg500\",\n",
      "                \"mrso\"\n",
      "            ],\n",
      "            \"preprefix\": \"North_Anomalies_\",\n",
      "            \"datafolder\": \"Data_CESM\"\n",
      "        },\n",
      "        \"prepare_XY_kwargs\": {\n",
      "            \"do_premix\": false,\n",
      "            \"premix_seed\": 0,\n",
      "            \"do_balance_folds\": true,\n",
      "            \"nfolds\": 5,\n",
      "            \"year_permutation\": null,\n",
      "            \"flatten_time_axis\": true,\n",
      "            \"return_time_series\": false,\n",
      "            \"make_XY_kwargs\": {\n",
      "                \"label_field\": \"t2m\",\n",
      "                \"time_start\": 31,\n",
      "                \"time_end\": 123,\n",
      "                \"T\": 14,\n",
      "                \"tau\": 0,\n",
      "                \"percent\": 5,\n",
      "                \"threshold\": null,\n",
      "                \"label_period_start\": null,\n",
      "                \"label_period_end\": null,\n",
      "                \"A_weights\": null,\n",
      "                \"return_threshold\": false\n",
      "            },\n",
      "            \"roll_X_kwargs\": {\n",
      "                \"roll_axis\": \"lon\",\n",
      "                \"roll_steps\": 0\n",
      "            }\n",
      "        },\n",
      "        \"k_fold_cross_val_kwargs\": {\n",
      "            \"load_from\": null,\n",
      "            \"nfolds\": 5,\n",
      "            \"val_folds\": 1,\n",
      "            \"u\": 10,\n",
      "            \"normalization_mode\": \"pointwise\",\n",
      "            \"fullmetrics\": true,\n",
      "            \"training_epochs\": 2,\n",
      "            \"training_epochs_tl\": 2,\n",
      "            \"loss\": \"sparse_categorical_crossentropy\",\n",
      "            \"lr\": 4e-05,\n",
      "            \"prune_threshold\": 0.25,\n",
      "            \"min_folds_before_pruning\": 2,\n",
      "            \"create_model_kwargs\": {\n",
      "                \"conv_channels\": [\n",
      "                    32,\n",
      "                    64,\n",
      "                    64\n",
      "                ],\n",
      "                \"kernel_sizes\": 3,\n",
      "                \"strides\": 1,\n",
      "                \"padding\": \"valid\",\n",
      "                \"batch_normalizations\": true,\n",
      "                \"conv_activations\": \"relu\",\n",
      "                \"conv_dropouts\": 0.3,\n",
      "                \"max_pool_sizes\": [\n",
      "                    2,\n",
      "                    2,\n",
      "                    false\n",
      "                ],\n",
      "                \"conv_l2coef\": 1e-06,\n",
      "                \"dense_units\": [\n",
      "                    64,\n",
      "                    2\n",
      "                ],\n",
      "                \"dense_activations\": [\n",
      "                    \"relu\",\n",
      "                    null\n",
      "                ],\n",
      "                \"dense_dropouts\": [\n",
      "                    0.3,\n",
      "                    false\n",
      "                ],\n",
      "                \"dense_l2coef\": [\n",
      "                    0.001,\n",
      "                    null\n",
      "                ]\n",
      "            },\n",
      "            \"train_model_kwargs\": {\n",
      "                \"enable_early_stopping\": true,\n",
      "                \"u\": 10,\n",
      "                \"batch_size\": 256,\n",
      "                \"checkpoint_every\": 1,\n",
      "                \"additional_callbacks\": [\n",
      "                    \"csv_logger\"\n",
      "                ],\n",
      "                \"return_metric\": \"val_CustomLoss\",\n",
      "                \"early_stopping_kwargs\": {\n",
      "                    \"monitor\": \"val_CustomLoss\",\n",
      "                    \"min_delta\": 0,\n",
      "                    \"patience\": 5,\n",
      "                    \"mode\": \"auto\"\n",
      "                }\n",
      "            },\n",
      "            \"optimal_checkpoint_kwargs\": {\n",
      "                \"metric\": \"val_CustomLoss\",\n",
      "                \"direction\": \"minimize\",\n",
      "                \"first_epoch\": 1,\n",
      "                \"collective\": false,\n",
      "                \"fold_subfolder\": null\n",
      "            }\n",
      "        }\n",
      "    },\n",
      "    \"telegram_kwargs\": {\n",
      "        \"telegram_bot_token\": \"~/ENSMLbot.txt\",\n",
      "        \"chat_ID\": null,\n",
      "        \"telegram_logging_level\": 31,\n",
      "        \"telegram_logging_format\": null\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "work_dir = './models/tests/test10'\n",
    "imoprt_dir = './models/hypop/t7-layers/config.json'\n",
    "t = ln.Trainer(root_folder=work_dir,config=imoprt_dir)\n",
    "d = {\n",
    "    'training_epochs': 2, \n",
    "    'training_epochs_tl': 2}\n",
    "ut.set_values_recursive(t.config_dict, d, inplace=True)\n",
    "print(ut.dict2str(t.config_dict))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scheduling 1 run at default values\n"
     ]
    }
   ],
   "source": [
    "\n",
    "t.schedule()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting 1 run\n",
      "apollo2048g: Run 1/1\n",
      "Models will be trained from scratch\n",
      "folder = '1'\n",
      "\n",
      "{}\n",
      "load_data:\n",
      "  Opening field TSA\n",
      "  First valid path found in /local/gmiloshe/CESM/Data_CESM/North_Anomalies_TSA.nc\n",
      "  monotonize_years:\n",
      "  monotonize_years: completed in 0.6 s\n",
      "  First valid path found in /local/gmiloshe/CESM/Data_CESM/CAM_landmask.nc\n",
      "  First valid path found in /local/gmiloshe/CESM/Data_CESM/CAM_cellarea.nc\n",
      "  select_years:\n",
      "  select_years: completed in 15.0 s\n",
      "  sort_lat:\n",
      "  sort_lat: completed in 0.0 s\n",
      "  select_lonlat:\n",
      "  select_lonlat: completed in 4.1 s\n",
      "  First valid path found in /local/gmiloshe/CESM/Data_CESM/CAM_landmask.nc\n",
      "  Opening field Z3\n",
      "  First valid path found in /local/gmiloshe/CESM/Data_CESM/North_Anomalies_Z3.500hPa.nc\n",
      "  monotonize_years:\n",
      "  monotonize_years: completed in 0.6 s\n",
      "  First valid path found in /local/gmiloshe/CESM/Data_CESM/CAM_landmask.nc\n",
      "  First valid path found in /local/gmiloshe/CESM/Data_CESM/CAM_cellarea.nc\n",
      "  select_years:\n",
      "  select_years: completed in 20.9 s\n",
      "  sort_lat:\n",
      "  sort_lat: completed in 0.0 s\n",
      "  select_lonlat:\n",
      "  select_lonlat: completed in 5.0 s\n",
      "  First valid path found in /local/gmiloshe/CESM/Data_CESM/CAM_landmask.nc\n",
      "  Opening field H2OSOI\n",
      "  First valid path found in /local/gmiloshe/CESM/Data_CESM/North_Anomalies_H2OSOI.nc\n",
      "  monotonize_years:\n",
      "  monotonize_years: completed in 0.7 s\n",
      "  First valid path found in /local/gmiloshe/CESM/Data_CESM/CAM_landmask.nc\n",
      "  First valid path found in /local/gmiloshe/CESM/Data_CESM/CAM_cellarea.nc\n",
      "  select_years:\n",
      "  select_years: completed in 16.9 s\n",
      "  sort_lat:\n",
      "  sort_lat: completed in 0.0 s\n",
      "  select_lonlat:\n",
      "  select_lonlat: completed in 4.1 s\n",
      "  First valid path found in /local/gmiloshe/CESM/Data_CESM/CAM_landmask.nc\n",
      "load_data: completed in 7 min 45.5 s\n",
      "prepare_XY:\n",
      "  return_threshold = False  \n",
      "  make_XY:\n",
      "    make_X:\n",
      "    make_X: completed in 3.8 s\n",
      "    assign_labels:\n",
      "      A_weights = None\n",
      "      compute_time_average:\n",
      "        compute_area_integral:\n",
      "        compute_area_integral: completed in 11.5 s\n",
      "      compute_time_average: completed in 12.5 s\n",
      "      threshold = 3.327819381901467\n",
      "    assign_labels: completed in 12.6 s\n",
      "  make_XY: completed in 16.4 s\n",
      "  roll_X:\n",
      "  roll_X: completed in 0.0 s\n",
      "  Mixing\n",
      "   label_period_start = 31 ;time_start = 31 ;time_end = 123 ;label_period_end = 123 \n",
      "  Y.shape = (800, 79), from 0 to 79 \n",
      "  balance_folds:\n",
      "    Balancing folds\n",
      "    fold 0 done!\n",
      "    fold 1 done!\n",
      "    fold 2 done!\n",
      "    fold 3 done!\n",
      "    fold 4 done!\n",
      "    Sums of the balanced 5 folds:\n",
      "    [632 632 632 632 632]\n",
      "    std/avg = 0.000\n",
      "    max relative deviation = 0.000\\%\n",
      "  balance_folds: completed in 0.1 s\n",
      "  Mixing completed in 3.5 s\n",
      "  \n",
      "  X.shape = (800, 79, 64, 128, 3), Y.shape = (800, 79)\n",
      "  Flattened time: X.shape = (63200, 64, 128, 3), Y.shape = (63200,)\n",
      "prepare_XY: completed in 24.3 s\n",
      "k_fold_cross_val:\n",
      "  Models will be trained from scratch\n",
      "  =============\n",
      "  fold 0 (1/5)\n",
      "  =============\n",
      "  k_fold_cross_val_split:\n",
      "  k_fold_cross_val_split: completed in 2.3 s\n",
      "  number of training data before undersampling: 50560 of which 48032 negative and 2528 positive\n",
      "  number of training data: 7331 of which 4803 negative and 2528 positive\n",
      "  0.0122\\% of the data have non zero std below 1e-4\n",
      "  X_tr.shape = (7331, 64, 128, 3), X_va.shape = (12640, 64, 128, 3)\n",
      "  convolutional args = [[3, 3, 3], [1, 1, 1], [True, True, True], ['relu', 'relu', 'relu'], [0.3, 0.3, 0.3], [2, 2, False], [1e-06, 1e-06, 1e-06], ['valid', 'valid', 'valid']]\n",
      "Run on folder = './models/tests/test10/1' failed due to TypeError(\"Expected string for argument 'padding' not ListWrapper(['valid', 'valid', 'valid']).\")\n",
      "Traceback (most recent call last):\n",
      "  File \"/ClimateDynamics/MediumSpace/ClimateLearningFR/gmiloshe/CESM/../PLASIM/Learn2_new.py\", line 2772, in run\n",
      "    score, info = k_fold_cross_val(folder, self.X, self.Y, **k_fold_cross_val_kwargs)\n",
      "  File \"/ClimateDynamics/MediumSpace/ClimateLearningFR/gmiloshe/general_purpose/utilities.py\", line 234, in wrapper\n",
      "    r = func(*args, **kwargs)\n",
      "  File \"/ClimateDynamics/MediumSpace/ClimateLearningFR/gmiloshe/general_purpose/utilities.py\", line 196, in wrapper_inner\n",
      "    r = func(*args, **kwargs)\n",
      "  File \"/ClimateDynamics/MediumSpace/ClimateLearningFR/gmiloshe/CESM/../PLASIM/Learn2_new.py\", line 2010, in k_fold_cross_val\n",
      "    model = create_model(input_shape=X_tr.shape[1:], **create_model_kwargs)\n",
      "  File \"/ClimateDynamics/MediumSpace/ClimateLearningFR/gmiloshe/CESM/../PLASIM/Learn2_new.py\", line 1420, in create_model\n",
      "    model.add(layers.Conv2D(conv_channels[i], kernel_sizes[i],\n",
      "  File \"/home/gmiloshe/miniconda3/envs/myenvnew/lib/python3.9/site-packages/tensorflow/python/training/tracking/base.py\", line 517, in _method_wrapper\n",
      "    result = method(self, *args, **kwargs)\n",
      "  File \"/home/gmiloshe/miniconda3/envs/myenvnew/lib/python3.9/site-packages/tensorflow/python/keras/engine/sequential.py\", line 208, in add\n",
      "    layer(x)\n",
      "  File \"/home/gmiloshe/miniconda3/envs/myenvnew/lib/python3.9/site-packages/tensorflow/python/keras/engine/base_layer.py\", line 951, in __call__\n",
      "    return self._functional_construction_call(inputs, args, kwargs,\n",
      "  File \"/home/gmiloshe/miniconda3/envs/myenvnew/lib/python3.9/site-packages/tensorflow/python/keras/engine/base_layer.py\", line 1090, in _functional_construction_call\n",
      "    outputs = self._keras_tensor_symbolic_call(\n",
      "  File \"/home/gmiloshe/miniconda3/envs/myenvnew/lib/python3.9/site-packages/tensorflow/python/keras/engine/base_layer.py\", line 822, in _keras_tensor_symbolic_call\n",
      "    return self._infer_output_signature(inputs, args, kwargs, input_masks)\n",
      "  File \"/home/gmiloshe/miniconda3/envs/myenvnew/lib/python3.9/site-packages/tensorflow/python/keras/engine/base_layer.py\", line 863, in _infer_output_signature\n",
      "    outputs = call_fn(inputs, *args, **kwargs)\n",
      "  File \"/home/gmiloshe/miniconda3/envs/myenvnew/lib/python3.9/site-packages/tensorflow/python/keras/layers/convolutional.py\", line 248, in call\n",
      "    outputs = self._convolution_op(inputs, self.kernel)\n",
      "  File \"/home/gmiloshe/miniconda3/envs/myenvnew/lib/python3.9/site-packages/tensorflow/python/util/dispatch.py\", line 201, in wrapper\n",
      "    return target(*args, **kwargs)\n",
      "  File \"/home/gmiloshe/miniconda3/envs/myenvnew/lib/python3.9/site-packages/tensorflow/python/ops/nn_ops.py\", line 1013, in convolution_v2\n",
      "    return convolution_internal(\n",
      "  File \"/home/gmiloshe/miniconda3/envs/myenvnew/lib/python3.9/site-packages/tensorflow/python/ops/nn_ops.py\", line 1143, in convolution_internal\n",
      "    return op(\n",
      "  File \"/home/gmiloshe/miniconda3/envs/myenvnew/lib/python3.9/site-packages/tensorflow/python/ops/nn_ops.py\", line 2597, in _conv2d_expanded_batch\n",
      "    return gen_nn_ops.conv2d(\n",
      "  File \"/home/gmiloshe/miniconda3/envs/myenvnew/lib/python3.9/site-packages/tensorflow/python/ops/gen_nn_ops.py\", line 948, in conv2d\n",
      "    padding = _execute.make_str(padding, \"padding\")\n",
      "  File \"/home/gmiloshe/miniconda3/envs/myenvnew/lib/python3.9/site-packages/tensorflow/python/eager/execute.py\", line 179, in make_str\n",
      "    raise TypeError(\"Expected string for argument '%s' not %s.\" %\n",
      "TypeError: Expected string for argument 'padding' not ListWrapper(['valid', 'valid', 'valid']).\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-05 16:58:23.966733: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-02-05 16:58:23.993235: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Run failed",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/ClimateDynamics/MediumSpace/ClimateLearningFR/gmiloshe/CESM/../PLASIM/Learn2_new.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, folder, load_data_kwargs, prepare_XY_kwargs, k_fold_cross_val_kwargs, log_level)\u001b[0m\n\u001b[1;32m   2771\u001b[0m             \u001b[0;31m# do kfold\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2772\u001b[0;31m             \u001b[0mscore\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mk_fold_cross_val\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfolder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk_fold_cross_val_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2773\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/ClimateDynamics/MediumSpace/ClimateLearningFR/gmiloshe/general_purpose/utilities.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    233\u001b[0m         \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'{func.__name__}:'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 234\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    235\u001b[0m         \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'{func.__name__}: completed in {pretty_time(time.time() - start_time)}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/ClimateDynamics/MediumSpace/ClimateLearningFR/gmiloshe/general_purpose/utilities.py\u001b[0m in \u001b[0;36mwrapper_inner\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    195\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m                 \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    197\u001b[0m             \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/ClimateDynamics/MediumSpace/ClimateLearningFR/gmiloshe/CESM/../PLASIM/Learn2_new.py\u001b[0m in \u001b[0;36mk_fold_cross_val\u001b[0;34m(folder, X, Y, create_model_kwargs, train_model_kwargs, optimal_checkpoint_kwargs, load_from, nfolds, val_folds, u, normalization_mode, fullmetrics, training_epochs, training_epochs_tl, loss, lr, prune_threshold, min_folds_before_pruning)\u001b[0m\n\u001b[1;32m   2009\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mload_from\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2010\u001b[0;31m             \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX_tr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcreate_model_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2011\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/ClimateDynamics/MediumSpace/ClimateLearningFR/gmiloshe/CESM/../PLASIM/Learn2_new.py\u001b[0m in \u001b[0;36mcreate_model\u001b[0;34m(input_shape, conv_channels, kernel_sizes, strides, padding, batch_normalizations, conv_activations, conv_dropouts, max_pool_sizes, conv_l2coef, dense_units, dense_activations, dense_dropouts, dense_l2coef)\u001b[0m\n\u001b[1;32m   1419\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1420\u001b[0;31m                 model.add(layers.Conv2D(conv_channels[i], kernel_sizes[i],\n\u001b[0m\u001b[1;32m   1421\u001b[0m                         strides=strides[i], input_shape=input_shape, padding=padding, kernel_regularizer=kernel_regularizer))\n",
      "\u001b[0;32m~/miniconda3/envs/myenvnew/lib/python3.9/site-packages/tensorflow/python/training/tracking/base.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    516\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 517\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    518\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/myenvnew/lib/python3.9/site-packages/tensorflow/python/keras/engine/sequential.py\u001b[0m in \u001b[0;36madd\u001b[0;34m(self, layer)\u001b[0m\n\u001b[1;32m    207\u001b[0m           \u001b[0;31m# to the input layer we just created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m           \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m           \u001b[0mset_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/myenvnew/lib/python3.9/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    950\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_in_functional_construction_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 951\u001b[0;31m       return self._functional_construction_call(inputs, args, kwargs,\n\u001b[0m\u001b[1;32m    952\u001b[0m                                                 input_list)\n",
      "\u001b[0;32m~/miniconda3/envs/myenvnew/lib/python3.9/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_functional_construction_call\u001b[0;34m(self, inputs, args, kwargs, input_list)\u001b[0m\n\u001b[1;32m   1089\u001b[0m         \u001b[0;31m# Check input assumptions set after layer building, e.g. input shape.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1090\u001b[0;31m         outputs = self._keras_tensor_symbolic_call(\n\u001b[0m\u001b[1;32m   1091\u001b[0m             inputs, input_masks, args, kwargs)\n",
      "\u001b[0;32m~/miniconda3/envs/myenvnew/lib/python3.9/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_keras_tensor_symbolic_call\u001b[0;34m(self, inputs, input_masks, args, kwargs)\u001b[0m\n\u001b[1;32m    821\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 822\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_infer_output_signature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    823\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/myenvnew/lib/python3.9/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_infer_output_signature\u001b[0;34m(self, inputs, args, kwargs, input_masks)\u001b[0m\n\u001b[1;32m    862\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_build\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 863\u001b[0;31m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    864\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/myenvnew/lib/python3.9/site-packages/tensorflow/python/keras/layers/convolutional.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    247\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 248\u001b[0;31m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_convolution_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkernel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    249\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/myenvnew/lib/python3.9/site-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/myenvnew/lib/python3.9/site-packages/tensorflow/python/ops/nn_ops.py\u001b[0m in \u001b[0;36mconvolution_v2\u001b[0;34m(input, filters, strides, padding, data_format, dilations, name)\u001b[0m\n\u001b[1;32m   1012\u001b[0m     name=None):\n\u001b[0;32m-> 1013\u001b[0;31m   return convolution_internal(\n\u001b[0m\u001b[1;32m   1014\u001b[0m       \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# pylint: disable=redefined-builtin\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/myenvnew/lib/python3.9/site-packages/tensorflow/python/ops/nn_ops.py\u001b[0m in \u001b[0;36mconvolution_internal\u001b[0;34m(input, filters, strides, padding, data_format, dilations, name, call_from_convolution, num_spatial_dims)\u001b[0m\n\u001b[1;32m   1142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1143\u001b[0;31m       return op(\n\u001b[0m\u001b[1;32m   1144\u001b[0m           \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/myenvnew/lib/python3.9/site-packages/tensorflow/python/ops/nn_ops.py\u001b[0m in \u001b[0;36m_conv2d_expanded_batch\u001b[0;34m(input, filters, strides, padding, data_format, dilations, name)\u001b[0m\n\u001b[1;32m   2596\u001b[0m     \u001b[0;31m# call slowdown in eager mode.  This branch doesn't require reshapes.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2597\u001b[0;31m     return gen_nn_ops.conv2d(\n\u001b[0m\u001b[1;32m   2598\u001b[0m         \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/myenvnew/lib/python3.9/site-packages/tensorflow/python/ops/gen_nn_ops.py\u001b[0m in \u001b[0;36mconv2d\u001b[0;34m(input, filter, strides, padding, use_cudnn_on_gpu, explicit_paddings, data_format, dilations, name)\u001b[0m\n\u001b[1;32m    947\u001b[0m   \u001b[0mstrides\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0m_execute\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_int\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_i\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"strides\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_i\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstrides\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 948\u001b[0;31m   \u001b[0mpadding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_execute\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"padding\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    949\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0muse_cudnn_on_gpu\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/myenvnew/lib/python3.9/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mmake_str\u001b[0;34m(v, arg_name)\u001b[0m\n\u001b[1;32m    178\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbytes_or_text_types\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 179\u001b[0;31m     raise TypeError(\"Expected string for argument '%s' not %s.\" %\n\u001b[0m\u001b[1;32m    180\u001b[0m                     (arg_name, repr(v)))\n",
      "\u001b[0;31mTypeError\u001b[0m: Expected string for argument 'padding' not ListWrapper(['valid', 'valid', 'valid']).",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_3154393/1127066224.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_multiple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/ClimateDynamics/MediumSpace/ClimateLearningFR/gmiloshe/CESM/../PLASIM/Learn2_new.py\u001b[0m in \u001b[0;36mrun_multiple\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2663\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscheduled_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2664\u001b[0m                 \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m48\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf'{HOSTNAME}: Run {i+1}/{nruns}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2665\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2666\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m49\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf'{HOSTNAME}: \\n\\n\\n\\n\\n\\nALL RUNS COMPLETED\\n\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2667\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/ClimateDynamics/MediumSpace/ClimateLearningFR/gmiloshe/CESM/../PLASIM/Learn2_new.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m   2932\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2933\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupon_failed_run\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'raise'\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2934\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2935\u001b[0m             \u001b[0minfo\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'status'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'FAILED'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2936\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/ClimateDynamics/MediumSpace/ClimateLearningFR/gmiloshe/CESM/../PLASIM/Learn2_new.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m   2914\u001b[0m         \u001b[0mscore\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2915\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2916\u001b[0;31m             \u001b[0mscore\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'{self.root_folder}/{folder}'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mrun_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2917\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2918\u001b[0m             \u001b[0mruns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mut\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjson2dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mruns_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/ClimateDynamics/MediumSpace/ClimateLearningFR/gmiloshe/CESM/../PLASIM/Learn2_new.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, folder, load_data_kwargs, prepare_XY_kwargs, k_fold_cross_val_kwargs, log_level)\u001b[0m\n\u001b[1;32m   2784\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2785\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2786\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Run failed'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2787\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2788\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Run failed"
     ]
    }
   ],
   "source": [
    "t.run_multiple()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "path_to_ERA = '/ClimateDynamics/MediumSpace/ClimateLearningFR/gmiloshe'/ERA/\n",
      "Could not load field_infos: using the hardcoded version\n",
      "Trying to import basemap\n",
      "In this environment you cannot import Basemap\n",
      "Trying to import cartopy\n",
      "Successfully imported cartopy\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<module 'ERA.ERA_Fields_New' from '/ClimateDynamics/MediumSpace/ClimateLearningFR/gmiloshe/ERA/ERA_Fields_New.py'>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import importlib as imp\n",
    "imp.reload(ln)\n",
    "imp.reload(ef)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scheduling 1 run at default values\n"
     ]
    }
   ],
   "source": [
    "t.schedule()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting 1 run\n",
      "apollo2048g: Run 1/1\n",
      "Models will be trained from scratch\n",
      "folder = '2'\n",
      "\n",
      "{}\n",
      "k_fold_cross_val:\n",
      "  Models will be trained from scratch\n",
      "  =============\n",
      "  fold 0 (1/5)\n",
      "  =============\n",
      "  k_fold_cross_val_split:\n",
      "  k_fold_cross_val_split: completed in 2.4 s\n",
      "  number of training data before undersampling: 50560 of which 48032 negative and 2528 positive\n",
      "  number of training data: 7331 of which 4803 negative and 2528 positive\n",
      "  0.0122\\% of the data have non zero std below 1e-4\n",
      "  X_tr.shape = (7331, 64, 128, 3), X_va.shape = (12640, 64, 128, 3)\n",
      "  convolutional args = [[3, 3, 3], [1, 1, 1], [True, True, True], ['relu', 'relu', 'relu'], [0.3, 0.3, 0.3], [2, 2, False], [1e-06, 1e-06, 1e-06], ['valid', 'valid', 'valid']]\n",
      "  dense args = [['relu', None], [0.3, False], [0.001, None]]\n",
      "  \n",
      "  Model: \"sequential_1\"\n",
      "  _________________________________________________________________\n",
      "  Layer (type)                 Output Shape              Param #   \n",
      "  =================================================================\n",
      "  conv2d_1 (Conv2D)            (None, 62, 126, 32)       896       \n",
      "  _________________________________________________________________\n",
      "  batch_normalization (BatchNo (None, 62, 126, 32)       128       \n",
      "  _________________________________________________________________\n",
      "  activation (Activation)      (None, 62, 126, 32)       0         \n",
      "  _________________________________________________________________\n",
      "  spatial_dropout2d (SpatialDr (None, 62, 126, 32)       0         \n",
      "  _________________________________________________________________\n",
      "  max_pooling2d (MaxPooling2D) (None, 31, 63, 32)        0         \n",
      "  _________________________________________________________________\n",
      "  conv2d_2 (Conv2D)            (None, 29, 61, 64)        18496     \n",
      "  _________________________________________________________________\n",
      "  batch_normalization_1 (Batch (None, 29, 61, 64)        256       \n",
      "  _________________________________________________________________\n",
      "  activation_1 (Activation)    (None, 29, 61, 64)        0         \n",
      "  _________________________________________________________________\n",
      "  spatial_dropout2d_1 (Spatial (None, 29, 61, 64)        0         \n",
      "  _________________________________________________________________\n",
      "  max_pooling2d_1 (MaxPooling2 (None, 14, 30, 64)        0         \n",
      "  _________________________________________________________________\n",
      "  conv2d_3 (Conv2D)            (None, 12, 28, 64)        36928     \n",
      "  _________________________________________________________________\n",
      "  batch_normalization_2 (Batch (None, 12, 28, 64)        256       \n",
      "  _________________________________________________________________\n",
      "  activation_2 (Activation)    (None, 12, 28, 64)        0         \n",
      "  _________________________________________________________________\n",
      "  spatial_dropout2d_2 (Spatial (None, 12, 28, 64)        0         \n",
      "  _________________________________________________________________\n",
      "  flatten (Flatten)            (None, 21504)             0         \n",
      "  _________________________________________________________________\n",
      "  dense (Dense)                (None, 64)                1376320   \n",
      "  _________________________________________________________________\n",
      "  dropout (Dropout)            (None, 64)                0         \n",
      "  _________________________________________________________________\n",
      "  dense_1 (Dense)              (None, 2)                 130       \n",
      "  =================================================================\n",
      "  Total params: 1,433,410\n",
      "  Trainable params: 1,433,090\n",
      "  Non-trainable params: 320\n",
      "  _________________________________________________________________\n",
      "  \n",
      "  Using sparse_categorical_crossentropy loss\n",
      "  train_model:\n",
      "    Converting training data to tensors\n",
      "    Converting validation data to tensors\n",
      "    Training the network on 7331 datapoint and validating on 12640\n",
      "    Epoch 1/2    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-05 17:01:16.322675: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n",
      "2023-02-05 17:01:16.345618: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2300000000 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    WARNING:tensorflow:AutoGraph could not transform <bound method MCCMetric.confusion_matrix of <ERA.TF_Fields.MCCMetric object at 0x7f347b80d7f0>> and will run it as-is.\n",
      "    Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "    Cause: module 'gast' has no attribute 'Index'\n",
      "    To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "    AutoGraph could not transform <bound method MCCMetric.confusion_matrix of <ERA.TF_Fields.MCCMetric object at 0x7f347b80d7f0>> and will run it as-is.\n",
      "    Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "    Cause: module 'gast' has no attribute 'Index'\n",
      "    To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "    WARNING: AutoGraph could not transform <bound method MCCMetric.confusion_matrix of <ERA.TF_Fields.MCCMetric object at 0x7f347b80d7f0>> and will run it as-is.\n",
      "    Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "    Cause: module 'gast' has no attribute 'Index'\n",
      "    To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert    \n",
      "    29/29 - 22s - loss: 0.7668 - accuracy: 0.6614 - MCC: 0.1906 - UnbiasedMCC: 0.0374 - confusion_matrix: 1832.7500 - BrierScore: 0.4430 - CustomLoss: 1.0181 - val_loss: 0.7300 - val_accuracy: 0.8513 - val_MCC: 0.3077 - val_UnbiasedMCC: 0.0000e+00 - val_confusion_matrix: 3160.0000 - val_BrierScore: 0.4290 - val_CustomLoss: 0.1932\n",
      "    \n",
      "    Epoch 00001: saving model to ./models/tests/test10/2/fold_0/cp-0001.ckpt    \n",
      "    Epoch 2/2    \n",
      "    29/29 - 19s - loss: 0.6144 - accuracy: 0.7669 - MCC: 0.4650 - UnbiasedMCC: 0.1614 - confusion_matrix: 1832.7500 - BrierScore: 0.4372 - CustomLoss: 0.8302 - val_loss: 0.6472 - val_accuracy: 0.8285 - val_MCC: 0.3282 - val_UnbiasedMCC: 0.0000e+00 - val_confusion_matrix: 3160.0000 - val_BrierScore: 0.4382 - val_CustomLoss: 0.1756\n",
      "    \n",
      "    Epoch 00002: saving model to ./models/tests/test10/2/fold_0/cp-0002.ckpt    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-05 17:02:07.013807: W tensorflow/python/util/util.cc:348] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    INFO:tensorflow:Assets written to: ./models/tests/test10/2/fold_0/assets\n",
      "    Assets written to: ./models/tests/test10/2/fold_0/assets\n",
      "                 loss  accuracy       MCC  UnbiasedMCC  \\\n",
      "    epoch-1                                              \n",
      "    0        0.766842  0.661438  0.190556     0.037424   \n",
      "    1        0.614388  0.766880  0.465021     0.161357   \n",
      "    \n",
      "                              confusion_matrix  BrierScore  CustomLoss  val_loss  \\\n",
      "    epoch-1                                                                        \n",
      "    0         [[4788.0, 15.0], [2506.0, 22.0]]    0.442977    1.018073  0.730026   \n",
      "    1        [[4789.0, 14.0], [2404.0, 124.0]]    0.437242    0.830185  0.647189   \n",
      "    \n",
      "             val_accuracy   val_MCC  val_UnbiasedMCC  \\\n",
      "    epoch-1                                            \n",
      "    0            0.851266  0.307740              0.0   \n",
      "    1            0.828481  0.328222              0.0   \n",
      "    \n",
      "                       val_confusion_matrix  val_BrierScore  val_CustomLoss  \n",
      "    epoch-1                                                                  \n",
      "    0        [[12008.0, 0.0], [632.0, 0.0]]        0.428999        0.193226  \n",
      "    1        [[12008.0, 0.0], [632.0, 0.0]]        0.438219        0.175598  \n",
      "    score = 0.17559795081615448\n",
      "  train_model: completed in 54.5 s\n",
      "  RAM memory: 4.558e+11\n",
      "  =============\n",
      "  fold 1 (2/5)\n",
      "  =============\n",
      "  k_fold_cross_val_split:\n",
      "  k_fold_cross_val_split: completed in 2.5 s\n",
      "  number of training data before undersampling: 50560 of which 48032 negative and 2528 positive\n",
      "  number of training data: 7331 of which 4803 negative and 2528 positive\n",
      "  0.0163\\% of the data have non zero std below 1e-4\n",
      "  X_tr.shape = (7331, 64, 128, 3), X_va.shape = (12640, 64, 128, 3)\n",
      "  convolutional args = [[3, 3, 3], [1, 1, 1], [True, True, True], ['relu', 'relu', 'relu'], [0.3, 0.3, 0.3], [2, 2, False], [1e-06, 1e-06, 1e-06], ['valid', 'valid', 'valid']]\n",
      "  dense args = [['relu', None], [0.3, False], [0.001, None]]\n",
      "  \n",
      "  Model: \"sequential\"\n",
      "  _________________________________________________________________\n",
      "  Layer (type)                 Output Shape              Param #   \n",
      "  =================================================================\n",
      "  conv2d (Conv2D)              (None, 62, 126, 32)       896       \n",
      "  _________________________________________________________________\n",
      "  batch_normalization (BatchNo (None, 62, 126, 32)       128       \n",
      "  _________________________________________________________________\n",
      "  activation (Activation)      (None, 62, 126, 32)       0         \n",
      "  _________________________________________________________________\n",
      "  spatial_dropout2d (SpatialDr (None, 62, 126, 32)       0         \n",
      "  _________________________________________________________________\n",
      "  max_pooling2d (MaxPooling2D) (None, 31, 63, 32)        0         \n",
      "  _________________________________________________________________\n",
      "  conv2d_1 (Conv2D)            (None, 29, 61, 64)        18496     \n",
      "  _________________________________________________________________\n",
      "  batch_normalization_1 (Batch (None, 29, 61, 64)        256       \n",
      "  _________________________________________________________________\n",
      "  activation_1 (Activation)    (None, 29, 61, 64)        0         \n",
      "  _________________________________________________________________\n",
      "  spatial_dropout2d_1 (Spatial (None, 29, 61, 64)        0         \n",
      "  _________________________________________________________________\n",
      "  max_pooling2d_1 (MaxPooling2 (None, 14, 30, 64)        0         \n",
      "  _________________________________________________________________\n",
      "  conv2d_2 (Conv2D)            (None, 12, 28, 64)        36928     \n",
      "  _________________________________________________________________\n",
      "  batch_normalization_2 (Batch (None, 12, 28, 64)        256       \n",
      "  _________________________________________________________________\n",
      "  activation_2 (Activation)    (None, 12, 28, 64)        0         \n",
      "  _________________________________________________________________\n",
      "  spatial_dropout2d_2 (Spatial (None, 12, 28, 64)        0         \n",
      "  _________________________________________________________________\n",
      "  flatten (Flatten)            (None, 21504)             0         \n",
      "  _________________________________________________________________\n",
      "  dense (Dense)                (None, 64)                1376320   \n",
      "  _________________________________________________________________\n",
      "  dropout (Dropout)            (None, 64)                0         \n",
      "  _________________________________________________________________\n",
      "  dense_1 (Dense)              (None, 2)                 130       \n",
      "  =================================================================\n",
      "  Total params: 1,433,410\n",
      "  Trainable params: 1,433,090\n",
      "  Non-trainable params: 320\n",
      "  _________________________________________________________________\n",
      "  \n",
      "  Using sparse_categorical_crossentropy loss\n",
      "  train_model:\n",
      "    Converting training data to tensors\n",
      "    Converting validation data to tensors\n",
      "    Training the network on 7331 datapoint and validating on 12640\n",
      "    Epoch 1/2    \n",
      "    29/29 - 21s - loss: 0.8319 - accuracy: 0.6505 - MCC: 0.1815 - UnbiasedMCC: 0.0142 - confusion_matrix: 1832.7500 - BrierScore: 0.4387 - CustomLoss: 1.0505 - val_loss: 0.7392 - val_accuracy: 0.8460 - val_MCC: 0.3127 - val_UnbiasedMCC: 0.0000e+00 - val_confusion_matrix: 3160.0000 - val_BrierScore: 0.4278 - val_CustomLoss: 0.1947\n",
      "    \n",
      "    Epoch 00001: saving model to ./models/tests/test10/2/fold_1/cp-0001.ckpt    \n",
      "    Epoch 2/2    \n",
      "    29/29 - 19s - loss: 0.6343 - accuracy: 0.7436 - MCC: 0.4077 - UnbiasedMCC: 0.1229 - confusion_matrix: 1832.7500 - BrierScore: 0.4382 - CustomLoss: 0.8599 - val_loss: 0.6145 - val_accuracy: 0.8684 - val_MCC: 0.3414 - val_UnbiasedMCC: 0.0000e+00 - val_confusion_matrix: 3160.0000 - val_BrierScore: 0.4429 - val_CustomLoss: 0.1732\n",
      "    \n",
      "    Epoch 00002: saving model to ./models/tests/test10/2/fold_1/cp-0002.ckpt    \n",
      "    INFO:tensorflow:Assets written to: ./models/tests/test10/2/fold_1/assets\n",
      "    Assets written to: ./models/tests/test10/2/fold_1/assets\n",
      "                 loss  accuracy       MCC  UnbiasedMCC  \\\n",
      "    epoch-1                                              \n",
      "    0        0.831853  0.650525  0.181526     0.014210   \n",
      "    1        0.634325  0.743555  0.407709     0.122907   \n",
      "    \n",
      "                             confusion_matrix  BrierScore  CustomLoss  val_loss  \\\n",
      "    epoch-1                                                                       \n",
      "    0        [[4713.0, 90.0], [2470.0, 58.0]]    0.438664    1.050452  0.739210   \n",
      "    1        [[4790.0, 13.0], [2448.0, 80.0]]    0.438228    0.859941  0.614482   \n",
      "    \n",
      "             val_accuracy   val_MCC  val_UnbiasedMCC  \\\n",
      "    epoch-1                                            \n",
      "    0            0.845965  0.312716              0.0   \n",
      "    1            0.868434  0.341390              0.0   \n",
      "    \n",
      "                       val_confusion_matrix  val_BrierScore  val_CustomLoss  \n",
      "    epoch-1                                                                  \n",
      "    0        [[12008.0, 0.0], [632.0, 0.0]]        0.427788        0.194685  \n",
      "    1        [[12008.0, 0.0], [632.0, 0.0]]        0.442863        0.173203  \n",
      "    score = 0.1732027530670166\n",
      "  train_model: completed in 53.0 s\n",
      "  RAM memory: 4.566e+11\n",
      "  =============\n",
      "  fold 2 (3/5)\n",
      "  =============\n",
      "  k_fold_cross_val_split:\n",
      "  k_fold_cross_val_split: completed in 2.5 s\n",
      "  number of training data before undersampling: 50560 of which 48032 negative and 2528 positive\n",
      "  number of training data: 7331 of which 4803 negative and 2528 positive\n",
      "  0.0163\\% of the data have non zero std below 1e-4\n",
      "  X_tr.shape = (7331, 64, 128, 3), X_va.shape = (12640, 64, 128, 3)\n",
      "  convolutional args = [[3, 3, 3], [1, 1, 1], [True, True, True], ['relu', 'relu', 'relu'], [0.3, 0.3, 0.3], [2, 2, False], [1e-06, 1e-06, 1e-06], ['valid', 'valid', 'valid']]\n",
      "  dense args = [['relu', None], [0.3, False], [0.001, None]]\n",
      "  \n",
      "  Model: \"sequential\"\n",
      "  _________________________________________________________________\n",
      "  Layer (type)                 Output Shape              Param #   \n",
      "  =================================================================\n",
      "  conv2d (Conv2D)              (None, 62, 126, 32)       896       \n",
      "  _________________________________________________________________\n",
      "  batch_normalization (BatchNo (None, 62, 126, 32)       128       \n",
      "  _________________________________________________________________\n",
      "  activation (Activation)      (None, 62, 126, 32)       0         \n",
      "  _________________________________________________________________\n",
      "  spatial_dropout2d (SpatialDr (None, 62, 126, 32)       0         \n",
      "  _________________________________________________________________\n",
      "  max_pooling2d (MaxPooling2D) (None, 31, 63, 32)        0         \n",
      "  _________________________________________________________________\n",
      "  conv2d_1 (Conv2D)            (None, 29, 61, 64)        18496     \n",
      "  _________________________________________________________________\n",
      "  batch_normalization_1 (Batch (None, 29, 61, 64)        256       \n",
      "  _________________________________________________________________\n",
      "  activation_1 (Activation)    (None, 29, 61, 64)        0         \n",
      "  _________________________________________________________________\n",
      "  spatial_dropout2d_1 (Spatial (None, 29, 61, 64)        0         \n",
      "  _________________________________________________________________\n",
      "  max_pooling2d_1 (MaxPooling2 (None, 14, 30, 64)        0         \n",
      "  _________________________________________________________________\n",
      "  conv2d_2 (Conv2D)            (None, 12, 28, 64)        36928     \n",
      "  _________________________________________________________________\n",
      "  batch_normalization_2 (Batch (None, 12, 28, 64)        256       \n",
      "  _________________________________________________________________\n",
      "  activation_2 (Activation)    (None, 12, 28, 64)        0         \n",
      "  _________________________________________________________________\n",
      "  spatial_dropout2d_2 (Spatial (None, 12, 28, 64)        0         \n",
      "  _________________________________________________________________\n",
      "  flatten (Flatten)            (None, 21504)             0         \n",
      "  _________________________________________________________________\n",
      "  dense (Dense)                (None, 64)                1376320   \n",
      "  _________________________________________________________________\n",
      "  dropout (Dropout)            (None, 64)                0         \n",
      "  _________________________________________________________________\n",
      "  dense_1 (Dense)              (None, 2)                 130       \n",
      "  =================================================================\n",
      "  Total params: 1,433,410\n",
      "  Trainable params: 1,433,090\n",
      "  Non-trainable params: 320\n",
      "  _________________________________________________________________\n",
      "  \n",
      "  Using sparse_categorical_crossentropy loss\n",
      "  train_model:\n",
      "    Converting training data to tensors\n",
      "    Converting validation data to tensors\n",
      "    Training the network on 7331 datapoint and validating on 12640\n",
      "    Epoch 1/2    \n",
      "    29/29 - 21s - loss: 0.8036 - accuracy: 0.6588 - MCC: 0.2082 - UnbiasedMCC: 0.0715 - confusion_matrix: 1832.7500 - BrierScore: 0.4368 - CustomLoss: 1.0126 - val_loss: 0.7337 - val_accuracy: 0.7856 - val_MCC: 0.2885 - val_UnbiasedMCC: 0.0000e+00 - val_confusion_matrix: 3160.0000 - val_BrierScore: 0.4276 - val_CustomLoss: 0.1895\n",
      "    \n",
      "    Epoch 00001: saving model to ./models/tests/test10/2/fold_2/cp-0001.ckpt    \n",
      "    Epoch 2/2    \n",
      "    29/29 - 19s - loss: 0.6164 - accuracy: 0.7609 - MCC: 0.4516 - UnbiasedMCC: 0.1986 - confusion_matrix: 1832.7500 - BrierScore: 0.4362 - CustomLoss: 0.8218 - val_loss: 0.6171 - val_accuracy: 0.8547 - val_MCC: 0.3185 - val_UnbiasedMCC: 0.0000e+00 - val_confusion_matrix: 3160.0000 - val_BrierScore: 0.4422 - val_CustomLoss: 0.1726\n",
      "    \n",
      "    Epoch 00002: saving model to ./models/tests/test10/2/fold_2/cp-0002.ckpt    \n",
      "    INFO:tensorflow:Assets written to: ./models/tests/test10/2/fold_2/assets\n",
      "    Assets written to: ./models/tests/test10/2/fold_2/assets\n",
      "                loss  accuracy       MCC  UnbiasedMCC  \\\n",
      "    epoch-1                                             \n",
      "    0        0.80364  0.658846  0.208175     0.071513   \n",
      "    1        0.61638  0.760878  0.451645     0.198576   \n",
      "    \n",
      "                              confusion_matrix  BrierScore  CustomLoss  val_loss  \\\n",
      "    epoch-1                                                                        \n",
      "    0         [[4756.0, 47.0], [2455.0, 73.0]]    0.436776    1.012610  0.733692   \n",
      "    1        [[4782.0, 21.0], [2342.0, 186.0]]    0.436200    0.821756  0.617057   \n",
      "    \n",
      "             val_accuracy   val_MCC  val_UnbiasedMCC  \\\n",
      "    epoch-1                                            \n",
      "    0            0.785601  0.288531              0.0   \n",
      "    1            0.854668  0.318547              0.0   \n",
      "    \n",
      "                       val_confusion_matrix  val_BrierScore  val_CustomLoss  \n",
      "    epoch-1                                                                  \n",
      "    0        [[12008.0, 0.0], [632.0, 0.0]]        0.427568        0.189456  \n",
      "    1        [[12008.0, 0.0], [632.0, 0.0]]        0.442175        0.172561  \n",
      "    score = 0.1725609302520752\n",
      "  train_model: completed in 52.4 s\n",
      "  RAM memory: 4.570e+11\n",
      "  =============\n",
      "  fold 3 (4/5)\n",
      "  =============\n",
      "  k_fold_cross_val_split:\n",
      "  k_fold_cross_val_split: completed in 2.5 s\n",
      "  number of training data before undersampling: 50560 of which 48032 negative and 2528 positive\n",
      "  number of training data: 7331 of which 4803 negative and 2528 positive\n",
      "  0.0163\\% of the data have non zero std below 1e-4\n",
      "  X_tr.shape = (7331, 64, 128, 3), X_va.shape = (12640, 64, 128, 3)\n",
      "  convolutional args = [[3, 3, 3], [1, 1, 1], [True, True, True], ['relu', 'relu', 'relu'], [0.3, 0.3, 0.3], [2, 2, False], [1e-06, 1e-06, 1e-06], ['valid', 'valid', 'valid']]\n",
      "  dense args = [['relu', None], [0.3, False], [0.001, None]]\n",
      "  \n",
      "  Model: \"sequential\"\n",
      "  _________________________________________________________________\n",
      "  Layer (type)                 Output Shape              Param #   \n",
      "  =================================================================\n",
      "  conv2d (Conv2D)              (None, 62, 126, 32)       896       \n",
      "  _________________________________________________________________\n",
      "  batch_normalization (BatchNo (None, 62, 126, 32)       128       \n",
      "  _________________________________________________________________\n",
      "  activation (Activation)      (None, 62, 126, 32)       0         \n",
      "  _________________________________________________________________\n",
      "  spatial_dropout2d (SpatialDr (None, 62, 126, 32)       0         \n",
      "  _________________________________________________________________\n",
      "  max_pooling2d (MaxPooling2D) (None, 31, 63, 32)        0         \n",
      "  _________________________________________________________________\n",
      "  conv2d_1 (Conv2D)            (None, 29, 61, 64)        18496     \n",
      "  _________________________________________________________________\n",
      "  batch_normalization_1 (Batch (None, 29, 61, 64)        256       \n",
      "  _________________________________________________________________\n",
      "  activation_1 (Activation)    (None, 29, 61, 64)        0         \n",
      "  _________________________________________________________________\n",
      "  spatial_dropout2d_1 (Spatial (None, 29, 61, 64)        0         \n",
      "  _________________________________________________________________\n",
      "  max_pooling2d_1 (MaxPooling2 (None, 14, 30, 64)        0         \n",
      "  _________________________________________________________________\n",
      "  conv2d_2 (Conv2D)            (None, 12, 28, 64)        36928     \n",
      "  _________________________________________________________________\n",
      "  batch_normalization_2 (Batch (None, 12, 28, 64)        256       \n",
      "  _________________________________________________________________\n",
      "  activation_2 (Activation)    (None, 12, 28, 64)        0         \n",
      "  _________________________________________________________________\n",
      "  spatial_dropout2d_2 (Spatial (None, 12, 28, 64)        0         \n",
      "  _________________________________________________________________\n",
      "  flatten (Flatten)            (None, 21504)             0         \n",
      "  _________________________________________________________________\n",
      "  dense (Dense)                (None, 64)                1376320   \n",
      "  _________________________________________________________________\n",
      "  dropout (Dropout)            (None, 64)                0         \n",
      "  _________________________________________________________________\n",
      "  dense_1 (Dense)              (None, 2)                 130       \n",
      "  =================================================================\n",
      "  Total params: 1,433,410\n",
      "  Trainable params: 1,433,090\n",
      "  Non-trainable params: 320\n",
      "  _________________________________________________________________\n",
      "  \n",
      "  Using sparse_categorical_crossentropy loss\n",
      "  train_model:\n",
      "    Converting training data to tensors\n",
      "    Converting validation data to tensors\n",
      "    Training the network on 7331 datapoint and validating on 12640\n",
      "    Epoch 1/2    \n",
      "    29/29 - 21s - loss: 0.7481 - accuracy: 0.6789 - MCC: 0.2473 - UnbiasedMCC: 0.0634 - confusion_matrix: 1832.7500 - BrierScore: 0.4398 - CustomLoss: 0.9828 - val_loss: 0.7308 - val_accuracy: 0.7833 - val_MCC: 0.3044 - val_UnbiasedMCC: 0.0000e+00 - val_confusion_matrix: 3160.0000 - val_BrierScore: 0.4275 - val_CustomLoss: 0.1867\n",
      "    \n",
      "    Epoch 00001: saving model to ./models/tests/test10/2/fold_3/cp-0001.ckpt    \n",
      "    Epoch 2/2    \n",
      "    29/29 - 19s - loss: 0.6041 - accuracy: 0.7684 - MCC: 0.4734 - UnbiasedMCC: 0.1753 - confusion_matrix: 1832.7500 - BrierScore: 0.4346 - CustomLoss: 0.8063 - val_loss: 0.6086 - val_accuracy: 0.8544 - val_MCC: 0.3386 - val_UnbiasedMCC: 0.0000e+00 - val_confusion_matrix: 3160.0000 - val_BrierScore: 0.4423 - val_CustomLoss: 0.1671\n",
      "    \n",
      "    Epoch 00002: saving model to ./models/tests/test10/2/fold_3/cp-0002.ckpt    \n",
      "    INFO:tensorflow:Assets written to: ./models/tests/test10/2/fold_3/assets\n",
      "    Assets written to: ./models/tests/test10/2/fold_3/assets\n",
      "                 loss  accuracy       MCC  UnbiasedMCC  \\\n",
      "    epoch-1                                              \n",
      "    0        0.748069  0.678898  0.247251     0.063426   \n",
      "    1        0.604116  0.768381  0.473411     0.175299   \n",
      "    \n",
      "                              confusion_matrix  BrierScore  CustomLoss  val_loss  \\\n",
      "    epoch-1                                                                        \n",
      "    0         [[4787.0, 16.0], [2491.0, 37.0]]    0.439847    0.982762  0.730761   \n",
      "    1        [[4778.0, 25.0], [2369.0, 159.0]]    0.434598    0.806295  0.608552   \n",
      "    \n",
      "             val_accuracy   val_MCC  val_UnbiasedMCC  \\\n",
      "    epoch-1                                            \n",
      "    0            0.783307  0.304432              0.0   \n",
      "    1            0.854430  0.338558              0.0   \n",
      "    \n",
      "                       val_confusion_matrix  val_BrierScore  val_CustomLoss  \n",
      "    epoch-1                                                                  \n",
      "    0        [[12008.0, 0.0], [632.0, 0.0]]        0.427477        0.186685  \n",
      "    1        [[12008.0, 0.0], [632.0, 0.0]]        0.442315        0.167059  \n",
      "    score = 0.1670587658882141\n",
      "  train_model: completed in 52.3 s\n",
      "  RAM memory: 4.576e+11\n",
      "  =============\n",
      "  fold 4 (5/5)\n",
      "  =============\n",
      "  k_fold_cross_val_split:\n",
      "  k_fold_cross_val_split: completed in 0.7 s\n",
      "  number of training data before undersampling: 50560 of which 48032 negative and 2528 positive\n",
      "  number of training data: 7331 of which 4803 negative and 2528 positive\n",
      "  0.0122\\% of the data have non zero std below 1e-4\n",
      "  X_tr.shape = (7331, 64, 128, 3), X_va.shape = (12640, 64, 128, 3)\n",
      "  convolutional args = [[3, 3, 3], [1, 1, 1], [True, True, True], ['relu', 'relu', 'relu'], [0.3, 0.3, 0.3], [2, 2, False], [1e-06, 1e-06, 1e-06], ['valid', 'valid', 'valid']]\n",
      "  dense args = [['relu', None], [0.3, False], [0.001, None]]\n",
      "  \n",
      "  Model: \"sequential\"\n",
      "  _________________________________________________________________\n",
      "  Layer (type)                 Output Shape              Param #   \n",
      "  =================================================================\n",
      "  conv2d (Conv2D)              (None, 62, 126, 32)       896       \n",
      "  _________________________________________________________________\n",
      "  batch_normalization (BatchNo (None, 62, 126, 32)       128       \n",
      "  _________________________________________________________________\n",
      "  activation (Activation)      (None, 62, 126, 32)       0         \n",
      "  _________________________________________________________________\n",
      "  spatial_dropout2d (SpatialDr (None, 62, 126, 32)       0         \n",
      "  _________________________________________________________________\n",
      "  max_pooling2d (MaxPooling2D) (None, 31, 63, 32)        0         \n",
      "  _________________________________________________________________\n",
      "  conv2d_1 (Conv2D)            (None, 29, 61, 64)        18496     \n",
      "  _________________________________________________________________\n",
      "  batch_normalization_1 (Batch (None, 29, 61, 64)        256       \n",
      "  _________________________________________________________________\n",
      "  activation_1 (Activation)    (None, 29, 61, 64)        0         \n",
      "  _________________________________________________________________\n",
      "  spatial_dropout2d_1 (Spatial (None, 29, 61, 64)        0         \n",
      "  _________________________________________________________________\n",
      "  max_pooling2d_1 (MaxPooling2 (None, 14, 30, 64)        0         \n",
      "  _________________________________________________________________\n",
      "  conv2d_2 (Conv2D)            (None, 12, 28, 64)        36928     \n",
      "  _________________________________________________________________\n",
      "  batch_normalization_2 (Batch (None, 12, 28, 64)        256       \n",
      "  _________________________________________________________________\n",
      "  activation_2 (Activation)    (None, 12, 28, 64)        0         \n",
      "  _________________________________________________________________\n",
      "  spatial_dropout2d_2 (Spatial (None, 12, 28, 64)        0         \n",
      "  _________________________________________________________________\n",
      "  flatten (Flatten)            (None, 21504)             0         \n",
      "  _________________________________________________________________\n",
      "  dense (Dense)                (None, 64)                1376320   \n",
      "  _________________________________________________________________\n",
      "  dropout (Dropout)            (None, 64)                0         \n",
      "  _________________________________________________________________\n",
      "  dense_1 (Dense)              (None, 2)                 130       \n",
      "  =================================================================\n",
      "  Total params: 1,433,410\n",
      "  Trainable params: 1,433,090\n",
      "  Non-trainable params: 320\n",
      "  _________________________________________________________________\n",
      "  \n",
      "  Using sparse_categorical_crossentropy loss\n",
      "  train_model:\n",
      "    Converting training data to tensors\n",
      "    Converting validation data to tensors\n",
      "    Training the network on 7331 datapoint and validating on 12640\n",
      "    Epoch 1/2    \n",
      "    29/29 - 21s - loss: 0.7749 - accuracy: 0.6549 - MCC: 0.1755 - UnbiasedMCC: -1.7002e-03 - confusion_matrix: 1832.7500 - BrierScore: 0.4428 - CustomLoss: 1.0255 - val_loss: 0.7351 - val_accuracy: 0.8213 - val_MCC: 0.2747 - val_UnbiasedMCC: 0.0000e+00 - val_confusion_matrix: 3160.0000 - val_BrierScore: 0.4283 - val_CustomLoss: 0.1943\n",
      "    \n",
      "    Epoch 00001: saving model to ./models/tests/test10/2/fold_4/cp-0001.ckpt    \n",
      "    Epoch 2/2    \n",
      "    29/29 - 20s - loss: 0.6222 - accuracy: 0.7550 - MCC: 0.4362 - UnbiasedMCC: 0.1318 - confusion_matrix: 1832.7500 - BrierScore: 0.4382 - CustomLoss: 0.8487 - val_loss: 0.6023 - val_accuracy: 0.8378 - val_MCC: 0.3141 - val_UnbiasedMCC: 0.0000e+00 - val_confusion_matrix: 3160.0000 - val_BrierScore: 0.4438 - val_CustomLoss: 0.1707\n",
      "    \n",
      "    Epoch 00002: saving model to ./models/tests/test10/2/fold_4/cp-0002.ckpt    \n",
      "    INFO:tensorflow:Assets written to: ./models/tests/test10/2/fold_4/assets\n",
      "    Assets written to: ./models/tests/test10/2/fold_4/assets\n",
      "                 loss  accuracy       MCC  UnbiasedMCC  \\\n",
      "    epoch-1                                              \n",
      "    0        0.774851  0.654890  0.175517    -0.001700   \n",
      "    1        0.622220  0.755013  0.436154     0.131839   \n",
      "    \n",
      "                             confusion_matrix  BrierScore  CustomLoss  val_loss  \\\n",
      "    epoch-1                                                                       \n",
      "    0        [[4779.0, 24.0], [2516.0, 12.0]]    0.442847    1.025452  0.735064   \n",
      "    1         [[4795.0, 8.0], [2447.0, 81.0]]    0.438221    0.848715  0.602294   \n",
      "    \n",
      "             val_accuracy   val_MCC  val_UnbiasedMCC  \\\n",
      "    epoch-1                                            \n",
      "    0            0.821282  0.274660              0.0   \n",
      "    1            0.837816  0.314133              0.0   \n",
      "    \n",
      "                       val_confusion_matrix  val_BrierScore  val_CustomLoss  \n",
      "    epoch-1                                                                  \n",
      "    0        [[12008.0, 0.0], [632.0, 0.0]]        0.428301        0.194254  \n",
      "    1        [[12008.0, 0.0], [632.0, 0.0]]        0.443817        0.170712  \n",
      "    score = 0.17071206867694855\n",
      "  train_model: completed in 53.5 s\n",
      "  RAM memory: 4.576e+11\n",
      "  \n",
      "  Final scores:\n",
      "  \tfold 0: 0.17559795081615448\n",
      "  \tfold 1: 0.1732027530670166\n",
      "  \tfold 2: 0.1725609302520752\n",
      "  \tfold 3: 0.1670587658882141\n",
      "  \tfold 4: 0.17071206867694855\n",
      "  Average score: 0.1718+/-0.0029\n",
      "k_fold_cross_val: completed in 4 min 52.6 s\n",
      "run completed!!!\n",
      "\n",
      "\n",
      "apollo2048g: \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ALL RUNS COMPLETED\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "t.run_multiple()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenvnew",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7 (default, Sep 16 2021, 13:09:58) \n[GCC 7.5.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "13d6ac2b46cffe7b04dd84f7288304bd0f3c8f660cff0949df6ccaecc97804f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
