{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "In this environment you cannot import Basemap\n",
      "In this environment you cannot import Basemap\n"
     ]
    }
   ],
   "source": [
    "import Learn2_new as ln\n",
    "ut = ln.ut # utilities\n",
    "ef = ln.ef # ERA_Fields_New\n",
    "\n",
    "# log to stdout\n",
    "import logging\n",
    "import sys\n",
    "import os\n",
    "logging.getLogger().level = logging.INFO\n",
    "logging.getLogger().handlers = [logging.StreamHandler(sys.stdout)]\n",
    "\n",
    "# set spacing of the indentation\n",
    "ut.indentation_sep = '  '"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dealing with parameters\n",
    "\n",
    "The structure of `Learn2_new.py` is pretty nested, with functions calling other functions in such a way that changing a parameter seems difficult.\n",
    "The best way to do so is by using the functions `ln.get_default_params` and `ut.set_values_recursive`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Beginner approach\n",
    "\n",
    "The first way of approaching the code is by looking at the documentation of its functions, and when they have an argument of kind `*_kwargs`, it means that the function `*` will be called, so you can then look at its documentation and so on"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's say you want to use the function `ln.prepare_data`. If you look at its documentation you get"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function prepare_data in module Learn2_new:\n",
      "\n",
      "prepare_data(load_data_kwargs=None, prepare_XY_kwargs=None)\n",
      "    Combines all the steps from loading the data to the creation of X and Y\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    load_data_kwargs: dict\n",
      "        arguments to pass to the function `load_data`\n",
      "    prepare_XY_kwargs: dict\n",
      "        arguments to pass to the function `prepare_XY`\n",
      "        \n",
      "    Returns\n",
      "    -------\n",
      "    X : np.ndarray\n",
      "        data. If flatten_time_axis with shape (days, lat, lon, fields), else (years, days, lat, lon, fields)\n",
      "    Y : np.ndarray \n",
      "        labels. If flatten_time_axis with shape (days,), else (years, days)\n",
      "    year_permutation : np.ndarray\n",
      "        with shape (years,), final permutaion of the years that reproduces X and Y once applied to the just loaded data\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(ln.prepare_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This functions calls `ln.load_data` and `ln.prepare_XY`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function load_data in module Learn2_new:\n",
      "\n",
      "load_data(dataset_years=8000, year_list=None, sampling='', Model='Plasim', area='France', filter_area='France', lon_start=0, lon_end=128, lat_start=0, lat_end=22, mylocal='/local/gmiloshe/PLASIM/', fields=['t2m', 'zg500', 'mrso_filtered'])\n",
      "    Loads the data into Plasim_Fields objects\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    dataset_years : int, optional\n",
      "        number of years of the dataset, for now 8000 or 1000.\n",
      "    year_list : array-like or str or int or tuple or None, optional\n",
      "        list of years to load from the dataset. If None all years are loaded\n",
      "        if str must be in the format 'range([<start>],<end>,[<step>])', where square brackets mean the argument is optional. It will be interpreted as np.range([<start>],<end>,[<step>])\n",
      "        if tuple must be in format ([<start>],<end>,[<step>])\n",
      "        if int is just like providing only <end>\n",
      "    sampling : str, optional\n",
      "        '' (dayly) or '3hrs'\n",
      "    Model : str, optional\n",
      "        'Plasim', 'CESM', ... For now only Plasim is implemented\n",
      "    area : str, optional\n",
      "        region of interest, e.g. 'France'\n",
      "    filter_area : str, optional\n",
      "        area over which to keep filtered fields, usually the same of `area`. `filter` implies a mask\n",
      "    lon_start, lon_end, lat_start, lat_end : int\n",
      "        longitude and latitude extremes of the data expressed in indices (model specific)\n",
      "    mylocal : str or Path, optional\n",
      "        path the the data storage. For speed it is better if it is a local path.\n",
      "    fields : list, optional\n",
      "        list of field names to be loaded. Add '_filtered' to the name to have the values of the field outside `filter_area` set to zero.\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    _fields: dict\n",
      "        dictionary of ERA_Fields.Plasim_Field objects\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(ln.load_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the variable called `mylocal` governs the source of data. Depending on the machine we are using we might want to change it. For instance on r740server5, the local space is acutally: '/ClimateDynamics/MediumSpace/ClimateLearningFR/gmiloshe/PLASIM/';"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function prepare_XY in module Learn2_new:\n",
      "\n",
      "prepare_XY(fields, make_XY_kwargs=None, roll_X_kwargs=None, do_premix=False, premix_seed=0, do_balance_folds=True, nfolds=10, year_permutation=None, flatten_time_axis=True)\n",
      "    Performs all operations to extract from the fields X and Y ready to be fed to the neural network.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    fields : dict of ef.Plasim_Field objects\n",
      "    make_XY_kwargs : dict\n",
      "        arguments to pass to the function `make_XY`\n",
      "    roll_X_kwargs : dict\n",
      "        arguments to pass to the function `roll_X`\n",
      "    do_premix : bool, optional\n",
      "        whether to perform premixing, by default False\n",
      "    premix_seed : int, optional\n",
      "        seed for premixing, by default 0\n",
      "    do_balance_folds : bool, optional\n",
      "        whether to balance folds\n",
      "    nfolds : int, optional\n",
      "        necessary for balancing folds\n",
      "    year_permutation : np.ndarray, optional\n",
      "        if provided overrides both premixing and fold balancing, useful for transfer learning as avoids contaminating test sets. By default None\n",
      "    flatten_time_axis : bool, optional\n",
      "        whether to flatten the time axis consisting of years and days\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    X : np.ndarray\n",
      "        data. If flatten_time_axis with shape (days, lat, lon, fields), else (years, days, lat, lon, fields)\n",
      "    Y : np.ndarray \n",
      "        labels. If flatten_time_axis with shape (days,), else (years, days)\n",
      "    tot_permutation : np.ndarray\n",
      "        with shape (years,), final permutaion of the years that reproduces X and Y once applied to the just loaded data\n",
      "    lat : np.ndarray\n",
      "        latitude, with shape (lat,) (rolled if necessary)\n",
      "    lon : np.ndarray\n",
      "        longitude, with shape (lon,) (rolled if necessary)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(ln.prepare_XY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And `ln.prepare_XY` calls `ln.make_XY` and `ln.roll_X`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function make_XY in module Learn2_new:\n",
      "\n",
      "make_XY(fields, label_field='t2m', time_start=30, time_end=120, T=14, tau=0, percent=5, threshold=None)\n",
      "    Combines `make_X` and `assign_labels`\n",
      "    \n",
      "    Parameters:\n",
      "    -----------\n",
      "    fields : dict of Plasim_Field objects\n",
      "    label_field : str, optional\n",
      "        key for the field used for computing labels\n",
      "    time_start : int, optional\n",
      "        first day of the period of interest\n",
      "    time_end : int, optional\n",
      "        first day after the end of the period of interst\n",
      "    T : int, optional\n",
      "        width of the window for the running average\n",
      "    tau : int, optional\n",
      "        delay between observation and prediction\n",
      "    percent : float, optional\n",
      "        percentage of the most extreme heatwaves\n",
      "    threshold : float, optional\n",
      "        if provided overrides `percent`\n",
      "    \n",
      "    Returns:\n",
      "    --------\n",
      "    X : np.ndarray\n",
      "        with shape (years, days, lat, lon, field)\n",
      "    Y : np.ndarray\n",
      "        with shape (years, days)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(ln.make_XY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function roll_X in module Learn2_new:\n",
      "\n",
      "roll_X(X, roll_axis='lon', roll_steps=64)\n",
      "    Rolls `X` along a given axis. useful for example for moving France away from the Greenwich meridian.\n",
      "    In other words this allows one, for example, to shift the grid so that desired areas are not found at the boundary.\n",
      "    In principle this function allows us to roll along arbitrary axis, including days or years.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    X : np.ndarray\n",
      "        with shape (years, days, lat, lon, field)\n",
      "    roll_axis : int or str, optional\n",
      "        'year' (or 'y'), 'day' (or 'd'), 'lat', 'lon', 'field' (or 'f')\n",
      "    roll_steps : int, optional\n",
      "        number of gridsteps to roll: a positive value for `roll_steps` means that the elements of the array are moved forward in it,\n",
      "        e.g. `roll_steps` = 1 means that the old first element is now in the second place\n",
      "        This means that for every axis a positive value of `roll_steps` yields a shift of the array\n",
      "        'year', 'day' : forward in time\n",
      "        'lat' : southward\n",
      "        'lon' : eastward\n",
      "        'field' : forward in the numbering of the fields\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    np.ndarray\n",
      "        of the same shape of `X`\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(ln.roll_X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, now let's say you want to call `ln.prepare_data` with just the temperature field, using data from the short 1000 years dataset and rolling `X` by 16 steps, leavingall other values at their default. One (cumbersome) way to do it is the following"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prepare_data:\n",
      "  load_data:\n",
      "    load_field:\n",
      "    \tLoading field tas\n",
      "    \tLoaded time array\n",
      "    \tinput self.var.shape = (150000, 22, 128)\n",
      "    \toutput self.var.shape = (1000, 150, 22, 128)\n",
      "    load_field: completed in 6.1 s\n",
      "    Set_area_integral:\n",
      "    Set_area_integral: completed in 0.0 s\n",
      "  load_data: completed in 6.1 s\n",
      "  prepare_XY:\n",
      "    make_XY:\n",
      "      make_X:\n",
      "      make_X: completed in 0.3 s\n",
      "      assign_labels:\n",
      "      assign_labels: completed in 0.0 s\n",
      "    make_XY: completed in 0.4 s\n",
      "    roll_X:\n",
      "    roll_X: completed in 0.4 s\n",
      "    Mixing\n",
      "    balance_folds:\n",
      "      Balancing folds\n",
      "      fold 0 done!\n",
      "      fold 1 done!\n",
      "      fold 2 done!\n",
      "      fold 3 done!\n",
      "      fold 4 done!\n",
      "      fold 5 done!\n",
      "      fold 6 done!\n",
      "      fold 7 done!\n",
      "      fold 8 done!\n",
      "      fold 9 done!\n",
      "      Sums of the balanced 10 folds:\n",
      "      [385 385 385 385 385 385 385 385 385 385]\n",
      "      std/avg = 0.0\n",
      "      max relative deviation = 0.0\\%\n",
      "    balance_folds: completed in 0.0 s\n",
      "    Mixing completed in 0.3 s\n",
      "    \n",
      "    X.shape = (1000, 77, 22, 128, 1), Y.shape = (1000, 77)\n",
      "    Flattened time: X.shape = (77000, 22, 128, 1), Y.shape = (77000,)\n",
      "  prepare_XY: completed in 1.1 s\n",
      "prepare_data: completed in 7.2 s\n"
     ]
    }
   ],
   "source": [
    "X, Y, yp, lon, lat = ln.prepare_data(load_data_kwargs = {'fields': ['t2m'], 'dataset_years': 1000},\n",
    "                           prepare_XY_kwargs = {'roll_X_kwargs': {'roll_steps': 16}})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can inspect the coordinates to see that they are indeed in rolled order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(masked_array(data=[87.86379884, 85.09652699, 82.31291295, 79.52560657,\n",
       "                    76.73689968, 73.94751515, 71.15775201, 68.36775611,\n",
       "                    65.57760701, 62.7873518 , 59.99702011, 57.20663153,\n",
       "                    54.41619953, 51.62573367, 48.83524097, 46.04472663,\n",
       "                    43.25419467, 40.46364818, 37.67308963, 34.88252099,\n",
       "                    32.09194388, 29.30135962],\n",
       "              mask=False,\n",
       "        fill_value=1e+20),\n",
       " masked_array(data=[-45.    , -42.1875, -39.375 , -36.5625, -33.75  ,\n",
       "                    -30.9375, -28.125 , -25.3125, -22.5   , -19.6875,\n",
       "                    -16.875 , -14.0625, -11.25  ,  -8.4375,  -5.625 ,\n",
       "                     -2.8125,   0.    ,   2.8125,   5.625 ,   8.4375,\n",
       "                     11.25  ,  14.0625,  16.875 ,  19.6875,  22.5   ,\n",
       "                     25.3125,  28.125 ,  30.9375,  33.75  ,  36.5625,\n",
       "                     39.375 ,  42.1875,  45.    ,  47.8125,  50.625 ,\n",
       "                     53.4375,  56.25  ,  59.0625,  61.875 ,  64.6875,\n",
       "                     67.5   ,  70.3125,  73.125 ,  75.9375,  78.75  ,\n",
       "                     81.5625,  84.375 ,  87.1875,  90.    ,  92.8125,\n",
       "                     95.625 ,  98.4375, 101.25  , 104.0625, 106.875 ,\n",
       "                    109.6875, 112.5   , 115.3125, 118.125 , 120.9375,\n",
       "                    123.75  , 126.5625, 129.375 , 132.1875, 135.    ,\n",
       "                    137.8125, 140.625 , 143.4375, 146.25  , 149.0625,\n",
       "                    151.875 , 154.6875, 157.5   , 160.3125, 163.125 ,\n",
       "                    165.9375, 168.75  , 171.5625, 174.375 , 177.1875,\n",
       "                    180.    , 182.8125, 185.625 , 188.4375, 191.25  ,\n",
       "                    194.0625, 196.875 , 199.6875, 202.5   , 205.3125,\n",
       "                    208.125 , 210.9375, 213.75  , 216.5625, 219.375 ,\n",
       "                    222.1875, 225.    , 227.8125, 230.625 , 233.4375,\n",
       "                    236.25  , 239.0625, 241.875 , 244.6875, 247.5   ,\n",
       "                    250.3125, 253.125 , 255.9375, 258.75  , 261.5625,\n",
       "                    264.375 , 267.1875, 270.    , 272.8125, 275.625 ,\n",
       "                    278.4375, 281.25  , 284.0625, 286.875 , 289.6875,\n",
       "                    292.5   , 295.3125, 298.125 , 300.9375, 303.75  ,\n",
       "                    306.5625, 309.375 , 312.1875],\n",
       "              mask=False,\n",
       "        fill_value=1e+20))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lon, lat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If this command didn't work it is likely that you are running it from a machine which doesn't have the data in local space, or as mentioned earlier R740server5, in which case you need to specify the source in kwargs by doing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prepare_data:\n",
      "  load_data:\n",
      "    load_field:\n",
      "    \tLoading field tas\n",
      "    \tLoaded time array\n",
      "    \tinput self.var.shape = (150000, 22, 128)\n",
      "    \toutput self.var.shape = (1000, 150, 22, 128)\n",
      "    load_field: completed in 1 min 59.8 s\n",
      "    Set_area_integral:\n",
      "    Set_area_integral: completed in 0.1 s\n",
      "  load_data: completed in 1 min 59.9 s\n",
      "  prepare_XY:\n",
      "    make_XY:\n",
      "      make_X:\n",
      "      make_X: completed in 0.4 s\n",
      "      assign_labels:\n",
      "      assign_labels: completed in 0.0 s\n",
      "    make_XY: completed in 0.4 s\n",
      "    roll_X:\n",
      "    roll_X: completed in 0.5 s\n",
      "    Mixing\n",
      "    balance_folds:\n",
      "      Balancing folds\n",
      "      fold 0 done!\n",
      "      fold 1 done!\n",
      "      fold 2 done!\n",
      "      fold 3 done!\n",
      "      fold 4 done!\n",
      "      fold 5 done!\n",
      "      fold 6 done!\n",
      "      fold 7 done!\n",
      "      fold 8 done!\n",
      "      fold 9 done!\n",
      "      Sums of the balanced 10 folds:\n",
      "      [385 385 385 385 385 385 385 385 385 385]\n",
      "      std/avg = 0.0\n",
      "      max relative deviation = 0.0\\%\n",
      "    balance_folds: completed in 0.0 s\n",
      "    Mixing completed in 0.3 s\n",
      "    \n",
      "    X.shape = (1000, 77, 22, 128, 1), Y.shape = (1000, 77)\n",
      "    Flattened time: X.shape = (77000, 22, 128, 1), Y.shape = (77000,)\n",
      "  prepare_XY: completed in 1.3 s\n",
      "prepare_data: completed in 2 min 1.2 s\n"
     ]
    }
   ],
   "source": [
    "X, Y, yp, lon, lat = ln.prepare_data(load_data_kwargs = {'fields': ['t2m'], 'dataset_years': 1000, 'mylocal':  '/ClimateDynamics/MediumSpace/ClimateLearningFR/gmiloshe/PLASIM/'},\n",
    "                           prepare_XY_kwargs = {'roll_X_kwargs': {'rosteps': 16}})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Better approach\n",
    "\n",
    "If intstead you already roughly know how the code works, you can proceed in a more elegant way"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First create a dictionary of the default parameters using `ln.get_default_params`. Remeber to specify `recursive = True`, which will gather all the default parameters of the functions called in a nested manner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"load_data_kwargs\": {\n",
      "        \"dataset_years\": 8000,\n",
      "        \"year_list\": null,\n",
      "        \"sampling\": \"\",\n",
      "        \"Model\": \"Plasim\",\n",
      "        \"area\": \"France\",\n",
      "        \"filter_area\": \"France\",\n",
      "        \"lon_start\": 0,\n",
      "        \"lon_end\": 128,\n",
      "        \"lat_start\": 0,\n",
      "        \"lat_end\": 22,\n",
      "        \"mylocal\": \"/local/gmiloshe/PLASIM/\",\n",
      "        \"fields\": [\n",
      "            \"t2m\",\n",
      "            \"zg500\",\n",
      "            \"mrso_filtered\"\n",
      "        ]\n",
      "    },\n",
      "    \"prepare_XY_kwargs\": {\n",
      "        \"do_premix\": false,\n",
      "        \"premix_seed\": 0,\n",
      "        \"do_balance_folds\": true,\n",
      "        \"nfolds\": 10,\n",
      "        \"year_permutation\": null,\n",
      "        \"flatten_time_axis\": true,\n",
      "        \"make_XY_kwargs\": {\n",
      "            \"label_field\": \"t2m\",\n",
      "            \"time_start\": 30,\n",
      "            \"time_end\": 120,\n",
      "            \"T\": 14,\n",
      "            \"tau\": 0,\n",
      "            \"percent\": 5,\n",
      "            \"threshold\": null\n",
      "        },\n",
      "        \"roll_X_kwargs\": {\n",
      "            \"roll_axis\": \"lon\",\n",
      "            \"roll_steps\": 64\n",
      "        }\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "prepare_data_kwargs_default = ln.get_default_params(ln.prepare_data, recursive=True)\n",
    "print(ut.dict2str(prepare_data_kwargs_default)) # a nice way of printing nested dictionaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Again pay attention that the machine we are using has the data in space called 'local'. If so you don't need to specify the variable `mylocal` below)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you want to set the two parameters to non default values, and you can do it by using `ut.set_values_recursive`, without needing to account for the level of nestedness of the parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"load_data_kwargs\": {\n",
      "        \"dataset_years\": 1000,\n",
      "        \"year_list\": null,\n",
      "        \"sampling\": \"\",\n",
      "        \"Model\": \"Plasim\",\n",
      "        \"area\": \"France\",\n",
      "        \"filter_area\": \"France\",\n",
      "        \"lon_start\": 0,\n",
      "        \"lon_end\": 128,\n",
      "        \"lat_start\": 0,\n",
      "        \"lat_end\": 22,\n",
      "        \"mylocal\": \"/local/gmiloshe/PLASIM/\",\n",
      "        \"fields\": [\n",
      "            \"t2m\"\n",
      "        ]\n",
      "    },\n",
      "    \"prepare_XY_kwargs\": {\n",
      "        \"do_premix\": false,\n",
      "        \"premix_seed\": 0,\n",
      "        \"do_balance_folds\": true,\n",
      "        \"nfolds\": 10,\n",
      "        \"year_permutation\": null,\n",
      "        \"flatten_time_axis\": true,\n",
      "        \"make_XY_kwargs\": {\n",
      "            \"label_field\": \"t2m\",\n",
      "            \"time_start\": 30,\n",
      "            \"time_end\": 120,\n",
      "            \"T\": 14,\n",
      "            \"tau\": 0,\n",
      "            \"percent\": 5,\n",
      "            \"threshold\": null\n",
      "        },\n",
      "        \"roll_X_kwargs\": {\n",
      "            \"roll_axis\": \"lon\",\n",
      "            \"roll_steps\": 16\n",
      "        }\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "prepare_data_kwargs = ut.set_values_recursive(prepare_data_kwargs_default,\n",
    "                                              {'fields': ['t2m'], 'dataset_years': 1000, 'roll_steps': 16}) #, 'mylocal': '/ClimateDynamics/MediumSpace/ClimateLearningFR/gmiloshe/PLASIM/'})\n",
    "print(ut.dict2str(prepare_data_kwargs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And then you can run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prepare_data:\n",
      "  load_data:\n",
      "    load_field:\n",
      "    \tLoading field tas\n",
      "    \tLoaded time array\n",
      "    \tinput self.var.shape = (150000, 22, 128)\n",
      "    \toutput self.var.shape = (1000, 150, 22, 128)\n",
      "    load_field: completed in 6.3 s\n",
      "    Set_area_integral:\n",
      "    Set_area_integral: completed in 0.0 s\n",
      "  load_data: completed in 6.3 s\n",
      "  prepare_XY:\n",
      "    make_XY:\n",
      "      make_X:\n",
      "      make_X: completed in 0.3 s\n",
      "      assign_labels:\n",
      "      assign_labels: completed in 0.0 s\n",
      "    make_XY: completed in 0.3 s\n",
      "    roll_X:\n",
      "    roll_X: completed in 0.6 s\n",
      "    Mixing\n",
      "    balance_folds:\n",
      "      Balancing folds\n",
      "      fold 0 done!\n",
      "      fold 1 done!\n",
      "      fold 2 done!\n",
      "      fold 3 done!\n",
      "      fold 4 done!\n",
      "      fold 5 done!\n",
      "      fold 6 done!\n",
      "      fold 7 done!\n",
      "      fold 8 done!\n",
      "      fold 9 done!\n",
      "      Sums of the balanced 10 folds:\n",
      "      [385 385 385 385 385 385 385 385 385 385]\n",
      "      std/avg = 0.0\n",
      "      max relative deviation = 0.0\\%\n",
      "    balance_folds: completed in 0.0 s\n",
      "    Mixing completed in 0.3 s\n",
      "    \n",
      "    X.shape = (1000, 77, 22, 128, 1), Y.shape = (1000, 77)\n",
      "    Flattened time: X.shape = (77000, 22, 128, 1), Y.shape = (77000,)\n",
      "  prepare_XY: completed in 1.3 s\n",
      "prepare_data: completed in 7.6 s\n"
     ]
    }
   ],
   "source": [
    "X, Y, yp, lon, lat = ln.prepare_data(**prepare_data_kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading parameters from a config file\n",
    "\n",
    "If you want to load your default values from a config file, you can do as follows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"run_kwargs\": {\n",
      "        \"log_level\": 20,\n",
      "        \"load_data_kwargs\": {\n",
      "            \"dataset_years\": 8000,\n",
      "            \"year_list\": null,\n",
      "            \"sampling\": \"\",\n",
      "            \"Model\": \"Plasim\",\n",
      "            \"area\": \"France\",\n",
      "            \"filter_area\": \"France\",\n",
      "            \"lon_start\": 0,\n",
      "            \"lon_end\": 128,\n",
      "            \"lat_start\": 0,\n",
      "            \"lat_end\": 22,\n",
      "            \"mylocal\": \"/local/gmiloshe/PLASIM/\",\n",
      "            \"fields\": [\n",
      "                \"t2m\",\n",
      "                \"zg500\",\n",
      "                \"mrso_filtered\"\n",
      "            ]\n",
      "        },\n",
      "        \"prepare_XY_kwargs\": {\n",
      "            \"do_premix\": false,\n",
      "            \"premix_seed\": 0,\n",
      "            \"do_balance_folds\": true,\n",
      "            \"nfolds\": 10,\n",
      "            \"year_permutation\": null,\n",
      "            \"flatten_time_axis\": true,\n",
      "            \"make_XY_kwargs\": {\n",
      "                \"label_field\": \"t2m\",\n",
      "                \"time_start\": 30,\n",
      "                \"time_end\": 120,\n",
      "                \"T\": 14,\n",
      "                \"tau\": 0,\n",
      "                \"percent\": 5,\n",
      "                \"threshold\": null\n",
      "            },\n",
      "            \"roll_X_kwargs\": {\n",
      "                \"roll_axis\": \"lon\",\n",
      "                \"roll_steps\": 64\n",
      "            }\n",
      "        },\n",
      "        \"k_fold_cross_val_kwargs\": {\n",
      "            \"load_from\": \"last\",\n",
      "            \"nfolds\": 10,\n",
      "            \"val_folds\": 1,\n",
      "            \"u\": 1,\n",
      "            \"fullmetrics\": true,\n",
      "            \"training_epochs\": 40,\n",
      "            \"training_epochs_tl\": 10,\n",
      "            \"loss\": \"sparse_categorical_crossentropy\",\n",
      "            \"lr\": 0.0001,\n",
      "            \"create_model_kwargs\": {\n",
      "                \"conv_channels\": [\n",
      "                    32,\n",
      "                    64,\n",
      "                    64\n",
      "                ],\n",
      "                \"kernel_sizes\": 3,\n",
      "                \"strides\": 1,\n",
      "                \"batch_normalizations\": true,\n",
      "                \"conv_activations\": \"relu\",\n",
      "                \"conv_dropouts\": 0.2,\n",
      "                \"max_pool_sizes\": [\n",
      "                    2,\n",
      "                    2,\n",
      "                    false\n",
      "                ],\n",
      "                \"dense_units\": [\n",
      "                    64,\n",
      "                    2\n",
      "                ],\n",
      "                \"dense_activations\": [\n",
      "                    \"relu\",\n",
      "                    null\n",
      "                ],\n",
      "                \"dense_dropouts\": [\n",
      "                    0.2,\n",
      "                    false\n",
      "                ]\n",
      "            },\n",
      "            \"train_model_kwargs\": {\n",
      "                \"enable_early_stopping\": false,\n",
      "                \"batch_size\": 1024,\n",
      "                \"checkpoint_every\": 1,\n",
      "                \"additional_callbacks\": [\n",
      "                    \"csv_logger\"\n",
      "                ],\n",
      "                \"early_stopping_kwargs\": {\n",
      "                    \"monitor\": \"val_CustomLoss\",\n",
      "                    \"min_delta\": 0,\n",
      "                    \"patience\": 0,\n",
      "                    \"mode\": \"auto\"\n",
      "                }\n",
      "            },\n",
      "            \"optimal_checkpoint_kwargs\": {\n",
      "                \"metric\": \"val_CustomLoss\",\n",
      "                \"direction\": \"minimize\",\n",
      "                \"first_epoch\": 1,\n",
      "                \"collective\": true,\n",
      "                \"bypass\": null\n",
      "            }\n",
      "        }\n",
      "    },\n",
      "    \"telegram_kwargs\": {\n",
      "        \"telegram_bot_token\": \"~/ENSMLbot.txt\",\n",
      "        \"chat_ID\": null,\n",
      "        \"telegram_logging_level\": 31,\n",
      "        \"telegram_logging_format\": null\n",
      "    }\n",
      "}\n",
      "\n",
      "\n",
      "\n",
      "{\n",
      "    \"log_level\": 20,\n",
      "    \"dataset_years\": 8000,\n",
      "    \"year_list\": null,\n",
      "    \"sampling\": \"\",\n",
      "    \"Model\": \"Plasim\",\n",
      "    \"area\": \"France\",\n",
      "    \"filter_area\": \"France\",\n",
      "    \"lon_start\": 0,\n",
      "    \"lon_end\": 128,\n",
      "    \"lat_start\": 0,\n",
      "    \"lat_end\": 22,\n",
      "    \"mylocal\": \"/local/gmiloshe/PLASIM/\",\n",
      "    \"fields\": [\n",
      "        \"t2m\",\n",
      "        \"zg500\",\n",
      "        \"mrso_filtered\"\n",
      "    ],\n",
      "    \"do_premix\": false,\n",
      "    \"premix_seed\": 0,\n",
      "    \"do_balance_folds\": true,\n",
      "    \"nfolds\": 10,\n",
      "    \"year_permutation\": null,\n",
      "    \"flatten_time_axis\": true,\n",
      "    \"label_field\": \"t2m\",\n",
      "    \"time_start\": 30,\n",
      "    \"time_end\": 120,\n",
      "    \"T\": 14,\n",
      "    \"tau\": 0,\n",
      "    \"percent\": 5,\n",
      "    \"threshold\": null,\n",
      "    \"roll_axis\": \"lon\",\n",
      "    \"roll_steps\": 64,\n",
      "    \"load_from\": \"last\",\n",
      "    \"val_folds\": 1,\n",
      "    \"u\": 1,\n",
      "    \"fullmetrics\": true,\n",
      "    \"training_epochs\": 40,\n",
      "    \"training_epochs_tl\": 10,\n",
      "    \"loss\": \"sparse_categorical_crossentropy\",\n",
      "    \"lr\": 0.0001,\n",
      "    \"conv_channels\": [\n",
      "        32,\n",
      "        64,\n",
      "        64\n",
      "    ],\n",
      "    \"kernel_sizes\": 3,\n",
      "    \"strides\": 1,\n",
      "    \"batch_normalizations\": true,\n",
      "    \"conv_activations\": \"relu\",\n",
      "    \"conv_dropouts\": 0.2,\n",
      "    \"max_pool_sizes\": [\n",
      "        2,\n",
      "        2,\n",
      "        false\n",
      "    ],\n",
      "    \"dense_units\": [\n",
      "        64,\n",
      "        2\n",
      "    ],\n",
      "    \"dense_activations\": [\n",
      "        \"relu\",\n",
      "        null\n",
      "    ],\n",
      "    \"dense_dropouts\": [\n",
      "        0.2,\n",
      "        false\n",
      "    ],\n",
      "    \"enable_early_stopping\": false,\n",
      "    \"batch_size\": 1024,\n",
      "    \"checkpoint_every\": 1,\n",
      "    \"additional_callbacks\": [\n",
      "        \"csv_logger\"\n",
      "    ],\n",
      "    \"monitor\": \"val_CustomLoss\",\n",
      "    \"min_delta\": 0,\n",
      "    \"patience\": 0,\n",
      "    \"mode\": \"auto\",\n",
      "    \"metric\": \"val_CustomLoss\",\n",
      "    \"direction\": \"minimize\",\n",
      "    \"first_epoch\": 1,\n",
      "    \"collective\": true,\n",
      "    \"bypass\": null,\n",
      "    \"telegram_bot_token\": \"~/ENSMLbot.txt\",\n",
      "    \"chat_ID\": null,\n",
      "    \"telegram_logging_level\": 31,\n",
      "    \"telegram_logging_format\": null\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "config_dict = ut.json2dict('example_config.json') # load the config file\n",
    "print(ut.dict2str(config_dict))\n",
    "print('\\n\\n')\n",
    "config_dict_flat = ut.collapse_dict(config_dict) # flatten the dictionary\n",
    "print(ut.dict2str(config_dict_flat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"load_data_kwargs\": {\n",
      "        \"dataset_years\": 8000,\n",
      "        \"year_list\": null,\n",
      "        \"sampling\": \"\",\n",
      "        \"Model\": \"Plasim\",\n",
      "        \"area\": \"France\",\n",
      "        \"filter_area\": \"France\",\n",
      "        \"lon_start\": 0,\n",
      "        \"lon_end\": 128,\n",
      "        \"lat_start\": 0,\n",
      "        \"lat_end\": 22,\n",
      "        \"mylocal\": \"/local/gmiloshe/PLASIM/\",\n",
      "        \"fields\": [\n",
      "            \"t2m\",\n",
      "            \"zg500\",\n",
      "            \"mrso_filtered\"\n",
      "        ]\n",
      "    },\n",
      "    \"prepare_XY_kwargs\": {\n",
      "        \"do_premix\": false,\n",
      "        \"premix_seed\": 0,\n",
      "        \"do_balance_folds\": true,\n",
      "        \"nfolds\": 10,\n",
      "        \"year_permutation\": null,\n",
      "        \"flatten_time_axis\": true,\n",
      "        \"make_XY_kwargs\": {\n",
      "            \"label_field\": \"t2m\",\n",
      "            \"time_start\": 30,\n",
      "            \"time_end\": 120,\n",
      "            \"T\": 14,\n",
      "            \"tau\": 0,\n",
      "            \"percent\": 5,\n",
      "            \"threshold\": null\n",
      "        },\n",
      "        \"roll_X_kwargs\": {\n",
      "            \"roll_axis\": \"lon\",\n",
      "            \"roll_steps\": 64\n",
      "        }\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "ut.set_values_recursive(prepare_data_kwargs_default, config_dict_flat, inplace=True) # set all values in prepare_data_kwargs_default to the one that appear in config_dict_flat\n",
    "print(ut.dict2str(prepare_data_kwargs_default))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We had to do this way because `prepare_data_kwargs` is not a key of the config dictionary. Let's say instead you wanted the default arguments for the function `make_XY`, you could have simply done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"label_field\": \"t2m\",\n",
      "    \"time_start\": 30,\n",
      "    \"time_end\": 120,\n",
      "    \"T\": 14,\n",
      "    \"tau\": 0,\n",
      "    \"percent\": 5,\n",
      "    \"threshold\": null\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "make_XY_kwargs_default = ut.extract_nested(config_dict, 'make_XY_kwargs')\n",
    "print(ut.dict2str(make_XY_kwargs_default))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Where the function `ut.extract_nested` allows to obtain a key from a nested dictionary regardless of the level of indentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Working with the `Trainer` Class\n",
    "\n",
    "Instead of using the module level functions such as `load_data` or `train_model`, you can use the `Trainer` class to a simpler training of the networks and efficient over multiple runs.\n",
    "\n",
    "First create a `Trainer` object in a given work directory. You can avoid the work directory if don't plan to train networks\n",
    "\n",
    "Then you can call the equivalent of module level functions `t.prepare_data`, `t.prepare_XY`, `t.load_data`. If you call them multiple times with the same arguments the values will be cached, the values will be cached so you will save time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.__version__ = '2.4.1'\n",
      "tf.config.list_physical_devices('GPU') = []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alessandrolovo/Repos/Climate-Learning/PLASIM/Learn2_new.py:1820: UserWarning: \n",
      "This machine does not have a GPU: training may be very slow\n",
      "\n",
      "  warnings.warn('\\nThis machine does not have a GPU: training may be very slow\\n')\n"
     ]
    }
   ],
   "source": [
    "# create a work directory\n",
    "work_dir = './test'\n",
    "\n",
    "t = ln.Trainer(work_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Be careful if you want to train convolutional networks that the machine you are using has a GPU, otherwise training will be very slow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most interesting part is however related to performing full runs. First setup the config dictionary of the trainer object, for example here we want a specific network architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"conv_channels\": [\n",
      "        32,\n",
      "        64,\n",
      "        64\n",
      "    ],\n",
      "    \"kernel_sizes\": 3,\n",
      "    \"strides\": 1,\n",
      "    \"batch_normalizations\": true,\n",
      "    \"conv_activations\": \"relu\",\n",
      "    \"conv_dropouts\": 0.2,\n",
      "    \"max_pool_sizes\": [\n",
      "        2,\n",
      "        2,\n",
      "        false\n",
      "    ],\n",
      "    \"dense_units\": [\n",
      "        64,\n",
      "        2\n",
      "    ],\n",
      "    \"dense_activations\": [\n",
      "        \"relu\",\n",
      "        null\n",
      "    ],\n",
      "    \"dense_dropouts\": [\n",
      "        0.2,\n",
      "        false\n",
      "    ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(ut.dict2str(ut.extract_nested(t.config_dict, 'create_model_kwargs')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {\n",
    "    'conv_channels': [64, 24], # set number of convolutional kernels per layer\n",
    "    'kernel_sizes': [7, 3],\n",
    "    'strides': [3, 2],\n",
    "    'batch_normalization': False, # disable batch normalization\n",
    "    'max_pool_sizes': False, # disable max pool\n",
    "    'conv_dropout': False, # disable dropout in the convolutional layer\n",
    "\n",
    "    'dense_units': [128, 64, 16, 2], # number of neurons per fully connected layer\n",
    "    'dense_dropouts': [0.5, 0.5, 0.1, 0],\n",
    "    'dense_activations': ['relu', 'relu', 'relu', None]\n",
    "}\n",
    "\n",
    "ut.set_values_recursive(t.config_dict, d, inplace=True)\n",
    "print(ut.dict2str(t.config_dict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then you can schedule your runs, for example iterating over `tau` at two different `percent` levels, transfer learning from the last network with the same value for `percent`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scheduled the following 14 runs:\n",
      "0: {'load_from': 'last--percent__same'}\n",
      "1: {'load_from': 'last--percent__same', 'tau': -5}\n",
      "2: {'load_from': 'last--percent__same', 'tau': -10}\n",
      "3: {'load_from': 'last--percent__same', 'tau': -15}\n",
      "4: {'load_from': 'last--percent__same', 'tau': -20}\n",
      "5: {'load_from': 'last--percent__same', 'tau': -25}\n",
      "6: {'load_from': 'last--percent__same', 'tau': -30}\n",
      "7: {'load_from': 'last--percent__same', 'percent': 1}\n",
      "8: {'load_from': 'last--percent__same', 'percent': 1, 'tau': -5}\n",
      "9: {'load_from': 'last--percent__same', 'percent': 1, 'tau': -10}\n",
      "10: {'load_from': 'last--percent__same', 'percent': 1, 'tau': -15}\n",
      "11: {'load_from': 'last--percent__same', 'percent': 1, 'tau': -20}\n",
      "12: {'load_from': 'last--percent__same', 'percent': 1, 'tau': -25}\n",
      "13: {'load_from': 'last--percent__same', 'percent': 1, 'tau': -30}\n"
     ]
    }
   ],
   "source": [
    "t.schedule(percent=[5,1], tau=[0, -5, -10, -15, -20, -25, -30], load_from='last--percent__same')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t.run_multiple()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f58c806238b5edc44fc8624bbbe57f811658295c06d7c0c7dd7ec103a0da3bdf"
  },
  "kernelspec": {
   "display_name": "py3.9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
