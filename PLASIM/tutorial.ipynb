{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-17 09:01:42.577165: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "In this environment you cannot import Basemap\n",
      "In this environment you cannot import Basemap\n"
     ]
    }
   ],
   "source": [
    "import Learn2_new as ln\n",
    "ut = ln.ut # utilities\n",
    "ef = ln.ef # ERA_Fields_New\n",
    "\n",
    "# log to stdout\n",
    "import logging\n",
    "import sys\n",
    "logging.getLogger().level = logging.INFO\n",
    "logging.getLogger().handlers = [logging.StreamHandler(sys.stdout)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dealing with parameters\n",
    "\n",
    "The structure of `Learn2_new.py` is pretty nested, with functions calling other functions in such a way that changing a parameter seems difficult.\n",
    "The best way to do so is by using the functions `ln.get_default_params` and `ut.set_values_recursive`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Beginner approach\n",
    "\n",
    "The first way of approaching the code is by looking at the documentation of its functions, and when they have an argument of kind `*_kwargs`, it means that the function `*` will be called, so you can then look at its documentation and so on"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's say you want to use the function `ln.prepare_data`. If you look at its documentation you get"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function prepare_data in module Learn2_new:\n",
      "\n",
      "prepare_data(load_data_kwargs=None, prepare_XY_kwargs=None)\n",
      "    Combines all the steps from loading the data to the creation of X and Y\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    load_data_kwargs: dict\n",
      "        arguments to pass to the function `load_data`\n",
      "    prepare_XY_kwargs: dict\n",
      "        arguments to pass to the function `prepare_XY`\n",
      "        \n",
      "    Returns\n",
      "    -------\n",
      "    X : np.ndarray\n",
      "        data. If flatten_time_axis with shape (days, lat, lon, fields), else (years, days, lat, lon, fields)\n",
      "    Y : np.ndarray \n",
      "        labels. If flatten_time_axis with shape (days,), else (years, days)\n",
      "    year_permutation : np.ndarray\n",
      "        with shape (years,), final permutaion of the years that reproduces X and Y once applied to the just loaded data\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(ln.prepare_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This functions calls `ln.load_data` and `ln.prepare_XY`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function load_data in module Learn2_new:\n",
      "\n",
      "load_data(dataset_years=8000, year_list=None, sampling='', Model='Plasim', area='France', filter_area='France', lon_start=0, lon_end=128, lat_start=0, lat_end=22, mylocal='/local/gmiloshe/PLASIM/', fields=['t2m', 'zg500', 'mrso_filtered'])\n",
      "    Loads the data into Plasim_Fields objects\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    dataset_years : int, optional\n",
      "        number of years of the dataset, for now 8000 or 1000.\n",
      "    year_list : array-like or str or int or tuple or None, optional\n",
      "        list of years to load from the dataset. If None all years are loaded\n",
      "        if str must be in the format 'range([<start>],<end>,[<step>])', where square brackets mean the argument is optional. It will be interpreted as np.range([<start>],<end>,[<step>])\n",
      "        if tuple must be in format ([<start>],<end>,[<step>])\n",
      "        if int is just like providing only <end>\n",
      "    sampling : str, optional\n",
      "        '' (dayly) or '3hrs'\n",
      "    Model : str, optional\n",
      "        'Plasim', 'CESM', ... For now only Plasim is implemented\n",
      "    area : str, optional\n",
      "        region of interest, e.g. 'France'\n",
      "    filter_area : str, optional\n",
      "        area over which to keep filtered fields, usually the same of `area`. `filter` implies a mask\n",
      "    lon_start, lon_end, lat_start, lat_end : int\n",
      "        longitude and latitude extremes of the data expressed in indices (model specific)\n",
      "    mylocal : str or Path, optional\n",
      "        path the the data storage. For speed it is better if it is a local path.\n",
      "    fields : list, optional\n",
      "        list of field names to be loaded. Add '_filtered' to the name to have the values of the field outside `filter_area` set to zero.\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    _fields: dict\n",
      "        dictionary of ERA_Fields.Plasim_Field objects\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(ln.load_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the variable called `mylocal` governs the source of data. Depending on the machine we are using we might want to change it. For instance on r740server5, the local space is acutally: '/ClimateDynamics/MediumSpace/ClimateLearningFR/gmiloshe/PLASIM/';"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function prepare_XY in module Learn2_new:\n",
      "\n",
      "prepare_XY(fields, make_XY_kwargs=None, roll_X_kwargs=None, do_premix=False, premix_seed=0, do_balance_folds=True, nfolds=10, year_permutation=None, flatten_time_axis=True)\n",
      "    Performs all operations to extract from the fields X and Y ready to be fed to the neural network.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    fields : dict of ef.Plasim_Field objects\n",
      "    make_XY_kwargs : dict\n",
      "        arguments to pass to the function `make_XY`\n",
      "    roll_X_kwargs : dict\n",
      "        arguments to pass to the function `roll_X`\n",
      "    do_premix : bool, optional\n",
      "        whether to perform premixing, by default False\n",
      "    premix_seed : int, optional\n",
      "        seed for premixing, by default 0\n",
      "    do_balance_folds : bool, optional\n",
      "        whether to balance folds\n",
      "    nfolds : int, optional\n",
      "        necessary for balancing folds\n",
      "    year_permutation : np.ndarray, optional\n",
      "        if provided overrides both premixing and fold balancing, useful for transfer learning as avoids contaminating test sets. By default None\n",
      "    flatten_time_axis : bool, optional\n",
      "        whether to flatten the time axis consisting of years and days\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    X : np.ndarray\n",
      "        data. If flatten_time_axis with shape (days, lat, lon, fields), else (years, days, lat, lon, fields)\n",
      "    Y : np.ndarray \n",
      "        labels. If flatten_time_axis with shape (days,), else (years, days)\n",
      "    tot_permutation : np.ndarray\n",
      "        with shape (years,), final permutaion of the years that reproduces X and Y once applied to the just loaded data\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(ln.prepare_XY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And `ln.prepare_XY` calls `ln.make_XY` and `ln.roll_X`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function make_XY in module Learn2_new:\n",
      "\n",
      "make_XY(fields, label_field='t2m', time_start=30, time_end=120, T=14, tau=0, percent=5, threshold=None)\n",
      "    Combines `make_X` and `assign_labels`\n",
      "    \n",
      "    Parameters:\n",
      "    -----------\n",
      "    fields : dict of Plasim_Field objects\n",
      "    label_field : str, optional\n",
      "        key for the field used for computing labels\n",
      "    time_start : int, optional\n",
      "        first day of the period of interest\n",
      "    time_end : int, optional\n",
      "        first day after the end of the period of interst\n",
      "    T : int, optional\n",
      "        width of the window for the running average\n",
      "    tau : int, optional\n",
      "        delay between observation and prediction\n",
      "    percent : float, optional\n",
      "        percentage of the most extreme heatwaves\n",
      "    threshold : float, optional\n",
      "        if provided overrides `percent`\n",
      "    \n",
      "    Returns:\n",
      "    --------\n",
      "    X : np.ndarray\n",
      "        with shape (years, days, lat, lon, field)\n",
      "    Y : np.ndarray\n",
      "        with shape (years, days)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(ln.make_XY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function roll_X in module Learn2_new:\n",
      "\n",
      "roll_X(X, roll_axis='lon', roll_steps=64)\n",
      "    Rolls `X` along a given axis. useful for example for moving France away from the Greenwich meridian.\n",
      "    In other words this allows one, for example, to shift the grid so that desired areas are not found at the boundary.\n",
      "    In principle this function allows us to roll along arbitrary axis, including days or years.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    X : np.ndarray\n",
      "        with shape (years, days, lat, lon, field)\n",
      "    roll_axis : int or str, optional\n",
      "        'year' (or 'y'), 'day' (or 'd'), 'lat', 'lon', 'field' (or 'f')\n",
      "    roll_steps : int, optional\n",
      "        number of gridsteps to roll: a positive value for `roll_steps` means that the elements of the array are moved forward in it,\n",
      "        e.g. `roll_steps` = 1 means that the old first element is now in the second place\n",
      "        This means that for every axis a positive value of `roll_steps` yields a shift of the array\n",
      "        'year', 'day' : forward in time\n",
      "        'lat' : southward\n",
      "        'lon' : eastward\n",
      "        'field' : forward in the numbering of the fields\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    np.ndarray\n",
      "        of the same shape of `X`\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(ln.roll_X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, now let's say you want to call `ln.prepare_data` with just the temperature field, using data from the short 1000 years dataset and rolling `X` by 16 steps, leavingall other values at their default. One (cumbersome) way to do it is the following"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prepare_data:\n",
      "\tload_data:\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: b'/local/gmiloshe/PLASIM/Data_Plasim_inter/CONTROL_lsmask.nc'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_35235/1718156466.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m X, Y, yp = ln.prepare_data(load_data_kwargs = {'fields': ['t2m'], 'dataset_years': 1000},\n\u001b[0m\u001b[1;32m      2\u001b[0m                            prepare_XY_kwargs = {'roll_X_kwargs': {'roll_steps': 16}})\n",
      "\u001b[0;32m/ClimateDynamics/MediumSpace/ClimateLearningFR/gmiloshe/ERA/utilities.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    225\u001b[0m         \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m         \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'{func.__name__}:'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 227\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    228\u001b[0m         \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'{func.__name__}: completed in {pretty_time(time.time() - start_time)}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/ClimateDynamics/MediumSpace/ClimateLearningFR/gmiloshe/ERA/utilities.py\u001b[0m in \u001b[0;36mwrapper_inner\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    188\u001b[0m                     \u001b[0mstream\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindent_write\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 190\u001b[0;31m                 \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    191\u001b[0m             \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m                 \u001b[0;31m# restore original functions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/ClimateDynamics/MediumSpace/ClimateLearningFR/gmiloshe/PLASIM/Learn2_new.py\u001b[0m in \u001b[0;36mprepare_data\u001b[0;34m(load_data_kwargs, prepare_XY_kwargs)\u001b[0m\n\u001b[1;32m   1661\u001b[0m     \u001b[0;31m# load data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1662\u001b[0m     \u001b[0mfields\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mload_data_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1663\u001b[0;31m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1664\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mprepare_XY\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfields\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mprepare_XY_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1665\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/ClimateDynamics/MediumSpace/ClimateLearningFR/gmiloshe/ERA/utilities.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    225\u001b[0m         \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m         \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'{func.__name__}:'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 227\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    228\u001b[0m         \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'{func.__name__}: completed in {pretty_time(time.time() - start_time)}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/ClimateDynamics/MediumSpace/ClimateLearningFR/gmiloshe/ERA/utilities.py\u001b[0m in \u001b[0;36mwrapper_inner\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    188\u001b[0m                     \u001b[0mstream\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindent_write\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 190\u001b[0;31m                 \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    191\u001b[0m             \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m                 \u001b[0;31m# restore original functions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/ClimateDynamics/MediumSpace/ClimateLearningFR/gmiloshe/PLASIM/Learn2_new.py\u001b[0m in \u001b[0;36mload_data\u001b[0;34m(dataset_years, year_list, sampling, Model, area, filter_area, lon_start, lon_end, lat_start, lat_end, mylocal, fields)\u001b[0m\n\u001b[1;32m    656\u001b[0m         \u001b[0myear_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0myear_list\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# unpack the arguments of the tuple\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    657\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 658\u001b[0;31m     \u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell_area\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlsm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mef\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExtractAreaWithMask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmylocal\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mModel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0marea\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# extract land-sea mask and multiply it by cell area\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    659\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    660\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msampling\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'3hrs'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/ClimateDynamics/MediumSpace/ClimateLearningFR/gmiloshe/ERA/ERA_Fields_New.py\u001b[0m in \u001b[0;36mExtractAreaWithMask\u001b[0;34m(mylocal, Model, area)\u001b[0m\n\u001b[1;32m   1741\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mExtractAreaWithMask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmylocal\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mModel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0marea\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# extract land sea mask and multiply it by cell area\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1742\u001b[0m     \u001b[0;31m# Load the land area mask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1743\u001b[0;31m     \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmylocal\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'Data_Plasim_inter/CONTROL_lsmask.nc'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1744\u001b[0m     \u001b[0mlsm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvariables\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'lsm'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1745\u001b[0m     \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32msrc/netCDF4/_netCDF4.pyx\u001b[0m in \u001b[0;36mnetCDF4._netCDF4.Dataset.__init__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32msrc/netCDF4/_netCDF4.pyx\u001b[0m in \u001b[0;36mnetCDF4._netCDF4._ensure_nc_success\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: b'/local/gmiloshe/PLASIM/Data_Plasim_inter/CONTROL_lsmask.nc'"
     ]
    }
   ],
   "source": [
    "X, Y, yp = ln.prepare_data(load_data_kwargs = {'fields': ['t2m'], 'dataset_years': 1000},\n",
    "                           prepare_XY_kwargs = {'roll_X_kwargs': {'roll_steps': 16}})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If this command didn't work it is likely that you are running it from a machine which doesn't have the data in local space, or as mentioned earlier R740server5, in which case you need to specify the source in kwargs by doing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prepare_data:\n",
      "\tload_data:\n",
      "\t\tload_field:\n",
      "\t\t\tLoading field tas\n",
      "\t\t\tLoaded time array\n",
      "\t\t\tinput self.var.shape = (150000, 22, 128)\n",
      "\t\t\toutput self.var.shape = (1000, 150, 22, 128)\n",
      "\t\tload_field: completed in 21.3 s\n",
      "\t\tSet_area_integral:\n",
      "\t\tSet_area_integral: completed in 0.1 s\n",
      "\tload_data: completed in 21.4 s\n",
      "\tprepare_XY:\n",
      "\t\tmake_XY:\n",
      "\t\t\tmake_X:\n",
      "\t\t\tmake_X: completed in 0.3 s\n",
      "\t\t\tassign_labels:\n",
      "\t\t\tassign_labels: completed in 0.0 s\n",
      "\t\tmake_XY: completed in 0.3 s\n",
      "\t\troll_X:\n",
      "\t\troll_X: completed in 0.4 s\n",
      "\t\tMixing\n",
      "\t\tbalance_folds:\n",
      "\t\t\tBalancing folds\n",
      "\t\t\tfold 0 done!\n",
      "\t\t\tfold 1 done!\n",
      "\t\t\tfold 2 done!\n",
      "\t\t\tfold 3 done!\n",
      "\t\t\tfold 4 done!\n",
      "\t\t\tfold 5 done!\n",
      "\t\t\tfold 6 done!\n",
      "\t\t\tfold 7 done!\n",
      "\t\t\tfold 8 done!\n",
      "\t\t\tfold 9 done!\n",
      "\t\t\tSums of the balanced 10 folds:\n",
      "\t\t\t[385 385 385 385 385 385 385 385 385 385]\n",
      "\t\t\tstd/avg = 0.0\n",
      "\t\t\tmax relative deviation = 0.0\\%\n",
      "\t\tbalance_folds: completed in 0.0 s\n",
      "\t\tMixing completed in 0.2 s\n",
      "\t\t\n",
      "\t\tX.shape = (1000, 77, 22, 128, 1), Y.shape = (1000, 77)\n",
      "\t\tFlattened time: X.shape = (77000, 22, 128, 1), Y.shape = (77000,)\n",
      "\tprepare_XY: completed in 1.0 s\n",
      "prepare_data: completed in 22.4 s\n"
     ]
    }
   ],
   "source": [
    "X, Y, yp = ln.prepare_data(load_data_kwargs = {'fields': ['t2m'], 'dataset_years': 1000, 'mylocal':  '/ClimateDynamics/MediumSpace/ClimateLearningFR/gmiloshe/PLASIM/'},\n",
    "                           prepare_XY_kwargs = {'roll_X_kwargs': {'roll_steps': 16}})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Better approach\n",
    "\n",
    "If intstead you already roughly know how the code works, you can proceed in a more elegant way"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First create a dictionary of the default parameters using `ln.get_default_params`. Remeber to specify `recursive = True`, which will gather all the default parameters of the functions called in a nested manner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"load_data_kwargs\": {\n",
      "        \"dataset_years\": 8000,\n",
      "        \"year_list\": null,\n",
      "        \"sampling\": \"\",\n",
      "        \"Model\": \"Plasim\",\n",
      "        \"area\": \"France\",\n",
      "        \"filter_area\": \"France\",\n",
      "        \"lon_start\": 0,\n",
      "        \"lon_end\": 128,\n",
      "        \"lat_start\": 0,\n",
      "        \"lat_end\": 22,\n",
      "        \"mylocal\": \"/local/gmiloshe/PLASIM/\",\n",
      "        \"fields\": [\n",
      "            \"t2m\",\n",
      "            \"zg500\",\n",
      "            \"mrso_filtered\"\n",
      "        ]\n",
      "    },\n",
      "    \"prepare_XY_kwargs\": {\n",
      "        \"do_premix\": false,\n",
      "        \"premix_seed\": 0,\n",
      "        \"do_balance_folds\": true,\n",
      "        \"nfolds\": 10,\n",
      "        \"year_permutation\": null,\n",
      "        \"flatten_time_axis\": true,\n",
      "        \"make_XY_kwargs\": {\n",
      "            \"label_field\": \"t2m\",\n",
      "            \"time_start\": 30,\n",
      "            \"time_end\": 120,\n",
      "            \"T\": 14,\n",
      "            \"tau\": 0,\n",
      "            \"percent\": 5,\n",
      "            \"threshold\": null\n",
      "        },\n",
      "        \"roll_X_kwargs\": {\n",
      "            \"roll_axis\": \"lon\",\n",
      "            \"roll_steps\": 64\n",
      "        }\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "prepare_data_kwargs_default = ln.get_default_params(ln.prepare_data, recursive=True)\n",
    "print(ut.dict2str(prepare_data_kwargs_default)) # a nice way of printing nested dictionaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Again pay attention that the machine we are using has the data in space called 'local'. If so you don't need to specify the variable `mylocal` below)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you want to set the two parameters to non default values, and you can do it by using `ut.set_values_recursive`, without needing to account for the level of nestedness of the parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"load_data_kwargs\": {\n",
      "        \"dataset_years\": 1000,\n",
      "        \"year_list\": null,\n",
      "        \"sampling\": \"\",\n",
      "        \"Model\": \"Plasim\",\n",
      "        \"area\": \"France\",\n",
      "        \"filter_area\": \"France\",\n",
      "        \"lon_start\": 0,\n",
      "        \"lon_end\": 128,\n",
      "        \"lat_start\": 0,\n",
      "        \"lat_end\": 22,\n",
      "        \"mylocal\": \"/ClimateDynamics/MediumSpace/ClimateLearningFR/gmiloshe/PLASIM/\",\n",
      "        \"fields\": [\n",
      "            \"t2m\"\n",
      "        ]\n",
      "    },\n",
      "    \"prepare_XY_kwargs\": {\n",
      "        \"do_premix\": false,\n",
      "        \"premix_seed\": 0,\n",
      "        \"do_balance_folds\": true,\n",
      "        \"nfolds\": 10,\n",
      "        \"year_permutation\": null,\n",
      "        \"flatten_time_axis\": true,\n",
      "        \"make_XY_kwargs\": {\n",
      "            \"label_field\": \"t2m\",\n",
      "            \"time_start\": 30,\n",
      "            \"time_end\": 120,\n",
      "            \"T\": 14,\n",
      "            \"tau\": 0,\n",
      "            \"percent\": 5,\n",
      "            \"threshold\": null\n",
      "        },\n",
      "        \"roll_X_kwargs\": {\n",
      "            \"roll_axis\": \"lon\",\n",
      "            \"roll_steps\": 16\n",
      "        }\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "prepare_data_kwargs = ut.set_values_recursive(prepare_data_kwargs_default,\n",
    "                                              {'fields': ['t2m'], 'dataset_years': 1000, 'roll_steps': 16, 'mylocal': '/ClimateDynamics/MediumSpace/ClimateLearningFR/gmiloshe/PLASIM/'})\n",
    "print(ut.dict2str(prepare_data_kwargs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And then you can run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prepare_data:\n",
      "\tload_data:\n",
      "\t\tload_field:\n",
      "\t\t\tLoading field tas\n",
      "\t\t\tLoaded time array\n",
      "\t\t\tinput self.var.shape = (150000, 22, 128)\n",
      "\t\t\toutput self.var.shape = (1000, 150, 22, 128)\n",
      "\t\tload_field: completed in 5.6 s\n",
      "\t\tSet_area_integral:\n",
      "\t\tSet_area_integral: completed in 0.0 s\n",
      "\tload_data: completed in 5.6 s\n",
      "\tprepare_XY:\n",
      "\t\tmake_XY:\n",
      "\t\t\tmake_X:\n",
      "\t\t\tmake_X: completed in 0.2 s\n",
      "\t\t\tassign_labels:\n",
      "\t\t\tassign_labels: completed in 0.0 s\n",
      "\t\tmake_XY: completed in 0.3 s\n",
      "\t\troll_X:\n",
      "\t\troll_X: completed in 0.3 s\n",
      "\t\tMixing\n",
      "\t\tbalance_folds:\n",
      "\t\t\tBalancing folds\n",
      "\t\t\tfold 0 done!\n",
      "\t\t\tfold 1 done!\n",
      "\t\t\tfold 2 done!\n",
      "\t\t\tfold 3 done!\n",
      "\t\t\tfold 4 done!\n",
      "\t\t\tfold 5 done!\n",
      "\t\t\tfold 6 done!\n",
      "\t\t\tfold 7 done!\n",
      "\t\t\tfold 8 done!\n",
      "\t\t\tfold 9 done!\n",
      "\t\t\tSums of the balanced 10 folds:\n",
      "\t\t\t[385 385 385 385 385 385 385 385 385 385]\n",
      "\t\t\tstd/avg = 0.0\n",
      "\t\t\tmax relative deviation = 0.0\\%\n",
      "\t\tbalance_folds: completed in 0.0 s\n",
      "\t\tMixing completed in 0.2 s\n",
      "\t\t\n",
      "\t\tX.shape = (1000, 77, 22, 128, 1), Y.shape = (1000, 77)\n",
      "\t\tFlattened time: X.shape = (77000, 22, 128, 1), Y.shape = (77000,)\n",
      "\tprepare_XY: completed in 0.8 s\n",
      "prepare_data: completed in 6.5 s\n"
     ]
    }
   ],
   "source": [
    "X, Y, yp = ln.prepare_data(**prepare_data_kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to load your default values from a config file, you can do as following"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"run_kwargs\": {\n",
      "        \"log_level\": 20,\n",
      "        \"load_data_kwargs\": {\n",
      "            \"dataset_years\": 8000,\n",
      "            \"year_list\": null,\n",
      "            \"sampling\": \"\",\n",
      "            \"Model\": \"Plasim\",\n",
      "            \"area\": \"France\",\n",
      "            \"filter_area\": \"France\",\n",
      "            \"lon_start\": 0,\n",
      "            \"lon_end\": 128,\n",
      "            \"lat_start\": 0,\n",
      "            \"lat_end\": 22,\n",
      "            \"mylocal\": \"/local/gmiloshe/PLASIM/\",\n",
      "            \"fields\": [\n",
      "                \"t2m\",\n",
      "                \"zg500\",\n",
      "                \"mrso_filtered\"\n",
      "            ]\n",
      "        },\n",
      "        \"prepare_XY_kwargs\": {\n",
      "            \"do_premix\": false,\n",
      "            \"premix_seed\": 0,\n",
      "            \"do_balance_folds\": true,\n",
      "            \"nfolds\": 10,\n",
      "            \"year_permutation\": null,\n",
      "            \"flatten_time_axis\": true,\n",
      "            \"make_XY_kwargs\": {\n",
      "                \"label_field\": \"t2m\",\n",
      "                \"time_start\": 30,\n",
      "                \"time_end\": 120,\n",
      "                \"T\": 14,\n",
      "                \"tau\": 0,\n",
      "                \"percent\": 5,\n",
      "                \"threshold\": null\n",
      "            },\n",
      "            \"roll_X_kwargs\": {\n",
      "                \"roll_axis\": \"lon\",\n",
      "                \"roll_steps\": 64\n",
      "            }\n",
      "        },\n",
      "        \"k_fold_cross_val_kwargs\": {\n",
      "            \"load_from\": \"last\",\n",
      "            \"nfolds\": 10,\n",
      "            \"val_folds\": 1,\n",
      "            \"u\": 1,\n",
      "            \"fullmetrics\": true,\n",
      "            \"training_epochs\": 40,\n",
      "            \"training_epochs_tl\": 10,\n",
      "            \"loss\": \"sparse_categorical_crossentropy\",\n",
      "            \"lr\": 0.0001,\n",
      "            \"create_model_kwargs\": {\n",
      "                \"conv_channels\": [\n",
      "                    32,\n",
      "                    64,\n",
      "                    64\n",
      "                ],\n",
      "                \"kernel_sizes\": 3,\n",
      "                \"strides\": 1,\n",
      "                \"batch_normalizations\": true,\n",
      "                \"conv_activations\": \"relu\",\n",
      "                \"conv_dropouts\": 0.2,\n",
      "                \"max_pool_sizes\": [\n",
      "                    2,\n",
      "                    2,\n",
      "                    false\n",
      "                ],\n",
      "                \"dense_units\": [\n",
      "                    64,\n",
      "                    2\n",
      "                ],\n",
      "                \"dense_activations\": [\n",
      "                    \"relu\",\n",
      "                    null\n",
      "                ],\n",
      "                \"dense_dropouts\": [\n",
      "                    0.2,\n",
      "                    false\n",
      "                ]\n",
      "            },\n",
      "            \"train_model_kwargs\": {\n",
      "                \"enable_early_stopping\": false,\n",
      "                \"batch_size\": 1024,\n",
      "                \"checkpoint_every\": 1,\n",
      "                \"additional_callbacks\": [\n",
      "                    \"csv_logger\"\n",
      "                ],\n",
      "                \"early_stopping_kwargs\": {\n",
      "                    \"monitor\": \"val_CustomLoss\",\n",
      "                    \"min_delta\": 0,\n",
      "                    \"patience\": 0,\n",
      "                    \"mode\": \"auto\"\n",
      "                }\n",
      "            },\n",
      "            \"optimal_checkpoint_kwargs\": {\n",
      "                \"metric\": \"val_CustomLoss\",\n",
      "                \"direction\": \"minimize\",\n",
      "                \"first_epoch\": 1,\n",
      "                \"collective\": true,\n",
      "                \"bypass\": null\n",
      "            }\n",
      "        }\n",
      "    },\n",
      "    \"telegram_kwargs\": {\n",
      "        \"telegram_bot_token\": \"~/ENSMLbot.txt\",\n",
      "        \"chat_ID\": null,\n",
      "        \"telegram_logging_level\": 31,\n",
      "        \"telegram_logging_format\": null\n",
      "    }\n",
      "}\n",
      "\n",
      "\n",
      "\n",
      "{\n",
      "    \"log_level\": 20,\n",
      "    \"dataset_years\": 8000,\n",
      "    \"year_list\": null,\n",
      "    \"sampling\": \"\",\n",
      "    \"Model\": \"Plasim\",\n",
      "    \"area\": \"France\",\n",
      "    \"filter_area\": \"France\",\n",
      "    \"lon_start\": 0,\n",
      "    \"lon_end\": 128,\n",
      "    \"lat_start\": 0,\n",
      "    \"lat_end\": 22,\n",
      "    \"mylocal\": \"/local/gmiloshe/PLASIM/\",\n",
      "    \"fields\": [\n",
      "        \"t2m\",\n",
      "        \"zg500\",\n",
      "        \"mrso_filtered\"\n",
      "    ],\n",
      "    \"do_premix\": false,\n",
      "    \"premix_seed\": 0,\n",
      "    \"do_balance_folds\": true,\n",
      "    \"nfolds\": 10,\n",
      "    \"year_permutation\": null,\n",
      "    \"flatten_time_axis\": true,\n",
      "    \"label_field\": \"t2m\",\n",
      "    \"time_start\": 30,\n",
      "    \"time_end\": 120,\n",
      "    \"T\": 14,\n",
      "    \"tau\": 0,\n",
      "    \"percent\": 5,\n",
      "    \"threshold\": null,\n",
      "    \"roll_axis\": \"lon\",\n",
      "    \"roll_steps\": 64,\n",
      "    \"load_from\": \"last\",\n",
      "    \"val_folds\": 1,\n",
      "    \"u\": 1,\n",
      "    \"fullmetrics\": true,\n",
      "    \"training_epochs\": 40,\n",
      "    \"training_epochs_tl\": 10,\n",
      "    \"loss\": \"sparse_categorical_crossentropy\",\n",
      "    \"lr\": 0.0001,\n",
      "    \"conv_channels\": [\n",
      "        32,\n",
      "        64,\n",
      "        64\n",
      "    ],\n",
      "    \"kernel_sizes\": 3,\n",
      "    \"strides\": 1,\n",
      "    \"batch_normalizations\": true,\n",
      "    \"conv_activations\": \"relu\",\n",
      "    \"conv_dropouts\": 0.2,\n",
      "    \"max_pool_sizes\": [\n",
      "        2,\n",
      "        2,\n",
      "        false\n",
      "    ],\n",
      "    \"dense_units\": [\n",
      "        64,\n",
      "        2\n",
      "    ],\n",
      "    \"dense_activations\": [\n",
      "        \"relu\",\n",
      "        null\n",
      "    ],\n",
      "    \"dense_dropouts\": [\n",
      "        0.2,\n",
      "        false\n",
      "    ],\n",
      "    \"enable_early_stopping\": false,\n",
      "    \"batch_size\": 1024,\n",
      "    \"checkpoint_every\": 1,\n",
      "    \"additional_callbacks\": [\n",
      "        \"csv_logger\"\n",
      "    ],\n",
      "    \"monitor\": \"val_CustomLoss\",\n",
      "    \"min_delta\": 0,\n",
      "    \"patience\": 0,\n",
      "    \"mode\": \"auto\",\n",
      "    \"metric\": \"val_CustomLoss\",\n",
      "    \"direction\": \"minimize\",\n",
      "    \"first_epoch\": 1,\n",
      "    \"collective\": true,\n",
      "    \"bypass\": null,\n",
      "    \"telegram_bot_token\": \"~/ENSMLbot.txt\",\n",
      "    \"chat_ID\": null,\n",
      "    \"telegram_logging_level\": 31,\n",
      "    \"telegram_logging_format\": null\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "config_dict = ut.json2dict('example_config.json') # load the config file\n",
    "print(ut.dict2str(config_dict))\n",
    "print('\\n\\n')\n",
    "config_dict_flat = ut.collapse_dict(config_dict) # flatten the dictionary\n",
    "print(ut.dict2str(config_dict_flat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'nice_dict_print' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_35235/2903939927.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mut\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_values_recursive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprepare_data_kwargs_default\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig_dict_flat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mnice_dict_print\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprepare_data_kwargs_default\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'nice_dict_print' is not defined"
     ]
    }
   ],
   "source": [
    "ut.set_values_recursive(prepare_data_kwargs_default, config_dict_flat, inplace=True)\n",
    "nice_dict_print(prepare_data_kwargs_default)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We had to do this way because `prepare_data_kwargs` is not a key of the config dictionary. Let's say instead you wanted the default arguments for the function `make_XY`, you could have simply done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**GM**: Where does the function `nice_dict_print` come from?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_XY_kwargs_default = ut.extract_nested(config_dict, 'make_XY_kwargs')\n",
    "print(ut.dict2str(make_XY_kwargs_default))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Where the function `ut.extract_nested` allows to obtain a key from a nested dictionary regardless of the level of indentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(77000, 22, 128, 1)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5a0ac5ce8bb8c88950cbb5884951ac07e03bb695621e79d254d25c8e1304a15f"
  },
  "kernelspec": {
   "display_name": "kernel3.9",
   "language": "python",
   "name": "kernel3.9"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
