{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "06cf35f6-5fa3-4387-a0bc-041820da3282",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\n",
      "fold_folder = PosixPath('xforanalogs/tests/testL2linear/fold_0')\n",
      "loading module from  xforanalogs/tests/testL2linear/Funs.py\n",
      "Note: NumExpr detected 64 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 8.\n",
      "NumExpr defaulting to 8 threads.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-16 17:31:53.400099: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "path_to_ERA = '/ClimateDynamics/MediumSpace/ClimateLearningFR/gmiloshe'/ERA/\n",
      "Trying to import basemap\n",
      "In this environment you cannot import Basemap\n",
      "Trying to import cartopy\n",
      "Trying to import basemap\n",
      "In this environment you cannot import Basemap\n",
      "Trying to import cartopy\n",
      "Successfully imported cartopy\n",
      "Successfully imported cartopy\n",
      "==Checking GPU==\n",
      "From xforanalogs/tests/testL2linear/Funs.py:45: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.config.list_physical_devices('GPU')` instead.\n",
      "==Checking CUDA==\n",
      "==Importing tensorflow packages===\n",
      "==Checking GPU==\n",
      "==Checking CUDA==\n",
      "==Reading data==\n",
      "\u001b[0m\n",
      "run_vae_kwargs = {'myinput': 'N', 'XY_run_vae_keywargs': None, 'log_level': 20, 'k_fold_cross_val_kwargs': {'keep_dims': [1], 'nfolds': 10, 'val_folds': 1, 'range_nfolds': None, 'u': 1, 'normalization_mode': 'global_logit', 'classification': True, 'evaluate_epoch': 'last', 'repeat_nan': 5, 'create_or_load_vae_kwargs': {'checkpoint_every': 10, 'VAE_kwargs': {'k1': 18, 'k2': 0.1, 'from_logits': False, 'field_weights': None, 'lat_0': None, 'lat_1': None, 'lon_0': None, 'lon_1': None, 'coef_out': 1, 'coef_in': 0, 'coef_class': 0, 'loss_type': 'L2', 'class_type': 'stochastic', 'mask_area': 'France', 'Z_DIM': 16, 'N_EPOCHS': 100, 'print_summary': True}, 'build_encoder_skip_kwargs': {'encoder_conv_filters': [32, 64, 64, 64], 'encoder_conv_kernel_size': [3, 3, 3, 3], 'encoder_conv_strides': [2, 2, 2, 1], 'encoder_conv_padding': ['same', 'same', 'same', 'valid'], 'encoder_conv_activation': ['LeakyRelu', 'LeakyRelu', 'LeakyRelu', 'LeakyRelu'], 'encoder_conv_skip': None, 'encoder_use_batch_norm': [False, False, False, False], 'encoder_use_dropout': [0, 0, 0, 0]}, 'build_decoder_skip_kwargs': {'decoder_conv_filters': [64, 64, 32, 1], 'decoder_conv_kernel_size': [3, 3, 3, 3], 'decoder_conv_strides': [1, 2, 2, 2], 'decoder_conv_padding': ['valid', 'same', 'same', 'same'], 'decoder_conv_activation': ['LeakyRelu', 'LeakyRelu', 'LeakyRelu', 'linear'], 'decoder_conv_skip': None, 'decoder_use_batch_norm': [False, False, False, False], 'decoder_use_dropout': [0, 0, 0, 0], 'usemask': False, 'reshape_activation': 'relu'}, 'create_classifier_kwargs': {'L2factor': None}}, 'train_vae_kwargs': {'batch_size': 128, 'validation_data': True, 'scheduler_kwargs': {'lr': 0.001, 'epoch_tol': None, 'lr_min': 0.0005}}}, 'load_data_kwargs': {'dataset_years': 8000, 'year_list': 'range(500)', 'sampling': '', 'Model': 'Plasim', 'area': 'France', 'filter_area': 'France', 'lon_start': 98, 'lon_end': 18, 'lat_start': 0, 'lat_end': 24, 'mylocal': '/local/gmiloshe/PLASIM/', 'fields': ['t2m_inter_filtered', 'zg500_inter', 'mrso_inter_filtered'], 'preprefix': 'ANO_'}, 'prepare_XY_kwargs': {'do_premix': False, 'premix_seed': 0, 'do_balance_folds': True, 'nfolds': 10, 'year_permutation': None, 'flatten_time_axis': True, 'return_time_series': True, 'make_XY_kwargs': {'label_field': 't2m_inter', 'time_start': 15, 'time_end': 134, 'T': 15, 'tau': 0, 'percent': 5, 'threshold': None, 'label_period_start': 30, 'label_period_end': 120, 'A_weights': [3, 0, 0, 3, 0, 0, 3, 0, 0, 3, 0, 0, 3, 0, 0], 'return_threshold': True}, 'roll_X_kwargs': {'roll_axis': 'lon', 'roll_steps': 0}}}\n",
      "run_vae:\n",
      "    myinput = 'N'\n",
      "     inputs lat_W = 24, lon_W = 48\n",
      "    encoder_conv_filters1 = 32, encoder_conv_kernel_size1 = 3, encoder_conv_strides1 = 2, encoder_conv_padding1 = 'same'\n",
      "     processing layer results in the dimension lat_W = 12.0, lon_W = 24.0\n",
      "    encoder_conv_filters1 = 64, encoder_conv_kernel_size1 = 3, encoder_conv_strides1 = 2, encoder_conv_padding1 = 'same'\n",
      "     processing layer results in the dimension lat_W = 6.0, lon_W = 12.0\n",
      "    encoder_conv_filters1 = 64, encoder_conv_kernel_size1 = 3, encoder_conv_strides1 = 2, encoder_conv_padding1 = 'same'\n",
      "     processing layer results in the dimension lat_W = 3.0, lon_W = 6.0\n",
      "    encoder_conv_filters1 = 64, encoder_conv_kernel_size1 = 3, encoder_conv_strides1 = 1, encoder_conv_padding1 = 'valid'\n",
      "     processing layer results in the dimension lat_W = 1.0, lon_W = 4.0\n",
      "    decoder_conv_filters1 = 64, decoder_conv_kernel_size1 = 3, decoder_conv_strides1 = 1, decoder_conv_padding1 = 'valid'\n",
      "     processing layer results in the dimension lat_W = 3.0, lon_W = 6.0\n",
      "    decoder_conv_filters1 = 64, decoder_conv_kernel_size1 = 3, decoder_conv_strides1 = 2, decoder_conv_padding1 = 'same'\n",
      "     processing layer results in the dimension lat_W = 6.0, lon_W = 12.0\n",
      "    decoder_conv_filters1 = 32, decoder_conv_kernel_size1 = 3, decoder_conv_strides1 = 2, decoder_conv_padding1 = 'same'\n",
      "     processing layer results in the dimension lat_W = 12.0, lon_W = 24.0\n",
      "    decoder_conv_filters1 = 1, decoder_conv_kernel_size1 = 3, decoder_conv_strides1 = 2, decoder_conv_padding1 = 'same'\n",
      "     processing layer results in the dimension lat_W = 24.0, lon_W = 48.0\n",
      "     pausing for 2 seconds...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-16 17:32:04.501971: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-11-16 17:32:04.600009: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2300000000 Hz\n",
      "2022-11-16 17:32:04.659120: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55edf06be110 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2022-11-16 17:32:04.659173: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "2022-11-16 17:32:04.663691: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\n",
      "2022-11-16 17:32:04.968800: E tensorflow/stream_executor/cuda/cuda_driver.cc:328] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2022-11-16 17:32:04.968856: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (apollo2048g): /proc/driver/nvidia/version does not exist\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    prepare_data_and_mask:\n",
      "        load_data:\n",
      "            Opening field tas\n",
      "            monotonize_years:\n",
      "            monotonize_years: completed in 3.9 s\n",
      "            select_years:\n",
      "            select_years: completed in 0.7 s\n",
      "            select_lonlat:\n",
      "            select_lonlat: completed in 2.8 s\n",
      "            Opening field zg\n",
      "            monotonize_years:\n",
      "            monotonize_years: completed in 4.2 s\n",
      "            select_years:\n",
      "            select_years: completed in 0.7 s\n",
      "            select_lonlat:\n",
      "            select_lonlat: completed in 2.9 s\n",
      "            Opening field mrso\n",
      "            monotonize_years:\n",
      "            monotonize_years: completed in 4.0 s\n",
      "            select_years:\n",
      "            select_years: completed in 0.7 s\n",
      "            select_lonlat:\n",
      "            select_lonlat: completed in 2.7 s\n",
      "        load_data: completed in 1 min 36.3 s\n",
      "        prepare_XY:\n",
      "            return_threshold = True            \n",
      "            make_XY:\n",
      "                make_X:\n",
      "                make_X: completed in 0.5 s\n",
      "                assign_labels:\n",
      "                    A_weights = [3, 0, 0, 3, 0, 0, 3, 0, 0, 3, 0, 0, 3, 0, 0]\n",
      "                    compute_time_average:\n",
      "                    \tcompute_area_integral:\n",
      "                    \tcompute_area_integral: completed in 0.8 s\n",
      "                    compute_time_average: completed in 2.8 s\n",
      "                    compute_time_average:\n",
      "                    compute_time_average: completed in 2.0 s\n",
      "                    threshold_new = 2.742728328704834\n",
      "                assign_labels: completed in 4.8 s\n",
      "            make_XY: completed in 5.3 s\n",
      "            roll_X:\n",
      "            roll_X: completed in 0.0 s\n",
      "            Mixing\n",
      "             label_period_start = 30 ;time_start = 15 ;time_end = 134 ;label_period_end = 120 \n",
      "            Y.shape = (500, 105), from 15 to 91 \n",
      "            balance_folds:\n",
      "                Balancing folds\n",
      "                fold 0 done!\n",
      "                fold 1 done!\n",
      "                fold 2 done!\n",
      "                fold 3 done!\n",
      "                fold 4 done!\n",
      "                fold 5 done!\n",
      "                fold 6 done!\n",
      "                fold 7 done!\n",
      "                fold 8 done!\n",
      "                fold 9 done!\n",
      "                Sums of the balanced 10 folds:\n",
      "                [190 190 190 190 190 190 190 190 190 190]\n",
      "                std/avg = 0.000\n",
      "                max relative deviation = 0.000\\%\n",
      "            balance_folds: completed in 0.0 s\n",
      "            Mixing completed in 0.4 s\n",
      "            \n",
      "            X.shape = (500, 105, 24, 48, 3), Y.shape = (500, 105)\n",
      "            Flattened time: X.shape = (52500, 24, 48, 3), Y.shape = (52500,)\n",
      "            compute_area_integral:\n",
      "            compute_area_integral: completed in 0.5 s\n",
      "            compute_area_integral:\n",
      "            compute_area_integral: completed in 0.4 s\n",
      "            time_series = [array([ 5.9059734 ,  5.2596064 ,  4.960754  , ...,  0.02219056,\n",
      "                   -1.21639   , -2.130549  ], dtype=float32), array([104.05559 , 109.004776, 107.45358 , ..., -49.361618, -46.130516,\n",
      "                   -39.455868], dtype=float32), array([-0.05739938, -0.05798355, -0.05831986, ..., -0.00390428,\n",
      "                   -0.00320801, -0.00268412], dtype=float32)]\n",
      "            time_series.shape = (52500, 3)\n",
      "        prepare_XY: completed in 7.1 s\n",
      "    prepare_data_and_mask: completed in 1 min 43.5 s\n",
      "    X.shape = (52500, 24, 48, 3)    \n",
      "    k_fold_cross_val:\n",
      "        xforanalogs/tests/testL2linear/fold_0/fold_num.npy exists\n",
      "        range_nfolds = [0]\n",
      "        =============\n",
      "        fold 0 (1/10)\n",
      "        =============\n",
      "        repeat_nan_local = 5\n",
      "        xforanalogs/tests/testL2linear/fold_0/fold_num.npy exists\n",
      "        i = 0, X.shape = (52500, 24, 48, 3), Y.shape = (52500,), nfolds=10, val_folds=1\n",
      "        We are working in the mode reconstruction = True\n",
      "        INPUT_DIM = (24, 48, 3)\n",
      "        normalize_X:\n",
      "            ===Normalizing X===\n",
      "            loading xforanalogs/tests/testL2linear/fold_0/X_mean.npy\n",
      "        normalize_X: completed in 1.3 s\n",
      "        create_or_load_vae_kwargs = {'checkpoint_every': 10, 'VAE_kwargs': {'k1': 18, 'k2': 0.1, 'from_logits': False, 'field_weights': None, 'lat_0': None, 'lat_1': None, 'lon_0': None, 'lon_1': None, 'coef_out': 1, 'coef_in': 0, 'coef_class': 0, 'loss_type': 'L2', 'class_type': 'stochastic', 'mask_area': 'France', 'Z_DIM': 16, 'N_EPOCHS': 100, 'print_summary': True}, 'build_encoder_skip_kwargs': {'encoder_conv_filters': [32, 64, 64, 64], 'encoder_conv_kernel_size': [3, 3, 3, 3], 'encoder_conv_strides': [2, 2, 2, 1], 'encoder_conv_padding': ['same', 'same', 'same', 'valid'], 'encoder_conv_activation': ['LeakyRelu', 'LeakyRelu', 'LeakyRelu', 'LeakyRelu'], 'encoder_conv_skip': None, 'encoder_use_batch_norm': [False, False, False, False], 'encoder_use_dropout': [0, 0, 0, 0]}, 'build_decoder_skip_kwargs': {'decoder_conv_filters': [64, 64, 32, 1], 'decoder_conv_kernel_size': [3, 3, 3, 3], 'decoder_conv_strides': [1, 2, 2, 2], 'decoder_conv_padding': ['valid', 'same', 'same', 'same'], 'decoder_conv_activation': ['LeakyRelu', 'LeakyRelu', 'LeakyRelu', 'linear'], 'decoder_conv_skip': None, 'decoder_use_batch_norm': [False, False, False, False], 'decoder_use_dropout': [0, 0, 0, 0], 'usemask': False, 'reshape_activation': 'relu'}, 'create_classifier_kwargs': {'L2factor': None}}\n",
      "        type(keep_dims) = <class 'list'>, keep_dims = [1]\n",
      "        X_va.shape = (52500, 24, 48, 1)\n",
      "        recomputing: INPUT_DIM = (24, 48, 1)\n",
      "        create_or_load_vae:\n",
      "            INPUT_DIM[:-1] = (24, 48)            \n",
      "            filter_mask.shape = (24, 48)\n",
      "            ones_dim.shape = (24, 48)\n",
      "            np.array([filter_mask,ones_dim,filter_mask], dtype=bool).shape = (3, 24, 48)\n",
      "            bool\n",
      "            ==Building encoder==\n",
      "            shape_before_flattening =                          (1, 4, 64)            \n",
      "            AutoGraph could not transform <bound method Sampling.call of <ERA.TF_Fields.Sampling object at 0x7f551a671970>> and will run it as-is.\n",
      "            Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "            Cause: module 'gast' has no attribute 'Index'\n",
      "            To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "            WARNING: AutoGraph could not transform <bound method Sampling.call of <ERA.TF_Fields.Sampling object at 0x7f551a671970>> and will run it as-is.\n",
      "            Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "            Cause: module 'gast' has no attribute 'Index'\n",
      "            To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert            \n",
      "            Model: \"encoder\"            \n",
      "            __________________________________________________________________________________________________            \n",
      "            Layer (type)                    Output Shape         Param #     Connected to                                 \n",
      "            ==================================================================================================            \n",
      "            encoder input (InputLayer)      [(None, 24, 48, 1)]  0                                                        \n",
      "            __________________________________________________________________________________________________            \n",
      "            encoder_conv_0 (Conv2D)         (None, 12, 24, 32)   320         encoder input[0][0]                          \n",
      "            __________________________________________________________________________________________________            \n",
      "            leaky_re_lu (LeakyReLU)         (None, 12, 24, 32)   0           encoder_conv_0[0][0]                         \n",
      "            __________________________________________________________________________________________________            \n",
      "            encoder_conv_1 (Conv2D)         (None, 6, 12, 64)    18496       leaky_re_lu[0][0]                            \n",
      "            __________________________________________________________________________________________________            \n",
      "            leaky_re_lu_1 (LeakyReLU)       (None, 6, 12, 64)    0           encoder_conv_1[0][0]                         \n",
      "            __________________________________________________________________________________________________            \n",
      "            encoder_conv_2 (Conv2D)         (None, 3, 6, 64)     36928       leaky_re_lu_1[0][0]                          \n",
      "            __________________________________________________________________________________________________            \n",
      "            leaky_re_lu_2 (LeakyReLU)       (None, 3, 6, 64)     0           encoder_conv_2[0][0]                         \n",
      "            __________________________________________________________________________________________________            \n",
      "            encoder_conv_3 (Conv2D)         (None, 1, 4, 64)     36928       leaky_re_lu_2[0][0]                          \n",
      "            __________________________________________________________________________________________________            \n",
      "            leaky_re_lu_3 (LeakyReLU)       (None, 1, 4, 64)     0           encoder_conv_3[0][0]                         \n",
      "            __________________________________________________________________________________________________            \n",
      "            flatten (Flatten)               (None, 256)          0           leaky_re_lu_3[0][0]                          \n",
      "            __________________________________________________________________________________________________            \n",
      "            z_mean (Dense)                  (None, 16)           4112        flatten[0][0]                                \n",
      "            __________________________________________________________________________________________________            \n",
      "            z_log_var (Dense)               (None, 16)           4112        flatten[0][0]                                \n",
      "            __________________________________________________________________________________________________            \n",
      "            sampling (Sampling)             (None, 16)           0           z_mean[0][0]                                 \n",
      "                                                                             z_log_var[0][0]                              \n",
      "            ==================================================================================================            \n",
      "            Total params: 100,896            \n",
      "            Trainable params: 100,896            \n",
      "            Non-trainable params: 0            \n",
      "            __________________________________________________________________________________________________            \n",
      "            ==Building decoder==\n",
      "            filter_mask.shape = (24, 48, 3)\n",
      "            Model: \"decoder\"            \n",
      "            _________________________________________________________________            \n",
      "            Layer (type)                 Output Shape              Param #               \n",
      "            =================================================================            \n",
      "            input_1 (InputLayer)         [(None, 16)]              0                     \n",
      "            _________________________________________________________________            \n",
      "            dense_1 (Dense)              (None, 256)               4352                  \n",
      "            _________________________________________________________________            \n",
      "            reshape (Reshape)            (None, 1, 4, 64)          0                     \n",
      "            _________________________________________________________________            \n",
      "            decoder_conv_0 (Conv2DTransp (None, 3, 6, 64)          36928                 \n",
      "            _________________________________________________________________            \n",
      "            leaky_re_lu_4 (LeakyReLU)    (None, 3, 6, 64)          0                     \n",
      "            _________________________________________________________________            \n",
      "            decoder_conv_1 (Conv2DTransp (None, 6, 12, 64)         36928                 \n",
      "            _________________________________________________________________            \n",
      "            leaky_re_lu_5 (LeakyReLU)    (None, 6, 12, 64)         0                     \n",
      "            _________________________________________________________________            \n",
      "            decoder_conv_2 (Conv2DTransp (None, 12, 24, 32)        18464                 \n",
      "            _________________________________________________________________            \n",
      "            leaky_re_lu_6 (LeakyReLU)    (None, 12, 24, 32)        0                     \n",
      "            _________________________________________________________________            \n",
      "            decoder_conv_3 (Conv2DTransp (None, 24, 48, 1)         289                   \n",
      "            _________________________________________________________________            \n",
      "            activation (Activation)      (None, 24, 48, 1)         0                     \n",
      "            =================================================================            \n",
      "            Total params: 96,961            \n",
      "            Trainable params: 96,961            \n",
      "            Non-trainable params: 0            \n",
      "            _________________________________________________________________            \n",
      "            ==Attaching decoder and encoder and compiling==\n",
      "            self.classifier = <tensorflow.python.keras.engine.functional.Functional object at 0x7f5a8f3f5ca0>            \n",
      "            vae.k1 = 18,vae.k2 = 0.1 \n",
      "            ==loading the model: xforanalogs/tests/testL2linear/fold_0\n",
      "            loading weights checkpoint_path = 'xforanalogs/tests/testL2linear/fold_0/cp_vae-0100.ckpt'\n",
      "            INITIAL_EPOCH = 100\n",
      "            Model: \"vae\"            \n",
      "            _________________________________________________________________            \n",
      "            Layer (type)                 Output Shape              Param #               \n",
      "            =================================================================            \n",
      "            encoder (Functional)         [(None, 16), (None, 16),  100896                \n",
      "            _________________________________________________________________            \n",
      "            decoder (Functional)         (None, 24, 48, 1)         96961                 \n",
      "            _________________________________________________________________            \n",
      "            classifier (Functional)      (None, 1)                 17                    \n",
      "            =================================================================            \n",
      "            Total params: 197,882            \n",
      "            Trainable params: 197,874            \n",
      "            Non-trainable params: 8            \n",
      "            _________________________________________________________________            \n",
      "            `period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "            ckpt_path_callback = <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f551a671a00>\n",
      "        create_or_load_vae: completed in 0.4 s\n",
      "        len(vae.trainable_weights) = 24, len(vae.encoder.trainable_weights) = 12, len(vae.decoder.trainable_weights) = 10\n",
      "        vae.encoder layers: inner_layer.name = 'encoder_conv_0'\n",
      "        inner_layer.weights[0][0,0,0,:] = <tf.Tensor: shape=(32,), dtype=float32, numpy=\n",
      "        array([ 0.01849275,  0.01136143, -0.06794339, -0.09340695, -0.05999703,\n",
      "                0.04673884,  0.07617673,  0.10689891, -0.04793035, -0.02913836,\n",
      "               -0.03331755,  0.04697365, -0.05656735, -0.03361843, -0.01816155,\n",
      "               -0.02409679, -0.05137702,  0.00735218,  0.04629302,  0.0913296 ,\n",
      "                0.01859755, -0.08327977,  0.004826  ,  0.12902243,  0.055927  ,\n",
      "               -0.09458552, -0.08391007,  0.14389545,  0.06088597, -0.18691197,\n",
      "                0.12918237, -0.08873079], dtype=float32)>\n",
      "        vae.classifier layers: inner_layer.name = 'classifier input'\n",
      "        inner_layer.weights = []\n",
      "        vae.classifier layers: inner_layer.name = 'dense'\n",
      "        inner_layer.weights = [<tf.Variable 'dense/kernel:0' shape=(16, 1) dtype=float32, numpy=\n",
      "        array([[-0.41812375],\n",
      "               [ 0.03896284],\n",
      "               [ 0.3401593 ],\n",
      "               [ 0.01312977],\n",
      "               [-0.26150012],\n",
      "               [-0.4657386 ],\n",
      "               [-0.47026733],\n",
      "               [-0.49402177],\n",
      "               [-0.26770842],\n",
      "               [-0.38632405],\n",
      "               [-0.23352417],\n",
      "               [-0.10596645],\n",
      "               [ 0.22930682],\n",
      "               [-0.15854585],\n",
      "               [-0.32876438],\n",
      "               [ 0.46394813]], dtype=float32)>, <tf.Variable 'dense/bias:0' shape=(1,) dtype=float32, numpy=array([0.], dtype=float32)>]\n",
      "        len(vae.trainable_weights) = 24, len(vae.encoder.trainable_weights) = 12, len(vae.decoder.trainable_weights) = 10\n",
      "        vae.encoder layers: inner_layer.name = 'encoder_conv_0'\n",
      "        inner_layer.weights[0][0,0,0,:] = <tf.Tensor: shape=(32,), dtype=float32, numpy=\n",
      "        array([ 0.01849275,  0.01136143, -0.06794339, -0.09340695, -0.05999703,\n",
      "                0.04673884,  0.07617673,  0.10689891, -0.04793035, -0.02913836,\n",
      "               -0.03331755,  0.04697365, -0.05656735, -0.03361843, -0.01816155,\n",
      "               -0.02409679, -0.05137702,  0.00735218,  0.04629302,  0.0913296 ,\n",
      "                0.01859755, -0.08327977,  0.004826  ,  0.12902243,  0.055927  ,\n",
      "               -0.09458552, -0.08391007,  0.14389545,  0.06088597, -0.18691197,\n",
      "                0.12918237, -0.08873079], dtype=float32)>\n",
      "        vae.classifier layers: inner_layer.name = 'classifier input'\n",
      "        inner_layer.weights = []\n",
      "        vae.classifier layers: inner_layer.name = 'dense'\n",
      "        inner_layer.weights = [<tf.Variable 'dense/kernel:0' shape=(16, 1) dtype=float32, numpy=\n",
      "        array([[-0.41812375],\n",
      "               [ 0.03896284],\n",
      "               [ 0.3401593 ],\n",
      "               [ 0.01312977],\n",
      "               [-0.26150012],\n",
      "               [-0.4657386 ],\n",
      "               [-0.47026733],\n",
      "               [-0.49402177],\n",
      "               [-0.26770842],\n",
      "               [-0.38632405],\n",
      "               [-0.23352417],\n",
      "               [-0.10596645],\n",
      "               [ 0.22930682],\n",
      "               [-0.15854585],\n",
      "               [-0.32876438],\n",
      "               [ 0.46394813]], dtype=float32)>, <tf.Variable 'dense/bias:0' shape=(1,) dtype=float32, numpy=array([0.], dtype=float32)>]\n",
      "        checkpoint_path = 'xforanalogs/tests/testL2linear/fold_0/cp_vae-0100.ckpt'\n",
      "        ==loading the model: xforanalogs/tests/testL2linear/fold_0/cp_vae-0100.ckpt\n",
      "        xforanalogs/tests/testL2linear/fold_0/cp_vae-0100.ckpt weights loaded\n",
      "        RAM memory: 2.047e+11\n",
      "         fold to terminate with repeat_nan_local = -1\n",
      "    k_fold_cross_val: completed in 2.1 s\n",
      "run_vae: completed in 1 min 47.6 s\n"
     ]
    }
   ],
   "source": [
    "# George Miloshevich 2022\n",
    "# The point of this notebook is to show that the new loss and the old loss give the same result\n",
    "# This routine is written for two parameters: input folder for VAE weights and the given epoch. It shows us how good the reconstruction of the VAE works\n",
    "import os, sys\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "os.environ['TF_XLA_FLAGS'] = '--tf_xla_enable_xla_devices'  # https://stackoverflow.com/questions/65907365/tensorflow-not-creating-xla-devices-tf-xla-enable-xla-devices-not-set\n",
    "import logging\n",
    "from colorama import Fore # support colored output in terminal\n",
    "from colorama import Style\n",
    "if __name__ == '__main__':\n",
    "    logger = logging.getLogger()\n",
    "    logger.handlers = [logging.StreamHandler(sys.stdout)]\n",
    "else:\n",
    "    logger = logging.getLogger(__name__)\n",
    "logger.level = logging.INFO\n",
    "\n",
    "fold_folder = Path('./xforanalogs/tests/testL2linear/fold_0')  # The name of the folder where the weights have been stored\n",
    "checkpoint = 15       # The checkpoint at which the weights have been stored\n",
    "\n",
    "import importlib.util\n",
    "def module_from_file(module_name, file_path): #The code that imports the file which originated the training with all the instructions\n",
    "            spec = importlib.util.spec_from_file_location(module_name, file_path)\n",
    "            module = importlib.util.module_from_spec(spec)\n",
    "            spec.loader.exec_module(module)\n",
    "            return module\n",
    "logger.info(f\"{Fore.BLUE}\") #  indicates we are inside the routine       \n",
    "logger.info(f\"{fold_folder = }\")\n",
    "logger.info(f\"loading module from  {fold_folder.parent}/Funs.py\")\n",
    "from importlib import import_module\n",
    "#foo = import_module(fold_folder+'/Funs.py', package=None)\n",
    "foo = module_from_file(\"foo\", f'{fold_folder.parent}/Funs.py')\n",
    "ef = foo.ef # Inherit ERA_Fields_New from the file we are calling\n",
    "ln = foo.ln\n",
    "ut = foo.ut\n",
    "\n",
    "run_vae_kwargs = ut.json2dict(f\"{fold_folder.parent}/config.json\")\n",
    "\n",
    "logger.info(\"==Importing tensorflow packages===\")\n",
    "import random as rd  \n",
    "from scipy.stats import norm\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "if len(sys.argv) > 3:\n",
    "    rd.seed(a=int(sys.argv[3]))\n",
    "else:\n",
    "    rd.seed(a=None) # None = system time\n",
    "\n",
    "tff = foo.tff # tensorflow routines \n",
    "ut = foo.ut # utilities\n",
    "logger.info(\"==Checking GPU==\")\n",
    "import tensorflow as tf\n",
    "tf.test.is_gpu_available(\n",
    "    cuda_only=False, min_cuda_compute_capability=None\n",
    ")\n",
    "\n",
    "logger.info(\"==Checking CUDA==\")\n",
    "tf.test.is_built_with_cuda()\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.axes_grid1.inset_locator import inset_axes\n",
    "import cartopy.mpl.geoaxes\n",
    "\n",
    "import matplotlib.gridspec as gridspec\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeat\n",
    "data_proj = ccrs.PlateCarree()\n",
    "\n",
    "#from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "sys.path.insert(1, '../ERA')\n",
    "import cartopy_plots as cplt\n",
    "\n",
    "\n",
    "logger.info(\"==Reading data==\")\n",
    "\n",
    "year_permutation = np.load(f'{fold_folder.parent}/year_permutation.npy')\n",
    "i = int(np.load(f'{fold_folder}/fold_num.npy'))\n",
    "\n",
    "time_start = ut.extract_nested(run_vae_kwargs, 'time_start')\n",
    "time_end = ut.extract_nested(run_vae_kwargs, 'time_end')\n",
    "T = ut.extract_nested(run_vae_kwargs, 'T')\n",
    "if (ut.keys_exists(run_vae_kwargs, 'label_period_start') and ut.keys_exists(run_vae_kwargs, 'label_period_end')):\n",
    "    label_period_start = ut.extract_nested(run_vae_kwargs, 'label_period_start')\n",
    "    label_period_end = ut.extract_nested(run_vae_kwargs, 'label_period_end')\n",
    "    if (label_period_start is not None) and (label_period_end is not None):\n",
    "        summer_days = label_period_end - label_period_start - T + 1\n",
    "    elif (label_period_start is None) and (label_period_end is not None):\n",
    "        summer_days = label_period_end - time_start - T + 1\n",
    "    elif (label_period_start is not None) and (label_period_end is None):\n",
    "        summer_days = time_end - label_period_start - T + 1\n",
    "    else:\n",
    "        summer_days = time_end - time_start - T + 1\n",
    "else:\n",
    "    summer_days = time_end - time_start - T + 1\n",
    "if ut.keys_exists(run_vae_kwargs, 'normalization_mode'):\n",
    "    normalization_mode = ut.extract_nested(run_vae_kwargs, 'normalization_mode')\n",
    "else:\n",
    "    normalization_mode = None\n",
    "\n",
    "if ut.keys_exists(run_vae_kwargs, 'keep_dims'):\n",
    "    keep_dims = ut.extract_nested(run_vae_kwargs, 'keep_dims')\n",
    "else:\n",
    "    keep_dims = None\n",
    "\n",
    "logger.info(f\"{Style.RESET_ALL}\")\n",
    "run_vae_kwargs = ut.set_values_recursive(run_vae_kwargs, {'myinput' : 'N'})\n",
    "if not os.path.exists(ut.extract_nested(run_vae_kwargs, 'mylocal')): # we are assuming that training was not run on R740server5\n",
    "    run_vae_kwargs = ut.set_values_recursive(run_vae_kwargs, {'mylocal' : '/ClimateDynamics/MediumSpace/ClimateLearningFR/gmiloshe/PLASIM/'})\n",
    "logger.info(f\"{run_vae_kwargs = }\")\n",
    "\n",
    "history, N_EPOCHS, INITIAL_EPOCH, checkpoint_path, LAT, LON, vae, X_va, Y_va, X_tr, Y_tr, _ = foo.run_vae(fold_folder, **run_vae_kwargs)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ea4ec274-4dae-4ee9-99d3-68d6d4a2b7cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((52500, 24, 48, 1), 7.5999355, -6.233911)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_va.shape, np.max(X_va), np.min(X_va)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6fc99651-44e1-4f58-925a-8c941ce0fd14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([2, 24, 48, 1])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = X_va[0:2,...]\n",
    "z_mean, z_log_var, z, zz = vae.call_encoder_classifier(data)\n",
    "reconstruction = vae.decoder(z)\n",
    "reconstruction.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "68a3dbb2-6d7e-48ac-a412-5d26a014d884",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=-158404.47>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = X_va[0:2,...]\n",
    "factor = vae.k1*vae.encoder_input_shape[1]*vae.encoder_input_shape[2]\n",
    "vae.coef_out*factor*tf.reduce_mean([tf.reduce_mean(vae.bce(data[...,i][..., np.newaxis], reconstruction[...,i][..., np.newaxis])) for i in range(reconstruction.shape[3])] ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ef25be66-5f74-4f97-a597-c4a41b58e116",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=-158404.47>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vae.k1*tf.reduce_mean(\n",
    "                tf.reduce_sum(\n",
    "                    tf.keras.losses.binary_crossentropy(data, reconstruction, from_logits=vae.from_logits), axis=(1, 2) # -Y_n Log( P_n) - (1 - Y_n) Log( 1 - P_n) is the expression for binary entropy\n",
    "                )\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6ff28cd1-f00a-4a91-9a3b-95a25c3805ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 12s, sys: 1min 45s, total: 2min 57s\n",
      "Wall time: 3.67 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=1476.3168>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "data = X_va\n",
    "z_mean, z_log_var, z, zz = vae.call_encoder_classifier(data)\n",
    "reconstruction = vae.decoder(z)\n",
    "reconstruction.shape\n",
    "factor = vae.k1*vae.encoder_input_shape[1]*vae.encoder_input_shape[2]\n",
    "vae.coef_out*factor*tf.reduce_mean([tf.reduce_mean(vae.rec_loss_form(data[...,i][..., np.newaxis], reconstruction[...,i][..., np.newaxis])) for i in range(reconstruction.shape[3])] ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "703aad16-7147-4c59-9de0-e5f584d8a774",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prepare_data_and_mask:\n",
      "    load_data:\n",
      "        Opening field tas\n",
      "        monotonize_years:\n",
      "        monotonize_years: completed in 4.4 s\n",
      "        select_years:\n",
      "        select_years: completed in 0.8 s\n",
      "        select_lonlat:\n",
      "        select_lonlat: completed in 2.9 s\n",
      "        Opening field zg\n",
      "        monotonize_years:\n",
      "        monotonize_years: completed in 4.0 s\n",
      "        select_years:\n",
      "        select_years: completed in 0.7 s\n",
      "        select_lonlat:\n",
      "        select_lonlat: completed in 2.9 s\n",
      "        Opening field mrso\n",
      "        monotonize_years:\n",
      "        monotonize_years: completed in 4.0 s\n",
      "        select_years:\n",
      "        select_years: completed in 0.7 s\n",
      "        select_lonlat:\n",
      "        select_lonlat: completed in 2.6 s\n",
      "    load_data: completed in 1 min 26.1 s\n",
      "    prepare_XY:\n",
      "        return_threshold = True        \n",
      "        make_XY:\n",
      "            make_X:\n",
      "            make_X: completed in 0.5 s\n",
      "            assign_labels:\n",
      "                A_weights = [3, 0, 0, 3, 0, 0, 3, 0, 0, 3, 0, 0, 3, 0, 0]\n",
      "                compute_time_average:\n",
      "                \tcompute_area_integral:\n",
      "                \tcompute_area_integral: completed in 0.8 s\n",
      "                compute_time_average: completed in 2.8 s\n",
      "                compute_time_average:\n",
      "                compute_time_average: completed in 2.0 s\n",
      "                threshold_new = 2.742728328704834\n",
      "            assign_labels: completed in 4.8 s\n",
      "        make_XY: completed in 5.3 s\n",
      "        roll_X:\n",
      "        roll_X: completed in 0.0 s\n",
      "        Mixing\n",
      "         label_period_start = 30 ;time_start = 15 ;time_end = 134 ;label_period_end = 120 \n",
      "        Y.shape = (500, 105), from 15 to 91 \n",
      "        balance_folds:\n",
      "            Balancing folds\n",
      "            fold 0 done!\n",
      "            fold 1 done!\n",
      "            fold 2 done!\n",
      "            fold 3 done!\n",
      "            fold 4 done!\n",
      "            fold 5 done!\n",
      "            fold 6 done!\n",
      "            fold 7 done!\n",
      "            fold 8 done!\n",
      "            fold 9 done!\n",
      "            Sums of the balanced 10 folds:\n",
      "            [190 190 190 190 190 190 190 190 190 190]\n",
      "            std/avg = 0.000\n",
      "            max relative deviation = 0.000\\%\n",
      "        balance_folds: completed in 0.0 s\n",
      "        Mixing completed in 0.4 s\n",
      "        \n",
      "        X.shape = (500, 105, 24, 48, 3), Y.shape = (500, 105)\n",
      "        Flattened time: X.shape = (52500, 24, 48, 3), Y.shape = (52500,)\n",
      "        compute_area_integral:\n",
      "        compute_area_integral: completed in 0.4 s\n",
      "        compute_area_integral:\n",
      "        compute_area_integral: completed in 0.4 s\n",
      "        time_series = [array([ 5.9059734 ,  5.2596064 ,  4.960754  , ...,  0.02219056,\n",
      "               -1.21639   , -2.130549  ], dtype=float32), array([104.05559 , 109.004776, 107.45358 , ..., -49.361618, -46.130516,\n",
      "               -39.455868], dtype=float32), array([-0.05739938, -0.05798355, -0.05831986, ..., -0.00390428,\n",
      "               -0.00320801, -0.00268412], dtype=float32)]\n",
      "        time_series.shape = (52500, 3)\n",
      "    prepare_XY: completed in 7.2 s\n",
      "prepare_data_and_mask: completed in 1 min 33.3 s\n"
     ]
    }
   ],
   "source": [
    "load_data_kwargs = ut.extract_nested(run_vae_kwargs, 'load_data_kwargs')\n",
    "prepare_XY_kwargs = ut.extract_nested(run_vae_kwargs, 'prepare_XY_kwargs')\n",
    "(_, _, year_permutation, _, _, _, threshold), mask  = ln.prepare_data_and_mask(load_data_kwargs=load_data_kwargs, prepare_XY_kwargs=prepare_XY_kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5397c089-fdfd-42e9-a424-016bf56c0b37",
   "metadata": {},
   "source": [
    "Now onto constructing different architectures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7321b68f-daa5-48af-920c-07e1349a5e20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'encoder_conv_filters': [32, 64], 'encoder_conv_kernel_size': [3, 3, 64], 'encoder_conv_strides': [2, 1], 'encoder_conv_padding': ['same', 'valid'], 'encoder_conv_activation': ['LeakyRelu', 'LeakyRelu', 'LeakyRelu'], 'encoder_conv_skip': None, 'encoder_use_batch_norm': [False, False, False, False], 'encoder_use_dropout': [0, 0, 0, 0]}\n",
      "shape_before_flattening =  (10, 22, 64)\n",
      "Model: \"encoder\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "encoder input (InputLayer)      [(None, 24, 48, 1)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "encoder_conv_0 (Conv2D)         (None, 12, 24, 32)   320         encoder input[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_65 (LeakyReLU)      (None, 12, 24, 32)   0           encoder_conv_0[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "encoder_conv_1 (Conv2D)         (None, 10, 22, 64)   18496       leaky_re_lu_65[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_66 (LeakyReLU)      (None, 10, 22, 64)   0           encoder_conv_1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "flatten_11 (Flatten)            (None, 14080)        0           leaky_re_lu_66[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 64)           901184      flatten_11[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_67 (LeakyReLU)      (None, 64)           0           dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "z_mean (Dense)                  (None, 16)           1040        leaky_re_lu_67[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "z_log_var (Dense)               (None, 16)           1040        leaky_re_lu_67[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "sampling_10 (Sampling)          (None, 16)           0           z_mean[0][0]                     \n",
      "                                                                 z_log_var[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 922,080\n",
      "Trainable params: 922,080\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "INPUT_DIM = X_va.shape[1:] \n",
    "Z_DIM = ut.extract_nested(run_vae_kwargs, 'Z_DIM')\n",
    "build_encoder_skip_kwargs = ut.extract_nested(run_vae_kwargs, 'build_encoder_skip_kwargs')\n",
    "build_encoder_skip_kwargs = ut.set_values_recursive(build_encoder_skip_kwargs, {'encoder_conv_filters' : [32,64],\n",
    "                                                'encoder_conv_kernel_size' : [3,3,64],\n",
    "                                                'encoder_conv_strides' : [2,1],\n",
    "                                                'encoder_conv_padding' : [\"same\",\"valid\"],\n",
    "                                                'encoder_conv_activation' : [\"LeakyRelu\",\"LeakyRelu\",\"LeakyRelu\"]\n",
    "                                                   })\n",
    "print(build_encoder_skip_kwargs)\n",
    "_, _, shape_before_flattening, encoder  = tff.build_encoder_skip(input_dim = INPUT_DIM, output_dim = Z_DIM, **build_encoder_skip_kwargs)\n",
    "encoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ba2c4eb0-0da2-4b50-a66c-4edad5276b49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape_before_flattening = (10, 22, 64)\n",
      "Model: \"decoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_9 (InputLayer)         [(None, 16)]              0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 14080)             239360    \n",
      "_________________________________________________________________\n",
      "reshape_8 (Reshape)          (None, 10, 22, 64)        0         \n",
      "_________________________________________________________________\n",
      "decoder_conv_0 (Conv2DTransp (None, 12, 24, 32)        18464     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_61 (LeakyReLU)   (None, 12, 24, 32)        0         \n",
      "_________________________________________________________________\n",
      "decoder_conv_1 (Conv2DTransp (None, 24, 48, 1)         289       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_62 (LeakyReLU)   (None, 24, 48, 1)         0         \n",
      "=================================================================\n",
      "Total params: 258,113\n",
      "Trainable params: 258,113\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "build_decoder_skip_kwargs = ut.extract_nested(run_vae_kwargs, 'build_decoder_skip_kwargs')\n",
    "build_decoder_skip_kwargs = ut.set_values_recursive(build_decoder_skip_kwargs, {'decoder_conv_filters' : [32,1],  #3], # Use 3 if working with 3 fields\n",
    "                                                'decoder_conv_kernel_size' : [3,3],\n",
    "                                                'decoder_conv_strides' : [1,2],\n",
    "                                                'decoder_conv_padding' : [\"valid\",\"same\",\"same\"],\n",
    "                                                'decoder_conv_activation' : [\"LeakyRelu\",\"LeakyRelu\",\"linear\"]\n",
    "                                                   })\n",
    "\n",
    "ones_dim = np.ones(INPUT_DIM[:-1])\n",
    "print(f'{shape_before_flattening = }')\n",
    "filter_mask = np.array([mask,ones_dim,mask], dtype=bool).transpose(1,2,0) \n",
    "_, _, decoder = tff.build_decoder_skip(mask=filter_mask, input_dim = Z_DIM, shape_before_flattening = shape_before_flattening, **build_decoder_skip_kwargs)\n",
    "decoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d98f11d-98a3-43ad-b12d-2853043b6924",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kernel3.9",
   "language": "python",
   "name": "kernel3.9"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
