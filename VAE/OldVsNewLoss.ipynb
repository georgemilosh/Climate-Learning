{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06cf35f6-5fa3-4387-a0bc-041820da3282",
   "metadata": {},
   "outputs": [],
   "source": [
    "# George Miloshevich 2022\n",
    "# The point of this notebook is to show that the new loss and the old loss give the same result\n",
    "# This routine is written for two parameters: input folder for VAE weights and the given epoch. It shows us how good the reconstruction of the VAE works\n",
    "import os, sys\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "os.environ['TF_XLA_FLAGS'] = '--tf_xla_enable_xla_devices'  # https://stackoverflow.com/questions/65907365/tensorflow-not-creating-xla-devices-tf-xla-enable-xla-devices-not-set\n",
    "import logging\n",
    "from colorama import Fore # support colored output in terminal\n",
    "from colorama import Style\n",
    "if __name__ == '__main__':\n",
    "    logger = logging.getLogger()\n",
    "    logger.handlers = [logging.StreamHandler(sys.stdout)]\n",
    "else:\n",
    "    logger = logging.getLogger(__name__)\n",
    "logger.level = logging.INFO\n",
    "\n",
    "fold_folder = Path('./xforanalogs/tests/testskip2/fold_0')  # The name of the folder where the weights have been stored\n",
    "checkpoint = 15       # The checkpoint at which the weights have been stored\n",
    "\n",
    "import importlib.util\n",
    "def module_from_file(module_name, file_path): #The code that imports the file which originated the training with all the instructions\n",
    "            spec = importlib.util.spec_from_file_location(module_name, file_path)\n",
    "            module = importlib.util.module_from_spec(spec)\n",
    "            spec.loader.exec_module(module)\n",
    "            return module\n",
    "logger.info(f\"{Fore.BLUE}\") #  indicates we are inside the routine       \n",
    "logger.info(f\"{fold_folder = }\")\n",
    "logger.info(f\"loading module from  {fold_folder.parent}/Funs.py\")\n",
    "from importlib import import_module\n",
    "#foo = import_module(fold_folder+'/Funs.py', package=None)\n",
    "foo = module_from_file(\"foo\", f'{fold_folder.parent}/Funs.py')\n",
    "ef = foo.ef # Inherit ERA_Fields_New from the file we are calling\n",
    "ln = foo.ln\n",
    "ut = foo.ut\n",
    "\n",
    "run_vae_kwargs = ut.json2dict(f\"{fold_folder.parent}/config.json\")\n",
    "\n",
    "logger.info(\"==Importing tensorflow packages===\")\n",
    "import random as rd  \n",
    "from scipy.stats import norm\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "if len(sys.argv) > 3:\n",
    "    rd.seed(a=int(sys.argv[3]))\n",
    "else:\n",
    "    rd.seed(a=None) # None = system time\n",
    "\n",
    "tff = foo.tff # tensorflow routines \n",
    "ut = foo.ut # utilities\n",
    "logger.info(\"==Checking GPU==\")\n",
    "import tensorflow as tf\n",
    "tf.test.is_gpu_available(\n",
    "    cuda_only=False, min_cuda_compute_capability=None\n",
    ")\n",
    "\n",
    "logger.info(\"==Checking CUDA==\")\n",
    "tf.test.is_built_with_cuda()\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.axes_grid1.inset_locator import inset_axes\n",
    "import cartopy.mpl.geoaxes\n",
    "\n",
    "import matplotlib.gridspec as gridspec\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeat\n",
    "data_proj = ccrs.PlateCarree()\n",
    "\n",
    "#from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "sys.path.insert(1, '../ERA')\n",
    "import cartopy_plots as cplt\n",
    "\n",
    "\n",
    "logger.info(\"==Reading data==\")\n",
    "\n",
    "year_permutation = np.load(f'{fold_folder.parent}/year_permutation.npy')\n",
    "i = int(np.load(f'{fold_folder}/fold_num.npy'))\n",
    "\n",
    "time_start = ut.extract_nested(run_vae_kwargs, 'time_start')\n",
    "time_end = ut.extract_nested(run_vae_kwargs, 'time_end')\n",
    "T = ut.extract_nested(run_vae_kwargs, 'T')\n",
    "if (ut.keys_exists(run_vae_kwargs, 'label_period_start') and ut.keys_exists(run_vae_kwargs, 'label_period_end')):\n",
    "    label_period_start = ut.extract_nested(run_vae_kwargs, 'label_period_start')\n",
    "    label_period_end = ut.extract_nested(run_vae_kwargs, 'label_period_end')\n",
    "    if (label_period_start is not None) and (label_period_end is not None):\n",
    "        summer_days = label_period_end - label_period_start - T + 1\n",
    "    elif (label_period_start is None) and (label_period_end is not None):\n",
    "        summer_days = label_period_end - time_start - T + 1\n",
    "    elif (label_period_start is not None) and (label_period_end is None):\n",
    "        summer_days = time_end - label_period_start - T + 1\n",
    "    else:\n",
    "        summer_days = time_end - time_start - T + 1\n",
    "else:\n",
    "    summer_days = time_end - time_start - T + 1\n",
    "if ut.keys_exists(run_vae_kwargs, 'normalization_mode'):\n",
    "    normalization_mode = ut.extract_nested(run_vae_kwargs, 'normalization_mode')\n",
    "else:\n",
    "    normalization_mode = None\n",
    "\n",
    "if ut.keys_exists(run_vae_kwargs, 'keep_dims'):\n",
    "    keep_dims = ut.extract_nested(run_vae_kwargs, 'keep_dims')\n",
    "else:\n",
    "    keep_dims = None\n",
    "#X, lat, lon, vae, Z_DIM, N_EPOCHS, INITIAL_EPOCH, BATCH_SIZE, LEARNING_RATE, checkpoint_path, fold_folder, myinput, history = foo.PrepareDataAndVAE(fold_folder, DIFFERENT_YEARS=year_permutation[:800])\n",
    "year_permutation_va = np.load(f'{fold_folder}/year_permutation_va.npy')\n",
    "# Select times we want to show for reconstruction\n",
    "if True: # select at random 10 years out of the validation set \n",
    "    year_permutation = list(year_permutation_va[rd.sample(range(len(year_permutation_va)), 10)])  \n",
    "    day_permutation = rd.sample(range(summer_days*len(year_permutation)), 5) \n",
    "else: # avoid random permutation, just select minimum number of years allowed in fold\n",
    "    year_permutation = [year_permutation_va[0]]\n",
    "    day_permutation = range(23,23+5)##range(12,12+5)#[4,5,6,7,8] # the length has to be 5 for plotting purposes\n",
    "    \n",
    "#TODO: convert the day permuation to the appropriate day and year\n",
    "logger.info(f\"{year_permutation = },{day_permutation = }\")\n",
    "\n",
    "logger.info(f\"{Style.RESET_ALL}\")\n",
    "run_vae_kwargs = ut.set_values_recursive(run_vae_kwargs, {'myinput' : 'N', 'year_permutation' :year_permutation})\n",
    "if not os.path.exists(ut.extract_nested(run_vae_kwargs, 'mylocal')): # we are assuming that training was not run on R740server5\n",
    "    run_vae_kwargs = ut.set_values_recursive(run_vae_kwargs, {'mylocal' : '/ClimateDynamics/MediumSpace/ClimateLearningFR/gmiloshe/PLASIM/'})\n",
    "logger.info(f\"{run_vae_kwargs = }\")\n",
    "\n",
    "history, N_EPOCHS, INITIAL_EPOCH, checkpoint_path, LAT, LON, vae, X_va, Y_va, X_tr, Y_tr, _ = foo.run_vae(fold_folder, **run_vae_kwargs)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ea4ec274-4dae-4ee9-99d3-68d6d4a2b7cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1050, 24, 48, 1), 0.9874537, 0.0014628773)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_va.shape, np.max(X_va), np.min(X_va)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6fc99651-44e1-4f58-925a-8c941ce0fd14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([2, 24, 48, 1])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = X_va[0:2,...]\n",
    "z_mean, z_log_var, z, zz = vae.call_encoder_classifier(data)\n",
    "reconstruction = vae.decoder(z)\n",
    "reconstruction.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "68a3dbb2-6d7e-48ac-a412-5d26a014d884",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=12066.404>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = X_va[0:2,...]\n",
    "factor = vae.k1*vae.encoder_input_shape[1]*vae.encoder_input_shape[2]\n",
    "vae.coef_out*factor*tf.reduce_mean([tf.reduce_mean(vae.rec_loss_form(data[...,i][..., np.newaxis], reconstruction[...,i][..., np.newaxis])) for i in range(reconstruction.shape[3])] ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ef25be66-5f74-4f97-a597-c4a41b58e116",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=12066.404>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vae.k1*tf.reduce_mean(\n",
    "                tf.reduce_sum(\n",
    "                    tf.keras.losses.binary_crossentropy(data, reconstruction, from_logits=vae.from_logits), axis=(1, 2) # -Y_n Log( P_n) - (1 - Y_n) Log( 1 - P_n) is the expression for binary entropy\n",
    "                )\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b69bf052-ab00-4bf1-aaed-4f89285ae5bb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kernel3.9",
   "language": "python",
   "name": "kernel3.9"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
