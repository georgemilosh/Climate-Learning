{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1e54e627-3618-4ab0-a9bb-406e6f54a6e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: NumExpr detected 64 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 8.\n",
      "NumExpr defaulting to 8 threads.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-26 15:08:58.039102: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "path_to_ERA = '/ClimateDynamics/MediumSpace/ClimateLearningFR/gmiloshe'/ERA/\n",
      "Trying to import basemap\n",
      "In this environment you cannot import Basemap\n",
      "Trying to import cartopy\n",
      "Trying to import basemap\n",
      "In this environment you cannot import Basemap\n",
      "Trying to import cartopy\n",
      "Successfully imported cartopy\n",
      "Successfully imported cartopy\n",
      "==Checking GPU==\n",
      "From xforanalogs/NA24by48/global_logit/yrs500/interT15/Funs.py:46: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.config.list_physical_devices('GPU')` instead.\n",
      "==Checking CUDA==\n",
      "<module 'PLASIM.Learn2_new' from '/ClimateDynamics/MediumSpace/ClimateLearningFR/gmiloshe/PLASIM/Learn2_new.py'>\n",
      "<module 'ERA.utilities' from '/ClimateDynamics/MediumSpace/ClimateLearningFR/gmiloshe/ERA/utilities.py'>\n",
      "<module 'ERA.TF_Fields' from '/ClimateDynamics/MediumSpace/ClimateLearningFR/gmiloshe/ERA/TF_Fields.py'>\n",
      "path_to_ERA = '/ClimateDynamics/MediumSpace/ClimateLearningFR/gmiloshe'/ERA/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-26 15:09:02.289302: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-11-26 15:09:02.318884: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\n",
      "2022-11-26 15:09:02.561840: E tensorflow/stream_executor/cuda/cuda_driver.cc:328] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2022-11-26 15:09:02.561887: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (apollo2048g): /proc/driver/nvidia/version does not exist\n",
      "2022-11-26 15:09:02.561901: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2022-11-26 15:09:02.569941: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<module 'Learn2_new' from '/ClimateDynamics/MediumSpace/ClimateLearningFR/gmiloshe/VAE/../PLASIM/Learn2_new.py'>\n",
      "<module 'utilities' from '/ClimateDynamics/MediumSpace/ClimateLearningFR/gmiloshe/ERA/utilities.py'>\n",
      "<module 'TF_Fields' from '/ClimateDynamics/MediumSpace/ClimateLearningFR/gmiloshe/ERA/TF_Fields.py'>\n",
      "==Checking GPU==\n",
      "==Checking CUDA==\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OMP: Info #276: omp_set_nested routine deprecated, please use omp_set_max_active_levels instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<module 'committor_analogue' from '/ClimateDynamics/MediumSpace/ClimateLearningFR/gmiloshe/VAE/committor_analogue.py'>\n"
     ]
    }
   ],
   "source": [
    "# George Miloshevich 2022\n",
    "\n",
    "import os, sys\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "\n",
    "from functools import partial # allows us to create a function with arguments passed\n",
    "folder = Path('./xforanalogs/NA24by48/global_logit/yrs500/interT15')  # The name of the folder where the weights have been stored\n",
    "\n",
    "\n",
    "import logging\n",
    "from colorama import Fore # support colored output in terminal\n",
    "from colorama import Style\n",
    "if __name__ == '__main__':\n",
    "    logger = logging.getLogger()\n",
    "    logger.handlers = [logging.StreamHandler(sys.stdout)]\n",
    "else:\n",
    "    logger = logging.getLogger(__name__)\n",
    "logger.level = logging.INFO     \n",
    "\n",
    "import importlib.util\n",
    "def module_from_file(module_name, file_path): #The code that imports the file which originated the training with all the instructions\n",
    "            spec = importlib.util.spec_from_file_location(module_name, file_path)\n",
    "            module = importlib.util.module_from_spec(spec)\n",
    "            spec.loader.exec_module(module)\n",
    "            return module\n",
    "\n",
    "from importlib import import_module\n",
    "#foo = import_module(fold_folder+'/Funs.py', package=None)\n",
    "\n",
    "\n",
    "#folder = './xforanalogs/NA24by48/Z8/yrs500/interT15fw20.1.20lrs4'\n",
    "foo = module_from_file(\"foo\", f'{folder}/Funs.py')\n",
    "import pickle\n",
    "import random as rd  \n",
    "from scipy.stats import norm\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import neighbors\n",
    "from sklearn.metrics import log_loss\n",
    "\n",
    "tff = foo.tff # tensorflow routines \n",
    "ut = foo.ut # utilities\n",
    "ln = foo.ln #Learn2_new.py\n",
    "print(ln)\n",
    "print(ut)\n",
    "print(tff)\n",
    "import committor_analogue as ca\n",
    "print(ca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b1523582",
   "metadata": {},
   "outputs": [],
   "source": [
    "ca.tff = tff\n",
    "ca.ut = ut\n",
    "ca.ln = ln\n",
    "\n",
    "\n",
    "import numba as nb\n",
    "from numba import jit,guvectorize,set_num_threads\n",
    "@guvectorize([(nb.int64,nb.int64,nb.int64[:],nb.int64[:],nb.int64,nb.int64[:,:],nb.int64[:,:])],\n",
    "             '(),(),(n),(m),(),(k,o)->(n,m)',nopython=True,target=\"parallel\") # to enable numba parallelism\n",
    "def TrajOnePoint(day, nn, n_Traj, numsteps, Markov_step, Matr_tr,res): # a day implies the temporal coordinates in days of the input from the 0-th year of the 1000 year long dataset\n",
    "    \"\"\" Compute `n_Traj` trajectories starting from `day` that take `numsteps` steps\n",
    "    Args:\n",
    "        day (_int_):            day in the validation set where the Markov chain will start\n",
    "        nn (_int_):             number of nearest neighbors to look for\n",
    "        n_Traj (_int array_):         Number of MC samples that start from the same day (number of trajectories).\n",
    "        numsteps (_int array_):       numbe of steps to take in each trajectory\n",
    "        Markov_step (_int_):    step in the Markov chain (how many days)\n",
    "        Matr_tr (_ndarray_):    T matrix inside the training set\n",
    "        res (_float_):          stores the committor (return), this is how numba vectorization forces the output to be treated\n",
    "    \"\"\"\n",
    "    wrong_index = 0 # This checks that during input or execution we were always working with indecies that exist in the considered matrices and we don't go below or above\n",
    "    if (day >= Matr_tr.shape[0]) or (day < 0): # We don't allow inputs that are outside of the range of Matr_va. \n",
    "        #print(\"day > Matr_va.shape[0]\")\n",
    "        wrong_index = 1 # manual debugging (unfortunately numba does not capture this)\n",
    "        print(\"We don't allow inputs that are outside of the range of Matr_va\")\n",
    "        for l_1 in n_Traj:\n",
    "            for l_2 in numsteps:\n",
    "                res[l_1][l_2] = np.nan # we simply  don't have corresponding index\n",
    "    if nn > Matr_tr.shape[1]:\n",
    "        wrong_index = 1 # manual debugging: use to monitor if we get out of the Matr_tr allowed set\n",
    "        print(\"We don't allow inputs that are outside of the range of Matr_va\")\n",
    "    else:\n",
    "        #print(\"day <= Matr_va.shape[0]\")\n",
    "        for i in n_Traj:   \n",
    "            s = day # We initialize trajectory at the first day\n",
    "            res[i][0] = s\n",
    "            #print(\"output: \", day,app,s, Matr_va.shape)\n",
    "            if (s >= Matr_tr.shape[0]) or (s < 0):\n",
    "                wrong_index = 1\n",
    "            for j in numsteps[1:]: \n",
    "                    app = rd.randint(0,nn-1) #analogue selection\n",
    "                    s = Matr_tr[s][app] + Markov_step         #analog state s is evolved in time\n",
    "                    res[i][j] = s\n",
    "                    if (s >= Matr_tr.shape[0]) or (s < 0):\n",
    "                        wrong_index = 1\n",
    "                    if nn > Matr_tr.shape[1]:\n",
    "                        wrong_index = 1 # manual debugging: use to monitor if we get out of the Matr_tr allowed set\n",
    "        if wrong_index == 1:\n",
    "            print(\"Somewhere inside the code there was an input outside of the range of matrices/vectors\")\n",
    "            for i in n_Traj:\n",
    "                for j in numsteps:\n",
    "                    res[l_1][l_2] = np.nan # we simply  don't have the corresponding index\n",
    "        \n",
    "def DressTrajOnePoint(day, ther,dela, Temp_va, Temp_tr, nn, n_Traj, numsteps, Markov_step, Matr_va, Matr_tr):\n",
    "    \"\"\"This function calls TrajOnePoint by selecting the right inputs provided to ca.CommOnePoint()\n",
    "    \"\"\"\n",
    "    n_Traj = np.arange(n_Traj)\n",
    "    numsteps = np.arange(numsteps) # Note that this overwrites what was prescribed in ca.RunNeighbors(). We want to simulate a day in summer\n",
    "    print(f'{n_Traj = }')\n",
    "    return TrajOnePoint(day, nn, n_Traj, numsteps, Markov_step, Matr_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "548d19be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\n",
      "{'nfield': 0, 'input_set': 'va', 'bulk_set': 'tr', 'RunCheckpoints_kwargs': {'start_calendar_day': 15, 'start_day_set': 'tr', 'allowselfanalogs': True, 'RunNeighbors_kwargs': {'num_Traj': 10, 'T': 15, 'chain_step': 3, 'neighbors': [3, 5, 10, 20, 40], 'delay': array([0, 1, 2, 3, 4, 5]), 'num_steps': 90}}}\n"
     ]
    }
   ],
   "source": [
    "ca.CommOnePoint = DressTrajOnePoint\n",
    "\n",
    "ln.RunCheckpoints = ca.RunCheckpoints\n",
    "ln.RunNeighbors = ca.RunNeighbors\n",
    "ln.RunFolds = ca.RunFolds\n",
    "\n",
    "\n",
    "#from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "sys.path.insert(1, '../ERA')\n",
    "year_permutation = np.load(f'{folder}/year_permutation.npy')\n",
    "run_vae_kwargs = ut.json2dict(f\"{folder}/config.json\")\n",
    "T = ut.extract_nested(run_vae_kwargs, 'T')\n",
    "if (ut.keys_exists(run_vae_kwargs, 'label_period_start') and ut.keys_exists(run_vae_kwargs, 'label_period_end')):\n",
    "    label_period_start = ut.extract_nested(run_vae_kwargs, 'label_period_start')\n",
    "    label_period_end = ut.extract_nested(run_vae_kwargs, 'label_period_end')\n",
    "    time_start = ut.extract_nested(run_vae_kwargs, 'time_start')\n",
    "    time_end = ut.extract_nested(run_vae_kwargs, 'time_end')\n",
    "threshold = np.array([np.load(f'{folder}/threshold.npy')]) #Threshold defining committor. This parameter I don't need, I shall perhaps transform it into epochs for variational autoencoder \n",
    "percent = ut.extract_nested(run_vae_kwargs, 'percent')\n",
    "nfolds = ut.extract_nested(run_vae_kwargs, 'nfolds')\n",
    "n_days = time_end-time_start-T+1   \n",
    "logger.info(f\"{Style.RESET_ALL}\")\n",
    "\n",
    "extra_day=1\n",
    "if ut.keys_exists(run_vae_kwargs, 'A_weights'):\n",
    "    A_weights = ut.extract_nested(run_vae_kwargs, 'A_weights')\n",
    "    if A_weights is not None:\n",
    "        extra_day = A_weights[0] # We need to see if the labels were interpolated to see how much the algorithm should jump each summer\n",
    "if extra_day == 3:\n",
    "    delay = np.arange(6)\n",
    "else:\n",
    "    delay = 3*np.arange(6)\n",
    "\n",
    "RunFolds_kwargs_default = ln.get_default_params(ca.RunFolds, recursive=True)\n",
    "RunFolds_kwargs_default = ut.set_values_recursive(\n",
    "    RunFolds_kwargs_default, {'num_Traj' : 10, 'chain_step' : extra_day,  'threshold' : threshold,\n",
    "                                'delay' : delay, 'neighbors' : [3,5,10,20,40], 'num_steps' : n_days - (label_period_start-time_start),\n",
    "                              'T' : T, 'allowselfanalogs' : True, 'input_set' : 'va', 'bulk_set' : 'tr',\n",
    "                              'start_calendar_day' :(label_period_start-time_start), 'start_day_set' : 'tr'}  )\n",
    "\n",
    "chain_step = ut.extract_nested(RunFolds_kwargs_default, 'chain_step')  \n",
    "logger.info(RunFolds_kwargs_default)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#logger.info(f'{sec[10][10].shape = }')\n",
    "\n",
    "#logger.info(sec[10][10][0,0])\n",
    "\n",
    "#logger.info(sec[10][10][0,0]%n_days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b9644040",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\n",
      "RunFolds:\n",
      "    fold = 0, loading from xforanalogs/NA24by48/global_logit/yrs500/interT15/fold_0/analogues.pkl\n",
      "    RunCheckpoints:\n",
      "        checkpoint = 10.0\n",
      "        Matr_va.shape = (5250, 100)\n",
      "        days.shape = (450,)        \n",
      "        RunNeighbors:\n",
      "            num_Traj = 10, N_Steps = 90, chain_step = 3, T = 15, neighbors = [3, 5, 10, 20, 40], delay = array([0, 1, 2, 3, 4, 5]), threshold = array([2.74272833])\n",
      "            nn = 3\n",
      "            n_Traj = array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])            \n",
      "            nn = 5\n",
      "            n_Traj = array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])            \n",
      "            nn = 10\n",
      "            n_Traj = array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])            \n",
      "            nn = 20\n",
      "            n_Traj = array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])            \n",
      "            nn = 40\n",
      "            n_Traj = array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])            \n",
      "            q[nn].shape = (450, 10, 90)\n",
      "        RunNeighbors: completed in 0.1 s\n",
      "        checkpoint = 50.0\n",
      "        Matr_va.shape = (5250, 100)\n",
      "        days.shape = (450,)        \n",
      "        RunNeighbors:\n",
      "            num_Traj = 10, N_Steps = 90, chain_step = 3, T = 15, neighbors = [3, 5, 10, 20, 40], delay = array([0, 1, 2, 3, 4, 5]), threshold = array([2.74272833])\n",
      "            nn = 3\n",
      "            n_Traj = array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])            \n",
      "            nn = 5\n",
      "            n_Traj = array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])            \n",
      "            nn = 10\n",
      "            n_Traj = array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])            \n",
      "            nn = 20\n",
      "            n_Traj = array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])            \n",
      "            nn = 40\n",
      "            n_Traj = array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])            \n",
      "            q[nn].shape = (450, 10, 90)\n",
      "        RunNeighbors: completed in 0.0 s\n",
      "        checkpoint = 100.0\n",
      "        Matr_va.shape = (5250, 100)\n",
      "        days.shape = (450,)        \n",
      "        RunNeighbors:\n",
      "            num_Traj = 10, N_Steps = 90, chain_step = 3, T = 15, neighbors = [3, 5, 10, 20, 40], delay = array([0, 1, 2, 3, 4, 5]), threshold = array([2.74272833])\n",
      "            nn = 3\n",
      "            n_Traj = array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])            \n",
      "            nn = 5\n",
      "            n_Traj = array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])            \n",
      "            nn = 10\n",
      "            n_Traj = array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])            \n",
      "            nn = 20\n",
      "            n_Traj = array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])            \n",
      "            nn = 40\n",
      "            n_Traj = array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])            \n",
      "            q[nn].shape = (450, 10, 90)\n",
      "        RunNeighbors: completed in 0.0 s\n",
      "        checkpoint = 500.0\n",
      "        Matr_va.shape = (5250, 100)\n",
      "        days.shape = (450,)        \n",
      "        RunNeighbors:\n",
      "            num_Traj = 10, N_Steps = 90, chain_step = 3, T = 15, neighbors = [3, 5, 10, 20, 40], delay = array([0, 1, 2, 3, 4, 5]), threshold = array([2.74272833])\n",
      "            nn = 3\n",
      "            n_Traj = array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])            \n",
      "            nn = 5\n",
      "            n_Traj = array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])            \n",
      "            nn = 10\n",
      "            n_Traj = array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])            \n",
      "            nn = 20\n",
      "            n_Traj = array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])            \n",
      "            nn = 40\n",
      "            n_Traj = array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])            \n",
      "            q[nn].shape = (450, 10, 90)\n",
      "        RunNeighbors: completed in 0.0 s\n",
      "    RunCheckpoints: completed in 0.1 s\n",
      "RunFolds: completed in 0.3 s\n",
      "\u001b[0m\n",
      "A_synth[10][10].shape = (450, 10, 76)\n",
      "Saving the synthetic time series in \n"
     ]
    }
   ],
   "source": [
    "logger.info(f\"{Fore.BLUE}\") #  indicates we are inside the routine \n",
    "\n",
    "with open(f'{folder}/fold_{0}/analogues.pkl', \"rb\") as open_file:\n",
    "    analog = pickle.load(open_file)\n",
    "analogues_tr = list(analog['ind_new_tr'].values())[0] # Here we need to load just random analogs for the compilation below\n",
    "time_series_tr = np.load(f\"{folder}/fold_{0}/time_series_tr.npy\")[:,0]\n",
    "#sec_1 = TrajOnePoint(33, [2,3,5,10,20,50],10, 5, chain_step, analogues_tr) # compiling (maybe we only need this once)\n",
    "sec = ca.RunFolds(folder,1, threshold, n_days, **RunFolds_kwargs_default)[0]   # We only run 1 fold\n",
    "logger.info(f\"{Style.RESET_ALL}\")\n",
    "\n",
    "time_series_synth = {k: {j:time_series_tr[u] for j, u in v.items()} for k, v in sec.items()}\n",
    "#logger.info(f'{time_series_synth[10][10].shape = }')\n",
    "convolve_vec = np.vectorize(partial(np.convolve, **{'mode':'valid'}), signature='(n),(m)->(k)')\n",
    "A_synth = {k: {j:convolve_vec(u, np.ones(T)/T) for j, u in v.items()} for k, v in time_series_synth.items()}\n",
    "logger.info(f'{A_synth[10][10].shape = }')\n",
    "logger.info('Saving the synthetic time series in ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e968ff73",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kernel3.9",
   "language": "python",
   "name": "kernel3.9"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
