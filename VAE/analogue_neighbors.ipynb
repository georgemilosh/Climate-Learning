{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-05 15:43:19.370375: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "In this environment you cannot import Basemap\n",
      "In this environment you cannot import Basemap\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From ./xforanalogs/NA24by48/Z8/yrs500/interT15fw20.1.20lrs4/Funs.py:46: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.config.list_physical_devices('GPU')` instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-05 15:43:22.612132: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-07-05 15:43:22.617793: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\n",
      "2022-07-05 15:43:22.829051: E tensorflow/stream_executor/cuda/cuda_driver.cc:328] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2022-07-05 15:43:22.829107: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (apollo2048g): /proc/driver/nvidia/version does not exist\n",
      "2022-07-05 15:43:22.829131: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2022-07-05 15:43:22.830585: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==Checking GPU==\n",
      "==Checking CUDA==\n",
      "==Reading data==\n"
     ]
    }
   ],
   "source": [
    "import importlib.util\n",
    "def module_from_file(module_name, file_path): #The code that imports the file which originated the training with all the instructions\n",
    "            spec = importlib.util.spec_from_file_location(module_name, file_path)\n",
    "            module = importlib.util.module_from_spec(spec)\n",
    "            spec.loader.exec_module(module)\n",
    "            return module\n",
    "\n",
    "from importlib import import_module\n",
    "#foo = import_module(fold_folder+'/Funs.py', package=None)\n",
    "\n",
    "\n",
    "folder = './xforanalogs/NA24by48/Z8/yrs500/interT15fw20.1.20lrs4'\n",
    "foo = module_from_file(\"foo\", f'{folder}/Funs.py')\n",
    "\n",
    "import random as rd  \n",
    "from scipy.stats import norm\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import neighbors\n",
    "from sklearn.metrics import log_loss\n",
    "\n",
    "tff = foo.tff # tensorflow routines \n",
    "ut = foo.ut # utilities\n",
    "ln = foo.ln #Learn2_new.py\n",
    "print(\"==Checking GPU==\")\n",
    "import tensorflow as tf\n",
    "tf.test.is_gpu_available(\n",
    "    cuda_only=False, min_cuda_compute_capability=None\n",
    ")\n",
    "\n",
    "print(\"==Checking CUDA==\")\n",
    "tf.test.is_built_with_cuda()\n",
    "\n",
    "#from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "sys.path.insert(1, '../ERA')\n",
    "\n",
    "print(\"==Reading data==\")\n",
    "\n",
    "year_permutation = np.load(f'{folder}/year_permutation.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_vae_kwargs = ut.json2dict(f\"{folder}/config.json\")\n",
    "T = ut.extract_nested(run_vae_kwargs, 'T')\n",
    "if (ut.keys_exists(run_vae_kwargs, 'label_period_start') and ut.keys_exists(run_vae_kwargs, 'label_period_end')):\n",
    "    label_period_start = ut.extract_nested(run_vae_kwargs, 'label_period_start')\n",
    "    label_period_end = ut.extract_nested(run_vae_kwargs, 'label_period_end')\n",
    "    time_start = ut.extract_nested(run_vae_kwargs, 'time_start')\n",
    "    time_end = ut.extract_nested(run_vae_kwargs, 'time_end')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "105"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_days = time_end-time_start-T+1\n",
    "n_days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0, 241,   0, ..., 351,   3,  52],\n",
       "       [  0,   0,  54, ..., 102, 145, 176],\n",
       "       [  0,   0, 405, ..., 390, 251, 378],\n",
       "       ...,\n",
       "       [449,  99,  99, ...,  74, 255, 123],\n",
       "       [281, 177, 241, ..., 208, 313, 198],\n",
       "       [208, 241, 211, ..., 376, 209, 339]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle\n",
    "fold = 0\n",
    "open_file = open(f'{folder}/fold_{fold}/analogues.pkl', \"rb\")\n",
    "analogues = pickle.load(open_file)\n",
    "open_file.close()\n",
    "\n",
    "checkpoint = 10\n",
    "\n",
    "analogues['ind_new_tr'][checkpoint]//n_days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,  12,   1, ...,  11,  48,  38],\n",
       "       [  1,   0,  29, ..., 100,  31,  87],\n",
       "       [  2,   3,  20, ...,  87,  93,  24],\n",
       "       ...,\n",
       "       [101,  44,  45, ...,  66,  59,  95],\n",
       "       [ 70,  46,  21, ...,  75,  24,  30],\n",
       "       [ 81,  21,  88, ...,  73,  25,  33]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analogues['ind_new_tr'][checkpoint]%n_days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[    0, 25317,     1, 25055, 10706, 32025, 32026, 32027,  5699],\n",
       "       [    1,     0,  5699, 42841,     2,  5701, 42840, 27301,  5700],\n",
       "       [    2,     3, 42545,  5363,  5365,  5699, 42841, 42544,     1],\n",
       "       [    3,     2,     4, 42545,  5367,  5366,  5365,  5368, 42546],\n",
       "       [    4,     5,     3,  5368,  5367, 12291,  5361,  5366, 32557],\n",
       "       [    5,     4,     6,  5368, 47154,  5361,  5367, 32557,     3],\n",
       "       [    6, 47154,     5,     7, 26782, 23223, 32562, 32561, 47155],\n",
       "       [    7,     8,  4332, 26782, 32562, 42319,  4331,     6, 47155],\n",
       "       [    8, 42320, 34685, 27246, 42014, 27245, 47156, 21432, 34236]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analogues['ind_new_tr'][checkpoint][:9,:9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.011160084656084656\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[   -1, 25317,    -1, ..., 36866,   363,  5498],\n",
       "       [   -1,    -1,  5699, ..., 10810, 15256, 18567],\n",
       "       [   -1,    -1, 42545, ..., 41037, 26448, 39714],\n",
       "       ...,\n",
       "       [   -1, 10439, 10440, ...,  7836, 26834, 13010],\n",
       "       [29575, 18631, 25326, ..., 21915, 32889, 20820],\n",
       "       [21921, 25326, 22243, ..., 39553, 21970, 35628]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "#selfanalogues = (analogues['ind_new_tr'][checkpoint]//n_days)[:,0][np.newaxis].T\n",
    "selfanalogues = ((np.arange(analogues['ind_new_tr'][checkpoint].shape[0]//n_days)[np.newaxis].T*np.ones((analogues['ind_new_tr'][checkpoint].shape[0]//n_days,n_days))).astype(int)).flatten()[np.newaxis].T # This is a matrix of years related to the raw index\n",
    "#selfanalogues*np.ones((selfanalogues.shape[0],analogues['ind_new_tr'][checkpoint].shape[1]))\n",
    "sameyear = selfanalogues*np.ones((selfanalogues.shape[0],analogues['ind_new_tr'][checkpoint].shape[1]))==analogues['ind_new_tr'][checkpoint]//n_days # A conditional matrix showing if the entry belongs to the same year \n",
    "#sameyear\n",
    "noselfanalogs = (np.where(sameyear,-1,analogues['ind_new_tr'][checkpoint])) # We set to -1 all the entries that are analogs of the same year\n",
    "print(np.mean(noselfanalogs == -1))\n",
    "noselfanalogs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[25317, 25055, 10706, ..., 47250, 47250, 47250],\n",
       "       [ 5699, 42841,  5701, ..., 47250, 47250, 47250],\n",
       "       [42545,  5363,  5365, ..., 47250, 47250, 47250],\n",
       "       ...,\n",
       "       [10439, 10440, 26960, ..., 47250, 47250, 47250],\n",
       "       [29575, 18631, 25326, ..., 20820, 47250, 47250],\n",
       "       [21921, 25326, 22243, ..., 39553, 21970, 35628]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "noselfanalogsmoved = []\n",
    "for noselfanalogs_row in noselfanalogs: # loop over samples\n",
    "    temp = np.delete(noselfanalogs_row,noselfanalogs_row==-1) # remove the values equal to -1 \n",
    "    noselfanalogsmoved.append(np.pad(temp, (0,noselfanalogs_row.shape[0] - temp.shape[0]), constant_values=(noselfanalogs.shape[0],noselfanalogs.shape[0])))  # pad with the length of the time series so that if we accidently get such analog the error will be returned\n",
    "noselfanalogsmoved = np.array(noselfanalogsmoved)\n",
    "noselfanalogsmoved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5250, 1000)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analogues['ind_new_va'][checkpoint].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "for j in range(5+np.max([0,3])//3):\n",
    "    print(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "13d6ac2b46cffe7b04dd84f7288304bd0f3c8f660cff0949df6ccaecc97804f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
