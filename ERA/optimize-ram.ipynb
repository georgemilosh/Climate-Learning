{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "In this environment you cannot import Basemap\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib widget\n",
    "from importlib import reload\n",
    "\n",
    "import ERA_Fields_New as ef\n",
    "\n",
    "import xarray as xr\n",
    "\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "from general_purpose import utilities as ut\n",
    "\n",
    "# log to stdout\n",
    "import logging\n",
    "logging.getLogger().level = logging.INFO\n",
    "logging.getLogger().handlers = [logging.StreamHandler(sys.stdout)]\n",
    "ut.indentation_sep = '  '"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "In this environment you cannot import Basemap\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<module 'ERA_Fields_New' from '/ClimateDynamics/MediumSpace/ClimateLearningFR/alovo/Climate-Learning/ERA/ERA_Fields_New.py'>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reload(ef)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mylocal = '/local/gmiloshe/PLASIM/'\n",
    "filename = 'Data_Plasim_LONG/ANO_LONG_tas.nc'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First valid path found in /local/gmiloshe/PLASIM/Data_Plasim_LONG/ANO_LONG_tas.nc\n",
      "CPU times: user 4.02 s, sys: 17.2 s, total: 21.2 s\n",
      "Wall time: 21.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "datas = xr.open_dataset(ut.first_valid_path(mylocal,filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 66 µs, sys: 0 ns, total: 66 µs\n",
      "Wall time: 70.1 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "field = datas['tas']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 470 µs, sys: 0 ns, total: 470 µs\n",
      "Wall time: 479 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "field = ef.discard_all_dimensions_but(field, dims_to_keep=['time', 'lon', 'lat'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "monotonize_years:\n",
      "monotonize_years: completed in 8.5 s\n",
      "CPU times: user 7.86 s, sys: 603 ms, total: 8.46 s\n",
      "Wall time: 8.45 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "field, yrs = ef.monotonize_years(field)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.73 s, sys: 52.6 ms, total: 1.78 s\n",
      "Wall time: 1.78 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "field = field.sel(time=field.time.dt.year.isin(np.arange(1000)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MemoryCachedArray(array=CopyOnWriteArray(array=LazilyIndexedArray(array=<xarray.backends.netCDF4_.NetCDF4ArrayWrapper object at 0x7f3c1a8eb500>, key=OuterIndexer((array([     0,      1,      2, ..., 149997, 149998, 149999]), slice(None, None, None), slice(None, None, None))))))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "field.variable._data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening field tas\n",
      "First valid path found in /local/gmiloshe/PLASIM/Data_Plasim_LONG/ANO_LONG_tas.nc\n",
      "monotonize_years:\n",
      "monotonize_years: completed in 6.2 s\n",
      "First valid path found in /local/gmiloshe/PLASIM/Data_Plasim_inter/CONTROL_lsmask.nc\n",
      "First valid path found in /local/gmiloshe/PLASIM/Data_Plasim_inter/CONTROL_gparea.nc\n",
      "CPU times: user 9.39 s, sys: 15.9 s, total: 25.2 s\n",
      "Wall time: 25.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "Field = ef.Plasim_Field('tas',filename,'t2m','Plasim',years=8000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "select_years:\n",
      "select_years: completed in 1.8 s\n"
     ]
    }
   ],
   "source": [
    "Field.select_years(np.arange(1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sort_lat:\n",
      "sort_lat: completed in 0.0 s\n"
     ]
    }
   ],
   "source": [
    "Field.sort_lat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "select_lonlat:\n",
      "  No filling of missing values\n",
      "select_lonlat: completed in 58.4 s\n"
     ]
    }
   ],
   "source": [
    "Field.select_lonlat(0,22,-64,64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "Field.field = Field.field.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-10 16:08:11.625427: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-03-10 16:08:11.728501: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "path_to_ERA = '/ClimateDynamics/MediumSpace/ClimateLearningFR/alovo/Climate-Learning'/ERA/\n",
      "Trying to import basemap\n",
      "In this environment you cannot import Basemap\n",
      "Trying to import cartopy\n",
      "Successfully imported cartopy\n",
      "Could not import sliding_window_view from np.lib.stride_tricks. Using custom copy for numpy<1.20\n",
      "Could not load field_infos: using the hardcoded version\n"
     ]
    }
   ],
   "source": [
    "from PLASIM import Learn2_new as ln"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load_data:\n",
      "  Opening field tas\n",
      "  First valid path found in /local/gmiloshe/PLASIM/Data_Plasim_LONG/ANO_LONG_tas.nc\n",
      "  monotonize_years:\n",
      "  monotonize_years: completed in 6.3 s\n",
      "  First valid path found in /local/gmiloshe/PLASIM/Data_Plasim_inter/CONTROL_lsmask.nc\n",
      "  First valid path found in /local/gmiloshe/PLASIM/Data_Plasim_inter/CONTROL_gparea.nc\n",
      "  select_years:\n",
      "  select_years: completed in 0.0 s\n",
      "  sort_lat:\n",
      "  sort_lat: completed in 0.0 s\n",
      "  select_lonlat:\n",
      "    No filling of missing values\n",
      "  select_lonlat: completed in 58.8 s\n",
      "  First valid path found in /local/gmiloshe/PLASIM/Data_Plasim_inter/CONTROL_lsmask.nc\n",
      "load_data: completed in 1 min 25.2 s\n",
      "CPU times: user 20.5 s, sys: 1min 4s, total: 1min 25s\n",
      "Wall time: 1min 25s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "fields = ln.load_data(fields=['t2m'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_years=8000\n",
    "year_list=None\n",
    "sampling=''\n",
    "Model='Plasim'\n",
    "area='France'\n",
    "filter_area='France'\n",
    "lon_start=-64\n",
    "lon_end=64\n",
    "lat_start=0\n",
    "lat_end=22\n",
    "fillna=None\n",
    "mylocal='/local/gmiloshe/PLASIM/',\n",
    "fields=['t2m']\n",
    "preprefix='ANO_'\n",
    "datafolder='Data_Plasim'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "if area != filter_area:\n",
    "    logger.warning(f'Fields will be filtered on a different area ({filter_area}) than the region of interest ({area}). If {area} is not a subset of {filter_area} the area integral will be different with and without filtering.')\n",
    "if Model.lower() not in datafolder.lower():\n",
    "    logger.warning(f'{datafolder = } does not contain the name of the model ({Model})')\n",
    "\n",
    "if dataset_years == 1000:\n",
    "    dataset_suffix = ''\n",
    "elif dataset_years == 8000:\n",
    "    dataset_suffix = 'LONG'\n",
    "else:\n",
    "    raise ValueError(f'Invalid number of {dataset_years = }')\n",
    "\n",
    "if isinstance(year_list, str):\n",
    "    if '(' not in year_list or ')' not in year_list:\n",
    "        raise ValueError(f'Unable to parse {year_list = }')\n",
    "    year_list = f\"({year_list.split('(',1)[1].split(')',1)[0]})\" # get just the arguments\n",
    "    year_list = ast.literal_eval(year_list) # now year_list is int or tuple\n",
    "\n",
    "if isinstance(year_list,int):\n",
    "    year_list = np.arange(year_list)\n",
    "elif isinstance(year_list, tuple):\n",
    "    year_list = np.arange(*year_list) # unpack the arguments of the tuple\n",
    "\n",
    "if sampling == '3hrs': \n",
    "    prefix = ''\n",
    "    if dataset_suffix == '':\n",
    "        file_suffix = f'../Climate/{datafolder}/'\n",
    "    else:\n",
    "        file_suffix = f'../Climate/{datafolder}_{dataset_suffix}/'\n",
    "else:\n",
    "    if dataset_suffix == '':\n",
    "        prefix = f'{preprefix}{dataset_suffix}'\n",
    "        file_suffix = f'{datafolder}{dataset_suffix}/'\n",
    "    else:\n",
    "        prefix = f'{preprefix}{dataset_suffix}_'\n",
    "        file_suffix = f'{datafolder}_{dataset_suffix}/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "field_name='t2m'\n",
    "ghost = False\n",
    "if field_name.endswith('_ghost'):\n",
    "    field_name = field_name.rsplit('_', 1)[0] # remove '_ghost'\n",
    "    ghost = True\n",
    "\n",
    "do_filter = False\n",
    "if field_name.endswith('_filtered'): # TO IMPROVE: if you have to filter the data load just the interesting part\n",
    "    field_name = field_name.rsplit('_', 1)[0] # remove '_filtered'\n",
    "    do_filter = True\n",
    "\n",
    "if field_name not in ln.fields_infos[Model]:\n",
    "    raise KeyError(f'Unknown field {field_name}')\n",
    "f_infos = ln.fields_infos[Model][field_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening field tas\n",
      "First valid path found in /local/gmiloshe/PLASIM/Data_Plasim_LONG/ANO_LONG_tas.nc\n",
      "monotonize_years:\n",
      "monotonize_years: completed in 6.1 s\n",
      "First valid path found in /local/gmiloshe/PLASIM/Data_Plasim_inter/CONTROL_lsmask.nc\n",
      "First valid path found in /local/gmiloshe/PLASIM/Data_Plasim_inter/CONTROL_gparea.nc\n"
     ]
    }
   ],
   "source": [
    "# create the field object\n",
    "field = ef.Plasim_Field(f_infos['name'], f\"{file_suffix}{prefix}{f_infos['filename_suffix']}.nc\", f_infos['label'], Model,\n",
    "                        years=dataset_years, mylocal=mylocal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "select_years:\n",
      "select_years: completed in 0.0 s\n"
     ]
    }
   ],
   "source": [
    "# select years\n",
    "field.select_years(year_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sort_lat:\n",
      "sort_lat: completed in 0.0 s\n"
     ]
    }
   ],
   "source": [
    "# Sort the latitudes\n",
    "field.sort_lat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "select_lonlat:\n",
      "  No filling of missing values\n",
      "select_lonlat: completed in 58.9 s\n"
     ]
    }
   ],
   "source": [
    "# select longitude and latitude\n",
    "field.select_lonlat(lat_start,lat_end,lon_start,lon_end,fillna)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter\n",
    "if do_filter: # set to zero all values outside `filter_area`\n",
    "    field.set_mask(filter_area)\n",
    "    field.filter()\n",
    "\n",
    "\n",
    "# prepare to compute area integral when needed\n",
    "field.set_mask(area)\n",
    "\n",
    "if ghost:\n",
    "    field_name += '_ghost'"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "07b665c933ae35d0fc22e8b5988b84554f26bb968a683e60ed7e11394e6ead53"
  },
  "kernelspec": {
   "display_name": "mlk",
   "language": "python",
   "name": "mlk"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
